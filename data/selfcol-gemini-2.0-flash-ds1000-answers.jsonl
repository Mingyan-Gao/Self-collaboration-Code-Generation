{"id": 0, "code": "```python\nresult = df.iloc[List]\n```", "metadata": {"problem_id": 0, "library_problem_id": 0, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 0}}
{"id": 1, "code": "```python\noriginal_types = df['Type'].copy()\nshuffled_df = df.iloc[List].copy()\nmismatches = (shuffled_df['Type'] != original_types).sum()\nresult = mismatches\n</code>\n\n</code>", "metadata": {"problem_id": 1, "library_problem_id": 1, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 0}}
{"id": 2, "code": "```python\nfor col in ['Qu1', 'Qu3']:\n    counts = df[col].value_counts()\n    infrequent_values = counts[counts < 2].index\n    df[col] = df[col].replace(infrequent_values, 'other')\n\nresult = df\n```\n\n</code>", "metadata": {"problem_id": 2, "library_problem_id": 2, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 2}}
{"id": 3, "code": "```python\nfor col in df.columns:\n    value_counts = df[col].value_counts()\n    infrequent_values = value_counts[value_counts < 3].index\n    df.loc[df[col].isin(infrequent_values), col] = 'other'\n\nresult = df\n```\n\n</code>", "metadata": {"problem_id": 3, "library_problem_id": 3, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 2}}
{"id": 4, "code": "```python\n    for col in ['Qu1', 'Qu2', 'Qu3']:\n        value_counts = df[col].value_counts()\n        infrequent_values = value_counts[value_counts < 2].index\n        df[col] = df[col].replace(infrequent_values, 'other')\n    return df\n```", "metadata": {"problem_id": 4, "library_problem_id": 4, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 2}}
{"id": 5, "code": "```python\ndef transform_column(df, column_name, min_count):\n    value_counts = df[column_name].value_counts()\n    to_replace = value_counts[value_counts < min_count].index\n    df[column_name] = df[column_name].replace(to_replace, 'other')\n    return df\n\ndf = transform_column(df, 'Qu1', 3)\ndf = transform_column(df, 'Qu3', 2)\n\nresult = df\n```\n\n</code>", "metadata": {"problem_id": 5, "library_problem_id": 5, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 2}}
{"id": 6, "code": "```python\nqu1_counts = df['Qu1'].value_counts()\nqu1_replacements = qu1_counts[qu1_counts < 3].index\ndf['Qu1'] = df['Qu1'].apply(lambda x: 'other' if x in qu1_replacements and x != 'apple' and x == 'egg' else ('other' if x in qu1_replacements and x != 'apple' else x))\n\nqu3_counts = df['Qu3'].value_counts()\nqu3_replacements = qu3_counts[qu3_counts < 2].index\ndf['Qu3'] = df['Qu3'].apply(lambda x: 'other' if x in qu3_replacements else x)\n\nresult = df\n```\n\n</code>", "metadata": {"problem_id": 6, "library_problem_id": 6, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 2}}
{"id": 7, "code": "```python\nkeep_df = df[df['keep_if_dup'] == 'Yes']\ndrop_df = df[df['keep_if_dup'] != 'Yes']\ndrop_df = drop_df.drop_duplicates(subset='url', keep='first')\nresult = pd.concat([keep_df, drop_df]).sort_index()\n```\n\n</code>", "metadata": {"problem_id": 7, "library_problem_id": 7, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 7}}
{"id": 8, "code": "```python\nseen_urls = set()\nresult = []\nfor index, row in df.iterrows():\n    if row['url'] not in seen_urls:\n        result.append(row)\n        if row['drop_if_dup'] == 'Yes':\n            seen_urls.add(row['url'])\n    elif row['drop_if_dup'] == 'No':\n        result.append(row)\nresult = pd.DataFrame(result)\n```\n\n</code>", "metadata": {"problem_id": 8, "library_problem_id": 8, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 7}}
{"id": 9, "code": "```python\nkeep_mask = df['keep_if_dup'] == 'Yes'\nkeep_df = df[keep_mask]\ndrop_df = df[~keep_mask]\ndrop_df = drop_df.drop_duplicates(subset='url', keep='last')\nresult = pd.concat([keep_df, drop_df]).sort_index()\n```\n\n</code>", "metadata": {"problem_id": 9, "library_problem_id": 9, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 7}}
{"id": 10, "code": "```python\nresult = {}\nfor name in df['name'].unique():\n    result[name] = {}\n    sub_df = df[df['name'] == name]\n    for _, row in sub_df.iterrows():\n        current_dict = result[name]\n        for col in df.columns[1:-1]:\n            value = row[col]\n            if value not in current_dict:\n                current_dict[value] = {}\n            current_dict = current_dict[value]\n        last_col = df.columns[-1]\n        current_dict[row[last_col]] = row[last_col]\ndef merge_dicts(dict1, dict2):\n    for key, value in dict2.items():\n        if key in dict1:\n            if isinstance(value, dict) and isinstance(dict1[key], dict):\n                merge_dicts(dict1[key], value)\n            else:\n                if not isinstance(dict1[key], list):\n                    dict1[key] = [dict1[key]]\n                dict1[key].append(value)\n        else:\n            dict1[key] = value\n    return dict1\nresult = {}\nfor name in df['name'].unique():\n    result[name] = {}\n    sub_df = df[df['name'] == name]\n    for _, row in sub_df.iterrows():\n        current_dict = result[name]\n        for col in df.columns[1:-1]:\n            value = row[col]\n            if col == df.columns[-2]:\n                last_dict = current_dict\n                last_value = value\n                if value not in current_dict:\n                    current_dict[value] = {}\n                current_dict = current_dict[value]\n            else:\n                if value not in current_dict:\n                    current_dict[value] = {}\n                current_dict = current_dict[value]\n        last_col = df.columns[-1]\n        current_dict[row[last_col]] = row[last_col]\nimport collections\ndef build_nested_dict(df):\n    output = collections.defaultdict(lambda: collections.defaultdict(dict))\n    for index, row in df.iterrows():\n        d = output[row['name']]\n        for i, col in enumerate(df.columns[1:-1]):\n            if not isinstance(d, dict):\n                break\n            d = d.setdefault(row[col], {})\n        if isinstance(d, dict):\n            d[row[df.columns[-1]]] = row[df.columns[-1]]\n    return output\nresult = build_nested_dict(df)\nfrom collections import defaultdict\ndef to_nested_dict(df):\n    result = defaultdict(lambda: defaultdict(dict))\n    for _, row in df.iterrows():\n        current_level = result[row['name']]\n        for col in df.columns[1:-1]:\n            current_level = current_level[row[col]]\n        current_level[row[df.columns[-1]]] = row[df.columns[-1]]\n    return {k: {k2: dict(v2) for k2, v2 in v.items()} for k, v in result.items()}\nresult = to_nested_dict(df)\n```\n\n</code>", "metadata": {"problem_id": 10, "library_problem_id": 10, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 10}}
{"id": 11, "code": "```python\ndf['datetime'] = df['datetime'].dt.tz_localize(None)\n```</code>", "metadata": {"problem_id": 11, "library_problem_id": 11, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 11}}
{"id": 12, "code": "```python\n    df['datetime'] = df['datetime'].dt.tz_localize(None)\n    return df\n```", "metadata": {"problem_id": 12, "library_problem_id": 12, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 11}}
{"id": 13, "code": "```python\ndf['datetime'] = df['datetime'].dt.tz_convert(None)\ndf['datetime'] = df['datetime'].dt.strftime('%d-%b-%Y %H:%M:%S')\ndf = df.sort_values(by='datetime')\n</code>\n", "metadata": {"problem_id": 13, "library_problem_id": 13, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 11}}
{"id": 14, "code": "```python\ndf['datetime'] = df['datetime'].dt.tz_localize(None)\ndf = df.sort_values(by='datetime')\n</code>\n", "metadata": {"problem_id": 14, "library_problem_id": 14, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 11}}
{"id": 15, "code": "```python\ndef parse_message(message):\n    message = message.strip('[]')\n    pairs = message.split(',')\n    result = {}\n    for pair in pairs:\n        if ':' in pair:\n            key, value = pair.split(':', 1)\n            key = key.strip()\n            value = value.strip()\n            if key:\n                result[key] = value if value else 'none'\n    return result\n\ndf['parsed_message'] = df['message'].apply(parse_message)\ndf = pd.concat([df, df['parsed_message'].apply(pd.Series)], axis=1)\ndf = df.fillna('none')\ndf = df.drop(['message', 'parsed_message'], axis=1)\nresult = df\n```\n\n</code>", "metadata": {"problem_id": 15, "library_problem_id": 15, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 15}}
{"id": 16, "code": "```python\nmask = df['product'].isin(products)\ndf.loc[mask, 'score'] = df.loc[mask, 'score'] * 10\n```\n\n</code>", "metadata": {"problem_id": 16, "library_problem_id": 16, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 16}}
{"id": 17, "code": "```python\nfor index, row in df.iterrows():\n    if row['product'] not in products:\n        df.loc[index, 'score'] = row['score'] * 10\n</code>", "metadata": {"problem_id": 17, "library_problem_id": 17, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 16}}
{"id": 18, "code": "```python\nfor product_range in products:\n    df.loc[(df['product'] >= product_range[0]) & (df['product'] <= product_range[1]), 'score'] *= 10\n```\n\n</code>", "metadata": {"problem_id": 18, "library_problem_id": 18, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 16}}
{"id": 19, "code": "```python\nmask = df['product'].isin(products)\nscores = df.loc[mask, 'score']\nmin_score = scores.min()\nmax_score = scores.max()\nnormalized_scores = (scores - min_score) / (max_score - min_score)\ndf.loc[mask, 'score'] = normalized_scores\n```\n\n</code>", "metadata": {"problem_id": 19, "library_problem_id": 19, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 16}}
{"id": 20, "code": "```python\ndf['category'] = df.idxmax(axis=1)\n```</code>", "metadata": {"problem_id": 20, "library_problem_id": 20, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 20}}
{"id": 21, "code": "```python\ncategories = []\nfor index in range(len(df)):\n    for col in ['A', 'B', 'C', 'D']:\n        if df.loc[index, col] == 0:\n            categories.append(col)\n            break\ndf['category'] = categories\n</code>\n\n</code>", "metadata": {"problem_id": 21, "library_problem_id": 21, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 20}}
{"id": 22, "code": "```python\ndf['category'] = df.apply(lambda row: list(df.columns[row == 1]), axis=1)\n```\n\n</code>", "metadata": {"problem_id": 22, "library_problem_id": 22, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 20}}
{"id": 23, "code": "```python\ndf['Date'] = df['Date'].dt.strftime('%b-%Y')\n</code>\n", "metadata": {"problem_id": 23, "library_problem_id": 23, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 23}}
{"id": 24, "code": "```python\ndf['Date'] = df['Date'].dt.strftime('%d-%b-%Y')\n</code>", "metadata": {"problem_id": 24, "library_problem_id": 24, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 23}}
{"id": 25, "code": "```python\ndf['Date'] = pd.to_datetime(df['Date'])\nList = pd.to_datetime(List)\nstart_date = List[0]\nend_date = List[1]\nmask = (df['Date'] >= start_date) & (df['Date'] <= end_date)\ndf = df.loc[mask]\ndf['Date'] = df['Date'].dt.strftime('%d-%b-%Y %A')\n```\n\n</code>", "metadata": {"problem_id": 25, "library_problem_id": 25, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 23}}
{"id": 26, "code": "```python\nfirst_column = df['#1'].tolist()\nrotated_column = [first_column[-1]] + first_column[:-1]\ndf['#1'] = rotated_column\n</code>", "metadata": {"problem_id": 26, "library_problem_id": 26, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 26}}
{"id": 27, "code": "```python\nfirst_col = df['#1'].copy()\nshifted_values = first_col.iloc[1:].tolist() + [first_col.iloc[0]]\ndf['#1'] = shifted_values\n```\n\n</code>", "metadata": {"problem_id": 27, "library_problem_id": 27, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 26}}
{"id": 28, "code": "```python\nfirst_val_col1 = df.iloc[0, 0]\ndf['#1'] = df['#1'].shift(1)\ndf['#1'].iloc[0] = df['#1'].iloc[-1]\ndf['#1'].iloc[-1] = first_val_col1\n\nlast_val_col2 = df.iloc[-1, 1]\ndf['#2'] = df['#2'].shift(-1)\ndf['#2'].iloc[-1] = df['#2'].iloc[0]\ndf['#2'].iloc[0] = last_val_col2\n```\n\n</code>", "metadata": {"problem_id": 28, "library_problem_id": 28, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 26}}
{"id": 29, "code": "```python\nimport pandas as pd\nfrom scipy.stats import linregress\n\ndf = pd.DataFrame({'#1': [11.6985, 43.6431, 54.9089, 63.1225, 72.4399],\n                   '#2': [126.0, 134.0, 130.0, 126.0, 120.0]},\n                  index=['1980-01-01', '1980-01-02', '1980-01-03', '1980-01-04', '1980-01-05'])\n\ndef calculate_r_squared(col1, col2):\n    slope, intercept, r_value, p_value, std_err = linregress(col1, col2)\n    return r_value**2\n\ndef shift_column(df, column_name, shift):\n    shifted_column = df[column_name].shift(shift).fillna(df[column_name].iloc[-shift])\n    return shifted_column\n\nr_squared_values = []\nshifted_dataframes = []\n\nfor shift in range(1, len(df) + 1):\n    shifted_col1 = shift_column(df, '#1', shift)\n    r_squared = calculate_r_squared(shifted_col1, df['#2'])\n    r_squared_values.append(r_squared)\n    shifted_dataframes.append(df.copy())\n    shifted_dataframes[-1]['#1'] = shifted_col1\n\nmin_r_squared = min(r_squared_values)\nmin_r_squared_index = r_squared_values.index(min_r_squared)\ndf = shifted_dataframes[min_r_squared_index]\n```\n\n</code>", "metadata": {"problem_id": 29, "library_problem_id": 29, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 26}}
{"id": 30, "code": "```python\ndf.columns = [col + 'X' for col in df.columns]\n</code>", "metadata": {"problem_id": 30, "library_problem_id": 30, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 30}}
{"id": 31, "code": "```python\ndf.columns = ['X' + col for col in df.columns]\n</code>", "metadata": {"problem_id": 31, "library_problem_id": 31, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 30}}
{"id": 32, "code": "```python\ndf.columns = ['X' + col for col in df.columns]\n</code>\n", "metadata": {"problem_id": 32, "library_problem_id": 32, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 30}}
{"id": 33, "code": "```python\nval_cols = [col for col in df.columns if 'val' in str(col)]\nagg_dict = {'group_color': 'first'}\nfor col in val_cols:\n    agg_dict[col] = 'mean'\nresult = df.groupby('group').agg(agg_dict)\n```\n\n</code>", "metadata": {"problem_id": 33, "library_problem_id": 33, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 33}}
{"id": 34, "code": "```python\nvalue_cols = [col for col in df.columns if 'val' in col]\naggregation_dict = {\"group_color\": \"first\"}\nfor col in value_cols:\n    aggregation_dict[col] = \"sum\"\nresult = df.groupby('group').agg(aggregation_dict)\n```</code>", "metadata": {"problem_id": 34, "library_problem_id": 34, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 33}}
{"id": 35, "code": "```python\nimport pandas as pd\n\ndf = pd.DataFrame({ 'group': ['A', 'A', 'A', 'B', 'B'], 'group_color' : ['green', 'green', 'green', 'blue', 'blue'], 'val1': [5, 2, 3, 4, 5], 'val2' : [4, 2, 8, 5, 7],'val42':[1,1,4,5,1] })\n\nvalue_cols = [col for col in df.columns if 'group' not in col and 'group_color' not in col]\nagg_dict = {}\nfor col in value_cols:\n    if col.endswith('2'):\n        agg_dict[col] = 'mean'\n    else:\n        agg_dict[col] = 'sum'\nagg_dict['group_color'] = 'first'\n\nresult = df.groupby('group').agg(agg_dict)\n```</code>", "metadata": {"problem_id": 35, "library_problem_id": 35, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 33}}
{"id": 36, "code": "```python\nresult = df.loc[row_list, column_list].mean(axis=0)\n</code>\n\n", "metadata": {"problem_id": 36, "library_problem_id": 36, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 36}}
{"id": 37, "code": "```python\nresult = df.iloc[row_list][column_list].sum()\n</code>", "metadata": {"problem_id": 37, "library_problem_id": 37, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 36}}
{"id": 38, "code": "```python\nresult = df.iloc[row_list][column_list].sum(axis=0)\nresult = result.drop(result.idxmax())\n```</code>", "metadata": {"problem_id": 38, "library_problem_id": 38, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 36}}
{"id": 39, "code": "```python\nresult = pd.concat([df[col].value_counts() for col in df.columns])\n</code>\n\n", "metadata": {"problem_id": 39, "library_problem_id": 39, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 39}}
{"id": 40, "code": "```python\nresult = df.apply(lambda x: x.astype(str).str.contains('null').sum())\nresult.name = 'null'\n</code>", "metadata": {"problem_id": 40, "library_problem_id": 40, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 39}}
{"id": 41, "code": "```python\nresult = ''\nfor col in df.columns:\n    result += f'---- {col} ---\\n'\n    result += df[col].value_counts().to_string() + '\\n'\n    result += f'Name: {col}, dtype: {df[col].dtype}\\n'\n</code>", "metadata": {"problem_id": 41, "library_problem_id": 41, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 39}}
{"id": 42, "code": "```python\nnew_header = df.iloc[1].combine_first(df.iloc[0]).tolist()\ndf.columns = new_header\ndf = df.drop([0, 1])\nresult = df\n```</code>", "metadata": {"problem_id": 42, "library_problem_id": 42, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 42}}
{"id": 43, "code": "```python\nheader = df.iloc[1].combine_first(df.iloc[0]).tolist()\ndf.columns = header\nresult = df.iloc[2:]\n</code>", "metadata": {"problem_id": 43, "library_problem_id": 43, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 42}}
{"id": 44, "code": "```python\nresult = df.apply(lambda x: pd.Series(x.sort_values(na_position='last').values), axis=1)\n```\n\n</code>", "metadata": {"problem_id": 44, "library_problem_id": 44, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 44}}
{"id": 45, "code": "```python\nvalues = df.values\nresult = np.full(values.shape, np.nan)\nfor i, row in enumerate(values):\n    valid_values = row[~np.isnan(row)]\n    result[i, -len(valid_values):] = valid_values\nresult = pd.DataFrame(result, columns=df.columns)\n```\n\n</code>", "metadata": {"problem_id": 45, "library_problem_id": 45, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 44}}
{"id": 46, "code": "```python\nresult = df.copy()\nfor col in df.columns:\n    result = result.sort_values(by=col, na_position='first')\n</code>", "metadata": {"problem_id": 46, "library_problem_id": 46, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 44}}
{"id": 47, "code": "```python\nmask = df['value'] < thresh\nsum_val = df.loc[mask, 'value'].sum()\nnew_row = pd.DataFrame({'value': [sum_val]}, index=['X'])\ndf_filtered = df[~mask]\nresult = pd.concat([df_filtered, new_row])\nresult = result.sort_index()\n</code>\n\n", "metadata": {"problem_id": 47, "library_problem_id": 47, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 47}}
{"id": 48, "code": "```python\nabove_threshold = df[df['value'] >= thresh]\nbelow_threshold = df[df['value'] < thresh]\nif not above_threshold.empty:\n    average = above_threshold['value'].mean()\n    new_row = pd.DataFrame({'value': [average]}, index=['X'])\n    result = pd.concat([below_threshold, new_row])\nelse:\n    result = below_threshold\n```\n\n</code>", "metadata": {"problem_id": 48, "library_problem_id": 48, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 47}}
{"id": 49, "code": "```python\noutside_section = df[(df['value'] < section_left) | (df['value'] > section_right)]\ninside_section = df[(df['value'] >= section_left) & (df['value'] <= section_right)]\n\nif not outside_section.empty:\n    average_value = outside_section['value'].mean()\n    new_row = pd.DataFrame({'value': [average_value]}, index=['X'])\n    result = pd.concat([inside_section, new_row])\nelse:\n    result = inside_section\n```\n\n</code>", "metadata": {"problem_id": 49, "library_problem_id": 49, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 47}}
{"id": 50, "code": "```python\nfor col in df.columns:\n    df['inv_' + col] = 1 / df[col]\nresult = df\n</code>\n", "metadata": {"problem_id": 50, "library_problem_id": 50, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 50}}
{"id": 51, "code": "```python\nimport numpy as np\n\nfor col in df.columns:\n    df[f'exp_{col} '] = np.exp(df[col])\nresult = df\n</code>\n", "metadata": {"problem_id": 51, "library_problem_id": 51, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 50}}
{"id": 52, "code": "```python\nimport numpy as np\nfor col in df.columns:\n    df[f'inv_{col}'] = np.where(df[col] != 0, 1 / df[col], 0)\nresult = df\n```\n\n</code>", "metadata": {"problem_id": 52, "library_problem_id": 52, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 50}}
{"id": 53, "code": "```python\nimport numpy as np\n\nfor col in df.columns:\n    df[f'sigmoid_{col}'] = 1 / (1 + np.exp(-df[col]))\nresult = df\n```\n\n</code>", "metadata": {"problem_id": 53, "library_problem_id": 53, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 50}}
{"id": 54, "code": "```python\nmin_idx = df.idxmin()\nresult = pd.Series(index=df.columns)\nfor col in df.columns:\n    mask = df.index <= min_idx[col]\n    result[col] = df.loc[mask, col].idxmax()\n```\n\n</code>", "metadata": {"problem_id": 54, "library_problem_id": 54, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 54}}
{"id": 55, "code": "```python\n    min_indices = df.idxmin()\n\n    def find_max_after_min(column, min_index):\n        sliced_column = column[column.index >= min_index]\n        if sliced_column.empty:\n            return None\n        return sliced_column.idxmax()\n\n    result = df.apply(lambda col: find_max_after_min(col, min_indices[col.name]), axis=0)\n```", "metadata": {"problem_id": 55, "library_problem_id": 55, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 54}}
{"id": 56, "code": "```python\nuser_date_range = df.groupby('user')['dt'].agg(['min', 'max'])\nnew_index = []\nfor user, row in user_date_range.iterrows():\n    new_index.extend(pd.date_range(row['min'], row['max'], name='dt'))\nnew_df = pd.DataFrame(new_index, columns=['dt'])\nnew_df['user'] = new_df.groupby(new_df['dt'].dt.year).apply(lambda x: [user] * len(x)).explode().values\nresult = pd.merge(new_df, df, on=['user', 'dt'], how='left').sort_values(by=['dt', 'user']).fillna(0)\n```\n\n</code>", "metadata": {"problem_id": 56, "library_problem_id": 56, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 56}}
{"id": 57, "code": "```python\ndef expand_dates(df):\n    df['dt'] = pd.to_datetime(df['dt'])\n    \n    dfs = []\n    for user, group in df.groupby('user'):\n        min_date = group['dt'].min()\n        max_date = group['dt'].max()\n        \n        date_range = pd.date_range(start=min_date, end=max_date)\n        new_df = pd.DataFrame({'dt': date_range})\n        new_df['user'] = user\n        new_df['val'] = 0\n        \n        merged_df = pd.merge(new_df, group, on=['user', 'dt'], how='left')\n        merged_df['val'] = merged_df['val_y'].fillna(merged_df['val_x']).astype(int)\n        merged_df = merged_df[['dt', 'user', 'val']]\n        dfs.append(merged_df)\n    \n    result = pd.concat(dfs)\n    result = result.sort_values(['dt', 'user']).reset_index(drop=True)\n    return result\n\nresult = expand_dates(df.copy())\n</code>\n\n</code>", "metadata": {"problem_id": 57, "library_problem_id": 57, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 56}}
{"id": 58, "code": "```python\ndef expand_dates(df):\n    df['dt'] = pd.to_datetime(df['dt'])\n    \n    dfs = []\n    for user, group in df.groupby('user'):\n        min_date = group['dt'].min()\n        max_date = group['dt'].max()\n        \n        date_range = pd.date_range(min_date, max_date)\n        \n        new_df = pd.DataFrame({'dt': date_range, 'user': user})\n        \n        merged_df = pd.merge(new_df, group, on=['user', 'dt'], how='left')\n        merged_df['val'] = merged_df['val'].fillna(233)\n        dfs.append(merged_df)\n        \n    final_df = pd.concat(dfs)\n    final_df = final_df.sort_values(by=['dt', 'user']).reset_index(drop=True)\n    return final_df\n\nresult = expand_dates(df.copy())\n```\n\n</code>", "metadata": {"problem_id": 58, "library_problem_id": 58, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 56}}
{"id": 59, "code": "```python\ndef expand_dates(group):\n    min_date = group['dt'].min()\n    max_date = group['dt'].max()\n    date_range = pd.date_range(min_date, max_date)\n    expanded_df = pd.DataFrame({'dt': date_range, 'user': group['user'].iloc[0]})\n    max_val = group['val'].max()\n    expanded_df['val'] = max_val\n    return expanded_df\n\ngrouped = df.groupby('user')\nresult = grouped.apply(expand_dates)\nresult = pd.concat(result).reset_index(drop=True)\nresult = result.sort_values(by=['user', 'dt']).reset_index(drop=True)\n```\n\n</code>", "metadata": {"problem_id": 59, "library_problem_id": 59, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 56}}
{"id": 60, "code": "```python\ndef expand_dates(group):\n    min_date = group['dt'].min()\n    max_date = group['dt'].max()\n    date_range = pd.date_range(min_date, max_date)\n    new_df = pd.DataFrame({'dt': date_range, 'user': group['user'].iloc[0]})\n    max_val = group['val'].max()\n    new_df['val'] = max_val\n    return new_df\n\ndf['dt'] = pd.to_datetime(df['dt'])\nresult = pd.concat(df.groupby('user').apply(expand_dates)).reset_index(drop=True)\nresult['dt'] = result['dt'].dt.strftime('%d-%b-%Y')\n```</code>", "metadata": {"problem_id": 60, "library_problem_id": 60, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 56}}
{"id": 61, "code": "```python\nname_to_id = {name: i + 1 for i, name in enumerate(df['name'].unique())}\ndf['name'] = df['name'].map(name_to_id)\nresult = df\n</code>\n\n", "metadata": {"problem_id": 61, "library_problem_id": 61, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 61}}
{"id": 62, "code": "```python\nmapping = {x: i + 1 for i, x in enumerate(df['a'].unique())}\ndf['a'] = df['a'].map(mapping)\nresult = df\n</code>\n\n</code>", "metadata": {"problem_id": 62, "library_problem_id": 62, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 61}}
{"id": 63, "code": "```python\n    unique_names = df['name'].unique()\n    name_to_id = {name: i + 1 for i, name in enumerate(unique_names)}\n    df['name'] = df['name'].replace(name_to_id)\n    return df\n```", "metadata": {"problem_id": 63, "library_problem_id": 63, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 61}}
{"id": 64, "code": "```python\ndf['combined'] = df['name'].astype(str) + '_' + df['a'].astype(str)\ndf['ID'] = pd.factorize(df['combined'])[0] + 1\nresult = df[['ID', 'b', 'c']]\n```\n\n</code>", "metadata": {"problem_id": 64, "library_problem_id": 64, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 61}}
{"id": 65, "code": "```python\ndf = pd.melt(df, id_vars=['user', 'someBool'], var_name='date', value_name='value')\ndf = df.rename(columns={'variable': 'date'})\ndf['value'] = pd.to_numeric(df['value'])\ndf = df[['user', 'date', 'value', 'someBool']]\n```\n\n</code>", "metadata": {"problem_id": 65, "library_problem_id": 65, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 65}}
{"id": 66, "code": "```python\ndf = pd.melt(df, id_vars=['user', '01/12/15'], value_vars=['02/12/15', 'someBool'], var_name='others', value_name='value')\ndf = df[['user', '01/12/15', 'others', 'value']]\n```\n\n</code>", "metadata": {"problem_id": 66, "library_problem_id": 66, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 65}}
{"id": 67, "code": "```python\ndf = pd.melt(df, id_vars=['user', 'someBool'], value_vars=['01/12/15', '02/12/15'], var_name='date', value_name='value')\ndf = df.dropna(subset=['value'])\ndf['value'] = pd.to_numeric(df['value'], errors='coerce')\ndf = df.dropna(subset=['value'])\ndf = df[['user', 'date', 'value', 'someBool']]\n```\n\n</code>", "metadata": {"problem_id": 67, "library_problem_id": 67, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 65}}
{"id": 68, "code": "```python\nresult = df[df['c'] > 0.5][columns].to_numpy()\n</code>", "metadata": {"problem_id": 68, "library_problem_id": 68, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 68}}
{"id": 69, "code": "```python\nresult = df.loc[df['c'] > 0.45, columns].to_numpy()\n</code>", "metadata": {"problem_id": 69, "library_problem_id": 69, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 68}}
{"id": 70, "code": "```python\n    return df[df['c'] > 0.5][columns].to_numpy()\n    ### END SOLUTION\n```", "metadata": {"problem_id": 70, "library_problem_id": 70, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 68}}
{"id": 71, "code": "```python\n    filtered_df = df[df['c'] > 0.5]\n    selected_df = filtered_df[columns].copy()\n    selected_df['sum'] = selected_df.sum(axis=1)\n    return selected_df\n```", "metadata": {"problem_id": 71, "library_problem_id": 71, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 68}}
{"id": 72, "code": "```python\n    return df[df['c'] > 0.5][columns]\n### END SOLUTION\n```", "metadata": {"problem_id": 72, "library_problem_id": 72, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 68}}
{"id": 73, "code": "```python\ndf['date'] = pd.to_datetime(df['date'], format='%m/%d/%y', errors='coerce')\ndf = df.sort_values(by='date')\nmask = [True] + [False] * (len(df) - 1)\nlast_date = df['date'].iloc[0]\nfor i in range(1, len(df)):\n    if (df['date'].iloc[i] - last_date).days > X:\n        mask[i] = True\n        last_date = df['date'].iloc[i]\nresult = df[mask]\n```\n\n</code>", "metadata": {"problem_id": 73, "library_problem_id": 73, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 73}}
{"id": 74, "code": "```python\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.sort_values(by='date')\nindices_to_remove = []\nfor i in range(len(df)):\n    if i in indices_to_remove:\n        continue\n    for j in range(i + 1, len(df)):\n        if j in indices_to_remove:\n            continue\n        time_difference = df['date'].iloc[j] - df['date'].iloc[i]\n        if time_difference <= pd.Timedelta(weeks=X):\n            indices_to_remove.append(j)\n\nresult = df.drop(indices_to_remove)\n```\n\n</code>", "metadata": {"problem_id": 74, "library_problem_id": 74, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 73}}
{"id": 75, "code": "```python\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.sort_values(by='date')\ndrop_indices = []\nkept_dates = []\n\nfor index, row in df.iterrows():\n    date = row['date']\n    overlap = False\n    for kept_date in kept_dates:\n        if abs(date - kept_date) <= pd.Timedelta(weeks=X):\n            overlap = True\n            break\n    if overlap:\n        drop_indices.append(index)\n    else:\n        kept_dates.append(date)\n\ndf = df.drop(drop_indices)\ndf['date'] = df['date'].dt.strftime('%d-%b-%Y')\nresult = df\n```\n\n</code>", "metadata": {"problem_id": 75, "library_problem_id": 75, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 73}}
{"id": 76, "code": "```python\nimport numpy as np\n\nresult = pd.DataFrame({'col1': df['col1'].values.reshape(-1,3).mean(axis=1)})\n</code>\n", "metadata": {"problem_id": 76, "library_problem_id": 76, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 76}}
{"id": 77, "code": "```python\nimport numpy as np\n\nresult = pd.DataFrame({'col1': df['col1'].values.reshape(-1, 3).sum(axis=1)})\n```\n\n</code>", "metadata": {"problem_id": 77, "library_problem_id": 77, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 76}}
{"id": 78, "code": "```python\nimport numpy as np\n\nresult = pd.DataFrame({'col1': df['col1'].values.reshape(-1, 4).sum(axis=1)})\n```\n\n</code>", "metadata": {"problem_id": 78, "library_problem_id": 78, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 76}}
{"id": 79, "code": "```python\nimport pandas as pd\n\ndf = pd.DataFrame({'col1':[2, 1, 3, 1, 0]})\n\nnum_bins = len(df) // 3\nmeans = []\nfor i in range(len(df) - 1, -1, -3):\n    start = max(0, i - 2)\n    mean = df['col1'][start:i+1].mean()\n    means.append(mean)\n\nmeans.reverse()\nresult = pd.DataFrame({'col1': means})\n</code>\n", "metadata": {"problem_id": 79, "library_problem_id": 79, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 76}}
{"id": 80, "code": "```python\nresults = []\ni = 0\nwhile i < len(df):\n    if i + 3 <= len(df):\n        results.append(df['col1'][i:i+3].sum())\n        i += 3\n    else:\n        results.append(df['col1'][i:i+2].mean())\n        i += 2\n    \nresult = pd.DataFrame({'col1': results})\n</code>\n", "metadata": {"problem_id": 80, "library_problem_id": 80, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 76}}
{"id": 81, "code": "```python\nresult = []\ni = len(df)\nwhile i > 0:\n    if len(result) % 2 == 0:\n        temp = df['col1'][max(0, i-3):i].sum()\n        i -= 3\n    else:\n        temp = df['col1'][max(0, i-2):i].mean()\n        i -= 2\n    result.append(temp)\nresult = pd.DataFrame({'col1':result[::-1]})\n</code>\n\n", "metadata": {"problem_id": 81, "library_problem_id": 81, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 76}}
{"id": 82, "code": "```python\ndf['A'] = df['A'].replace(0, pd.NA).fillna(method='ffill')\n```\n\n</code>", "metadata": {"problem_id": 82, "library_problem_id": 82, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 82}}
{"id": 83, "code": "```python\ndf = df.replace(0, pd.NA).fillna(method='bfill')\n```\n\n</code>", "metadata": {"problem_id": 83, "library_problem_id": 83, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 82}}
{"id": 84, "code": "```python\nimport numpy as np\n\ndf['ffill'] = df['A'].replace(0, np.nan).fillna(method='ffill')\ndf['bfill'] = df['A'].replace(0, np.nan).fillna(method='bfill')\ndf['A'] = np.maximum(df['ffill'], df['bfill'])\ndf = df[['A']]\n```\n\n</code>", "metadata": {"problem_id": 84, "library_problem_id": 84, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 82}}
{"id": 85, "code": "```python\n    df['number'] = df['duration'].str.extract(r'(\\d+)').astype('int')\n    df['time'] = df['duration'].str.extract(r'(\\s?\\w+)$').str.strip()\n    time_to_days = {'year': 365, 'month': 30, 'week': 7, 'day': 1}\n    df['time_days'] = df['time'].map(time_to_days)\n</code>", "metadata": {"problem_id": 85, "library_problem_id": 85, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 85}}
{"id": 86, "code": "```python\ndf['time'] = df['duration'].str.extract(r'([a-zA-Z]+)')\ndf['number'] = df['duration'].str.extract(r'(\\d+)').astype(int)\n\ntime_map = {'year': 365, 'month': 30, 'week': 7, 'day': 1}\ndf['time_day'] = df['time'].map(time_map)\n```\n\n</code>", "metadata": {"problem_id": 86, "library_problem_id": 86, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 85}}
{"id": 87, "code": "```python\n    df['number'] = df['duration'].str.extract(r'(\\d+)')\n    df['time'] = df['duration'].str.extract(r'([a-zA-Z]+)')\n    time_map = {'year': 365, 'month': 30, 'week': 7, 'day': 1}\n    df['time_days'] = df['time'].map(time_map)\n    return df\n```", "metadata": {"problem_id": 87, "library_problem_id": 87, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 85}}
{"id": 88, "code": "```python\ndf['time'] = df['duration'].str.extract(r'([a-zA-Z]+)')\ndf['number'] = df['duration'].str.extract(r'(\\d+)')\ntime_map = {'year': 365, 'month': 30, 'week': 7, 'day': 1}\ndf['time_day'] = df['time'].map(time_map)\ndf['time_day'] = pd.to_numeric(df['time_day'])\ndf['number'] = pd.to_numeric(df['number'])\ndf['time_day'] = df['time_day'] * df['number']\n```\n\n</code>", "metadata": {"problem_id": 88, "library_problem_id": 88, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 85}}
{"id": 89, "code": "```python\ncomparison_results = []\nfor column in columns_check_list:\n    comparison_results.append(df1[column] != df2[column])\ncombined_result = comparison_results[0]\nfor i in range(1, len(comparison_results)):\n    combined_result = combined_result | comparison_results[i]\nresult = combined_result.to_list()\n```\n\n</code>", "metadata": {"problem_id": 89, "library_problem_id": 89, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 89}}
{"id": 90, "code": "```python\nresult = (df1[columns_check_list] == df2[columns_check_list]).all(axis=1).tolist()\n```\n\n</code>", "metadata": {"problem_id": 90, "library_problem_id": 90, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 89}}
{"id": 91, "code": "```python\ndf = df.copy()\ndf.index = df.index.set_levels(pd.to_datetime(df.index.levels[1]), level=1)\n```</code>", "metadata": {"problem_id": 91, "library_problem_id": 91, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 91}}
{"id": 92, "code": "```python\ndf = df.copy()\ndf.index = df.index.set_levels(pd.to_datetime(df.index.levels[1]), level=1)\n```</code>", "metadata": {"problem_id": 92, "library_problem_id": 92, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 91}}
{"id": 93, "code": "```python\n    dates = pd.to_datetime(df.index.get_level_values('date'))\n    x = df['x'].values\n    y = df['y'].values\n    return [[d, xi, yi] for d, xi, yi in zip(dates, x, y)]\n```", "metadata": {"problem_id": 93, "library_problem_id": 93, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 91}}
{"id": 94, "code": "```python\n    df.index = df.index.set_levels(pd.to_datetime(df.index.levels[0]), level=0)\n    df = df.swaplevel(0, 1)\n    return df\n### END SOLUTION\n```", "metadata": {"problem_id": 94, "library_problem_id": 94, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 91}}
{"id": 95, "code": "```python\ndf = pd.melt(df, id_vars=['Country', 'Variable'], var_name='year', value_name='value')\ndf = df.pivot(index=['Country', 'year'], columns='Variable', values='value')\ndf = df.reset_index()\ndf.columns.name = None\n```\n\n</code>", "metadata": {"problem_id": 95, "library_problem_id": 95, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 95}}
{"id": 96, "code": "```python\ndf = pd.melt(df, id_vars=['Country', 'Variable'], var_name='year', value_name='value')\ndf['year'] = pd.to_numeric(df['year'])\ndf = df.pivot(index=['Country', 'year'], columns='Variable', values='value').reset_index()\ndf = df.sort_values(by=['Country', 'year'], ascending=[True, False])\ndf = df.reset_index(drop=True)\n```\n\n</code>", "metadata": {"problem_id": 96, "library_problem_id": 96, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 95}}
{"id": 97, "code": "```python\nvalue_cols = [col for col in df.columns if col.startswith('Value')]\ndf = df[df[value_cols].abs().lt(1).all(axis=1)]\n```</code>", "metadata": {"problem_id": 97, "library_problem_id": 97, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 97}}
{"id": 98, "code": "```python\nvalue_cols = [col for col in df.columns if col.startswith('Value')]\nabs_values = df[value_cols].abs()\nmask = (abs_values > 1).any(axis=1)\ndf = df[mask]\n```\n\n</code>", "metadata": {"problem_id": 98, "library_problem_id": 98, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 97}}
{"id": 99, "code": "```python\nvalue_cols = [col for col in df.columns if col.startswith('Value_')]\nmask = (df[value_cols].abs() > 1).any(axis=1)\ndf = df[mask]\ndf = df.rename(columns={col: col.replace('Value_', '') for col in value_cols})\n```\n\n</code>", "metadata": {"problem_id": 99, "library_problem_id": 99, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 97}}
{"id": 100, "code": "```python\nfor col in df.select_dtypes(include='object').columns:\n    df[col] = df[col].str.replace('&AMP;', '&', regex=False)\n</code>\n", "metadata": {"problem_id": 100, "library_problem_id": 100, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 100}}
{"id": 101, "code": "```python\ndf = df.applymap(lambda x: x.replace('&LT;', '<') if isinstance(x, str) else x)\n</code>\n\n</code>", "metadata": {"problem_id": 101, "library_problem_id": 101, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 100}}
{"id": 102, "code": "```python\n    string_columns = df.select_dtypes(include='object').columns\n    for col in string_columns:\n        df[col] = df[col].str.replace('&AMP;', '&', regex=False)\n    return df\n```", "metadata": {"problem_id": 102, "library_problem_id": 102, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 100}}
{"id": 103, "code": "```python\ndef replace_entities(text):\n    text = text.replace('&AMP;', '&')\n    text = text.replace('&LT;', '<')\n    text = text.replace('&GT;', '>')\n    return text\n\nfor col in df.select_dtypes(include='object'):\n    df[col] = df[col].apply(replace_entities)\n</code>\n\n", "metadata": {"problem_id": 103, "library_problem_id": 103, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 100}}
{"id": 104, "code": "```python\nfor col in df.columns:\n    if df[col].dtype == 'object':\n        df[col] = df[col].str.replace('&AMP;', '&')\n\nif 'A' in df.columns:\n    df['A'] = df['A'].replace('1 & 0', '1 & 0 = 0')\n</code>\n\n</code>", "metadata": {"problem_id": 104, "library_problem_id": 104, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 100}}
{"id": 105, "code": "```python\ndef split_name(name):\n    parts = name.split()\n    if len(parts) == 2:\n        first_name = parts[0]\n        last_name = parts[1]\n    else:\n        first_name = name\n        last_name = None\n    return first_name, last_name\n\ndf[['first_name', 'last_name']] = df['name'].apply(lambda x: pd.Series(split_name(x)))\n```\n\n</code>", "metadata": {"problem_id": 105, "library_problem_id": 105, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 105}}
{"id": 106, "code": "```python\ndef split_name(name):\n    parts = name.split()\n    if len(parts) == 2:\n        return parts[0], parts[1]\n    else:\n        return name, None\n\ndf[['1_name', '2_name']] = df['name'].apply(lambda x: pd.Series(split_name(x)))\n```\n\n</code>", "metadata": {"problem_id": 106, "library_problem_id": 106, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 105}}
{"id": 107, "code": "```python\ndef split_name(name):\n    parts = name.split()\n    if len(parts) > 2:\n        first_name = parts[0]\n        middle_name = ' '.join(parts[1:-1])\n        last_name = parts[-1]\n        return pd.Series([first_name, middle_name, last_name])\n    elif len(parts) == 2:\n        return pd.Series([parts[0], pd.NA, parts[1]])\n    else:\n        return pd.Series([name, pd.NA, pd.NA])\n\ndf[['first_name', 'middle_name', 'last_name']] = df['name'].apply(split_name)\n```\n\n</code>", "metadata": {"problem_id": 107, "library_problem_id": 107, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 105}}
{"id": 108, "code": "```python\nresult = pd.merge(df2, df1, on='Timestamp', how='left')\n```</code>", "metadata": {"problem_id": 108, "library_problem_id": 108, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 108}}
{"id": 109, "code": "```python\nresult = pd.merge(df1, df2, on='Timestamp', how='left')\nresult = result.dropna(subset=['stuff'])\nresult['stuff'] = result['stuff'].astype(int)\n```", "metadata": {"problem_id": 109, "library_problem_id": 109, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 108}}
{"id": 110, "code": "```python\ndef calculate_state(row):\n    if row['col2'] <= 50 and row['col3'] <= 50:\n        return row['col1']\n    else:\n        return max(row['col1'], row['col2'], row['col3'])\n\ndf['state'] = df.apply(calculate_state, axis=1)\n```\n\n</code>", "metadata": {"problem_id": 110, "library_problem_id": 110, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 110}}
{"id": 111, "code": "```python\ndf['state'] = df.apply(lambda row: row['col1'] if (row['col2'] > 50 and row['col3'] > 50) else row['col1'] + row['col2'] + row['col3'], axis=1)\n```\n\n</code>", "metadata": {"problem_id": 111, "library_problem_id": 111, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 110}}
{"id": 112, "code": "```python\nerror_values = []\nfor value in df['Field1']:\n    if not isinstance(value, int):\n        if isinstance(value, float) and value.is_integer():\n            continue\n        error_values.append(value)\ndf = error_values\n```\n\n</code>", "metadata": {"problem_id": 112, "library_problem_id": 112, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 112}}
{"id": 113, "code": "```python\nintegers = []\nfor value in df['Field1']:\n    if isinstance(value, int):\n        integers.append(value)\ndf = integers\n```\n\n</code>", "metadata": {"problem_id": 113, "library_problem_id": 113, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 112}}
{"id": 114, "code": "```python\n    error_values = []\n    for index, row in df.iterrows():\n        value = row['Field1']\n        if not isinstance(value, int):\n            error_values.append(value)\n    return error_values\n### END SOLUTION\n</code>\n", "metadata": {"problem_id": 114, "library_problem_id": 114, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 112}}
{"id": 115, "code": "```python\ndf['row_total'] = df[['val1', 'val2', 'val3', 'val4']].sum(axis=1)\n\nfor col in ['val1', 'val2', 'val3', 'val4']:\n    df[col] = df[col] / df['row_total']\n\ndf = df.drop('row_total', axis=1)\n```\n\n</code>", "metadata": {"problem_id": 115, "library_problem_id": 115, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 115}}
{"id": 116, "code": "```python\ndf = df.set_index('cat')\ndf = df / df.sum()\ndf = df.reset_index()\n</code>", "metadata": {"problem_id": 116, "library_problem_id": 116, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 115}}
{"id": 117, "code": "```python\nresult = df.loc[test]\n```", "metadata": {"problem_id": 117, "library_problem_id": 117, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 117}}
{"id": 118, "code": "```python\nresult = df.loc[test]\n</code>", "metadata": {"problem_id": 118, "library_problem_id": 118, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 117}}
{"id": 119, "code": "```python\nresult = df.drop(test)\n```</code>", "metadata": {"problem_id": 119, "library_problem_id": 119, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 117}}
{"id": 120, "code": "```python\n    from collections import OrderedDict\n    test_unique = list(OrderedDict.fromkeys(test))\n    return df.loc[test_unique]\n```", "metadata": {"problem_id": 120, "library_problem_id": 120, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 117}}
{"id": 121, "code": "```python\nfrom scipy.spatial import distance\n\ndef nearest_neighbor(df_group):\n    cars = df_group['car'].values\n    coords = df_group[['x', 'y']].values\n    \n    distances = distance.cdist(coords, coords)\n    \n    nearest_neighbors = []\n    nearest_distances = []\n    \n    for i in range(len(cars)):\n        distances[i, i] = float('inf')\n        nearest_index = distances[i].argmin()\n        nearest_neighbors.append(cars[nearest_index])\n        nearest_distances.append(distances[i, nearest_index])\n        \n    df_nearest = pd.DataFrame({\n        'car': cars,\n        'nearest_neighbour': nearest_neighbors,\n        'euclidean_distance': nearest_distances\n    })\n    return df_nearest\n\ndf2 = df.groupby('time').apply(nearest_neighbor).reset_index(drop=True)\ndf = df2.groupby('time')['euclidean_distance'].mean().reset_index(name='average_distance')\n```\n\n</code>", "metadata": {"problem_id": 121, "library_problem_id": 121, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 121}}
{"id": 122, "code": "```python\nfrom scipy.spatial.distance import cdist\nimport numpy as np\n\ndef calculate_distances(group):\n    points = group[['x', 'y']].to_numpy()\n    cars = group['car'].to_numpy()\n    distances = cdist(points, points, metric='euclidean')\n    \n    farthest_neighbors = []\n    euclidean_distances = []\n    \n    for i in range(len(cars)):\n        distances_i = distances[i]\n        distances_i[i] = -1  # Exclude self from being the farthest neighbor\n        farthest_neighbor_index = np.argmax(distances_i)\n        farthest_neighbor = cars[farthest_neighbor_index]\n        euclidean_distance = distances_i[farthest_neighbor_index]\n        \n        farthest_neighbors.append(farthest_neighbor)\n        euclidean_distances.append(euclidean_distance)\n    \n    group['farmost_neighbour'] = farthest_neighbors\n    group['euclidean_distance'] = euclidean_distances\n    return group[['car', 'farmost_neighbour', 'euclidean_distance']]\n\ndf2 = df.groupby('time').apply(calculate_distances).reset_index()\ndf = df2.groupby('time')['euclidean_distance'].mean()\n```\n\n</code>", "metadata": {"problem_id": 122, "library_problem_id": 122, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 121}}
{"id": 123, "code": "```python\ndef concatenate_row(row):\n    row = row.dropna()\n    return \",\".join(row)\n\ndf[\"keywords_all\"] = df.apply(concatenate_row, axis=1)\n```\n\n</code>", "metadata": {"problem_id": 123, "library_problem_id": 123, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 123}}
{"id": 124, "code": "```python\ndef concatenate_keywords(row):\n    row = row.dropna().astype(str)\n    return '-'.join(row)\n\ndf[\"keywords_all\"] = df.apply(concatenate_keywords, axis=1)\n```\n\n</code>", "metadata": {"problem_id": 124, "library_problem_id": 124, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 123}}
{"id": 125, "code": "```python\nkeyword_cols = ['keywords_0', 'keywords_1', 'keywords_2', 'keywords_3']\n\ndef concatenate_keywords(row):\n    keywords = []\n    for col in keyword_cols:\n        keyword = row[col]\n        if pd.notna(keyword):\n            keywords.append(keyword)\n    return '-'.join(keywords)\n\ndf['keywords_all'] = df.apply(concatenate_keywords, axis=1)\n```\n\n</code>", "metadata": {"problem_id": 125, "library_problem_id": 125, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 123}}
{"id": 126, "code": "```python\nkeyword_cols = ['keywords_0', 'keywords_1', 'keywords_2', 'keywords_3']\n\ndef concat_keywords(row):\n    keywords = [row[col] for col in keyword_cols if pd.notna(row[col])]\n    return '-'.join(keywords[::-1])\n\ndf['keywords_all'] = df.apply(concat_keywords, axis=1)\n```\n\n</code>", "metadata": {"problem_id": 126, "library_problem_id": 126, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 123}}
{"id": 127, "code": "```python\nsampled_df = df.sample(frac=0.2, random_state=0)\nsampled_index = sampled_df.index\ndf.loc[sampled_index, 'Quantity'] = 0\n```\n\n</code>", "metadata": {"problem_id": 127, "library_problem_id": 127, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 127}}
{"id": 128, "code": "```python\nsampled_df = df.sample(frac=0.2, random_state=0)\nsampled_indices = sampled_df.index\ndf.loc[sampled_indices, 'ProductId'] = 0\n```\n\n</code>", "metadata": {"problem_id": 128, "library_problem_id": 128, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 127}}
{"id": 129, "code": "```python\ndef sample_and_modify(group):\n    n = int(len(group) * 0.2)\n    sampled_indices = group.sample(n=n, random_state=0).index\n    group.loc[sampled_indices, 'Quantity'] = 0\n    return group\n\ndf = df.groupby('UserId', group_keys=False).apply(sample_and_modify)\n</code>", "metadata": {"problem_id": 129, "library_problem_id": 129, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 127}}
{"id": 130, "code": "```python\nduplicate_bool = df.duplicated(subset=['col1','col2'], keep='first')\nduplicate = df.loc[duplicate_bool == True]\n\nfirst_occurrence = {}\nfor index, row in df.iterrows():\n    key = (row['col1'], row['col2'])\n    if key not in first_occurrence:\n        first_occurrence[key] = index\n\nduplicate['index_original'] = duplicate.apply(lambda row: first_occurrence[(row['col1'], row['col2'])], axis=1)\nresult = duplicate\n```\n\n</code>", "metadata": {"problem_id": 130, "library_problem_id": 130, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 130}}
{"id": 131, "code": "```python\nduplicate_bool = df.duplicated(subset=['col1','col2'], keep='last')\nduplicate = df.loc[duplicate_bool == True]\nindex_map = {}\nfor index, row in duplicate.iterrows():\n    index_map[index] = df[(df['col1'] == row['col1']) & (df['col2'] == row['col2'])].index[-1]\nduplicate['index_original'] = duplicate.index.map(index_map)\nresult = duplicate\n```\n\n</code>", "metadata": {"problem_id": 131, "library_problem_id": 131, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 130}}
{"id": 132, "code": "```python\n    duplicate_bool = df.duplicated(subset=['col1','col2'], keep='first')\n    duplicate = df.loc[duplicate_bool == True]\n    first_occurrence = {}\n    for index, row in df.iterrows():\n        key = (row['col1'], row['col2'])\n        if key not in first_occurrence:\n            first_occurrence[key] = index\n    duplicate['index_original'] = duplicate.apply(lambda row: first_occurrence[(row['col1'], row['col2'])], axis=1)\n    return duplicate\n```</code>", "metadata": {"problem_id": 132, "library_problem_id": 132, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 130}}
{"id": 133, "code": "```python\nduplicate_bool = df.duplicated(subset=['col1','col2', '3col'], keep='first')\nduplicate = df.loc[duplicate_bool == True]\nfirst_occurrences = df.drop_duplicates(subset=['col1','col2', '3col'], keep='first').set_index(['col1','col2', '3col']).index\nindex_map = {row: df[(df['col1'] == row[0]) & (df['col2'] == row[1]) & (df['3col'] == row[2])].index[0] for row in first_occurrences}\nduplicate['index_original'] = duplicate.apply(lambda row: index_map[(row['col1'], row['col2'], row['3col'])], axis=1)\nresult = duplicate\n```\n\n</code>", "metadata": {"problem_id": 133, "library_problem_id": 133, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 130}}
{"id": 134, "code": "```python\nduplicate_bool = df.duplicated(subset=['col1','col2'], keep='last')\nduplicate = df.loc[duplicate_bool == True]\nlast_indices = df.groupby(['col1', 'col2']).tail(1).set_index(['col1', 'col2']).index\nindex_map = {idx: df[(df['col1'] == idx[0]) & (df['col2'] == idx[1])].index[-1] for idx in last_indices}\nduplicate['index_original'] = duplicate.apply(lambda row: index_map[(row['col1'], row['col2'])], axis=1)\nresult = duplicate\n```\n\n</code>", "metadata": {"problem_id": 134, "library_problem_id": 134, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 130}}
{"id": 135, "code": "```python\nmax_count = df.groupby(['Sp', 'Mt'])['count'].transform('max')\nresult = df[df['count'] == max_count]\n```</code>", "metadata": {"problem_id": 135, "library_problem_id": 135, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 135}}
{"id": 136, "code": "```python\nmax_count = df.groupby(['Sp', 'Mt'])['count'].transform('max')\nresult = df[df['count'] == max_count]\n```\n\n</code>", "metadata": {"problem_id": 136, "library_problem_id": 136, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 135}}
{"id": 137, "code": "```python\ngrouped = df.groupby(['Sp', 'Mt'])\ndf['min_count'] = grouped['count'].transform('min')\nresult = df[df['count'] == df['min_count']][['Sp', 'Mt', 'Value', 'count']]\n```\n\n</code>", "metadata": {"problem_id": 137, "library_problem_id": 137, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 135}}
{"id": 138, "code": "```python\nmax_count = df.groupby(['Sp', 'Value'])['count'].transform('max')\nresult = df[df['count'] == max_count]\n</code>", "metadata": {"problem_id": 138, "library_problem_id": 138, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 135}}
{"id": 139, "code": "```python\nresult = df.query(\"Category in @filter_list\")\n</code>\n\n", "metadata": {"problem_id": 139, "library_problem_id": 139, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 139}}
{"id": 140, "code": "```python\nresult = df.query(\"Category not in @filter_list\")\n</code>\n\n</code>", "metadata": {"problem_id": 140, "library_problem_id": 140, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 139}}
{"id": 141, "code": "```python\nvalue_vars = list(zip(df.columns.get_level_values(0), df.columns.get_level_values(1), df.columns.get_level_values(2)))\nresult = pd.melt(df, value_vars=value_vars)\n```\n\n</code>", "metadata": {"problem_id": 141, "library_problem_id": 141, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 141}}
{"id": 142, "code": "```python\nvalue_vars = list(zip(*df.columns))\nresult = pd.melt(df, value_vars=value_vars, var_name=['variable_0', 'variable_1', 'variable_2'])\n```\n\n</code>", "metadata": {"problem_id": 142, "library_problem_id": 142, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 141}}
{"id": 143, "code": "```python\ndf['cumsum'] = df.groupby('id')['val'].cumsum()\n```</code>", "metadata": {"problem_id": 143, "library_problem_id": 143, "library": "Pandas", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 143}}
{"id": 144, "code": "```python\ndf['cumsum'] = df.groupby('id')['val'].cumsum()\n```</code>", "metadata": {"problem_id": 144, "library_problem_id": 144, "library": "Pandas", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 143}}
{"id": 145, "code": "```python\ndf['cumsum'] = df.groupby('id')['val'].cumsum()\n```</code>", "metadata": {"problem_id": 145, "library_problem_id": 145, "library": "Pandas", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 143}}
{"id": 146, "code": "```python\ndf['cummax'] = df.groupby('id')['val'].cummax()\n```</code>", "metadata": {"problem_id": 146, "library_problem_id": 146, "library": "Pandas", "test_case_cnt": 3, "perturbation_type": "Semantic", "perturbation_origin_id": 143}}
{"id": 147, "code": "```python\ndf['cumsum'] = df.groupby('id')['val'].cumsum()\ndf['cumsum'] = df['cumsum'].clip(lower=0)\n```</code>", "metadata": {"problem_id": 147, "library_problem_id": 147, "library": "Pandas", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 143}}
{"id": 148, "code": "```python\ndef safe_sum(series):\n    if series.isnull().any():\n        return np.nan\n    else:\n        return series.sum()\n\nresult = df.groupby('l')['v'].agg(safe_sum)\n```\n\n</code>", "metadata": {"problem_id": 148, "library_problem_id": 148, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 148}}
{"id": 149, "code": "```python\ndef safe_sum(s):\n    if s.isna().any():\n        return np.nan\n    else:\n        return s.sum()\n\nresult = df.groupby('r')['v'].agg(safe_sum)\n```\n\n</code>", "metadata": {"problem_id": 149, "library_problem_id": 149, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 148}}
{"id": 150, "code": "```python\ndef sum_skipna(series):\n    if series.isnull().any():\n        return np.nan\n    else:\n        return series.sum()\n\nresult = df.groupby('l')['v'].apply(sum_skipna).reset_index()\n```\n\n</code>", "metadata": {"problem_id": 150, "library_problem_id": 150, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 148}}
{"id": 151, "code": "```python\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'Column1': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n    'Column2': [4, 3, 6, 8, 3, 4, 1, 4, 3],\n    'Column3': [7, 3, 3, 1, 2, 2, 3, 2, 7],\n    'Column4': [9, 8, 7, 6, 5, 4, 3, 2, 1],\n    'Column5': [1, 1, 1, 1, 1, 1, 1, 1, 1]})\n\ndef determine_relationship(df, col_a, col_b):\n    unique_a = df[col_a].nunique()\n    unique_b = df[col_b].nunique()\n    unique_pairs = df.groupby([col_a, col_b]).size().reset_index().shape[0]\n\n    if unique_a == unique_b == unique_pairs:\n        return \"one-to-one\"\n    elif unique_a == unique_pairs and unique_a < unique_b:\n        return \"one-to-many\"\n    elif unique_b == unique_pairs and unique_b < unique_a:\n        return \"many-to-one\"\n    else:\n        return \"many-to-many\"\n\nresults = []\ncolumns = df.columns\n\nfor col_a in columns:\n    for col_b in columns:\n        if col_a != col_b:\n            relationship = determine_relationship(df, col_a, col_b)\n            results.append(f\"{col_a} {col_b} {relationship}\")\n```\n\n</code>", "metadata": {"problem_id": 151, "library_problem_id": 151, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 151}}
{"id": 152, "code": "```python\nresult = []\nfor col1 in df.columns:\n    for col2 in df.columns:\n        nunique_col1 = df[col1].nunique()\n        nunique_col2 = df[col2].nunique()\n        nunique_combinations = df.groupby([col1, col2]).ngroups\n        \n        if nunique_col1 == nunique_combinations and nunique_col2 == nunique_combinations:\n            relationship = \"one-2-one\"\n        elif nunique_col1 == nunique_combinations and nunique_col2 != nunique_combinations:\n            relationship = \"one-2-many\"\n        elif nunique_col1 != nunique_combinations and nunique_col2 == nunique_combinations:\n            relationship = \"many-2-one\"\n        else:\n            relationship = \"many-2-many\"\n            \n        result.append(f\"{col1} {col2} {relationship}\")\n```\n\n</code>", "metadata": {"problem_id": 152, "library_problem_id": 152, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 151}}
{"id": 153, "code": "```python\nresult = pd.DataFrame(index=df.columns, columns=df.columns)\n\nfor col1 in df.columns:\n    for col2 in df.columns:\n        if col1 == col2:\n            continue\n\n        unique_col1 = df[col1].nunique()\n        unique_col2 = df[col2].nunique()\n        total_len = len(df)\n\n        if unique_col1 == total_len and unique_col2 == total_len:\n            if df.groupby(col1)[col2].nunique().max() == 1 and df.groupby(col2)[col1].nunique().max() == 1:\n                result.loc[col1, col2] = 'one-to-one'\n            else:\n                result.loc[col1, col2] = 'many-to-many'\n\n        elif unique_col1 == total_len and unique_col2 < total_len:\n            if df.groupby(col1)[col2].nunique().max() == 1:\n                result.loc[col1, col2] = 'one-to-one'\n            else:\n                result.loc[col1, col2] = 'one-to-many'\n\n        elif unique_col1 < total_len and unique_col2 == total_len:\n             if df.groupby(col2)[col1].nunique().max() == 1:\n                result.loc[col1, col2] = 'one-to-one'\n             else:\n                result.loc[col1, col2] = 'many-to-one'\n        else:\n            result.loc[col1, col2] = 'many-to-many'\n```\n\n</code>", "metadata": {"problem_id": 153, "library_problem_id": 153, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 151}}
{"id": 154, "code": "```python\nimport numpy as np\n\ndef column_relationship(df):\n    cols = df.columns\n    relationship_df = pd.DataFrame(index=cols, columns=cols)\n\n    for col1 in cols:\n        for col2 in cols:\n            if col1 == col2:\n                relationship_df.loc[col1, col2] = np.nan\n            else:\n                unique_col1 = df[col1].nunique()\n                unique_col2 = df[col2].nunique()\n                unique_pairs = df.groupby([col1, col2]).size().shape[0]\n\n                if unique_col1 == unique_col2 == unique_pairs:\n                    relationship_df.loc[col1, col2] = \"one-2-one\"\n                elif unique_col1 == unique_pairs:\n                    relationship_df.loc[col1, col2] = \"one-2-many\"\n                elif unique_col2 == unique_pairs:\n                    relationship_df.loc[col1, col2] = \"many-2-one\"\n                else:\n                    relationship_df.loc[col1, col2] = \"many-2-many\"\n    return relationship_df\n\nresult = column_relationship(df)\n```\n\n</code>", "metadata": {"problem_id": 154, "library_problem_id": 154, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 151}}
{"id": 155, "code": "```python\ndef clean_data(df):\n    df_cleaned = df.copy()\n    for col in ['firstname', 'lastname', 'email']:\n        df_cleaned[col] = df_cleaned[col].str.lower().str.replace(\" \", \"\")\n    return df_cleaned\n\ndf_cleaned = clean_data(df)\n\ngrouped = df.groupby(df_cleaned.columns.tolist())\n\nresult = pd.DataFrame()\nfor name, group in grouped:\n    if group['bank'].notna().any():\n        result = pd.concat([result, group[group['bank'].notna()].head(1)])\n    else:\n        result = pd.concat([result, group.head(1)])\n\n```</code>", "metadata": {"problem_id": 155, "library_problem_id": 155, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 155}}
{"id": 156, "code": "```python\ndef clean_and_convert(series):\n    series = series.fillna('')\n    series = series.astype(str)\n    series = series.str.replace(',', '')\n    return pd.to_numeric(series, errors='coerce')\n\ndf = pd.DataFrame({\n    'Revenue': ['24.73', '18.73', '17.56', '29.14', '22.67', '95.85', '84.58', '58.33', '29.63', '243.91', '230.77', '216.58', '206.23', '192.82', '741.15', '556.28', '414.51', '308.82', '2,144.78', '2,036.62', '1,916.60', '1,809.40', '1,711.97', '6,667.22', '5,373.59', '4,071.00', '3,050.20', '-0.06', '-1.88', '', '-0.13', '', '-0.14', '0.07', '0', '0', '-0.8', '-1.12', '1.32', '-0.05', '-0.34', '-1.37', '-1.9', '-1.48', '0.1', '41.98', '35', '-11.66', '27.09', '-3.44', '14.13', '-18.69', '-4.87', '-5.7'],\n    'Other, Net': ['-0.06', '-1.88', '', '-0.13', '', '-0.14', '0.07', '0', '0', '-0.8', '-1.12', '1.32', '-0.05', '-0.34', '-1.37', '-1.9', '-1.48', '0.1', '41.98', '35', '-11.66', '27.09', '-3.44', '14.13', '-18.69', '-4.87', '-5.7', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n})\n\ndf['Revenue'] = clean_and_convert(df['Revenue'])\ndf['Other, Net'] = clean_and_convert(df['Other, Net'])\n\nresult = df\n```</code>", "metadata": {"problem_id": 156, "library_problem_id": 156, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 156}}
{"id": 157, "code": "```python\nresult = df.groupby(df.apply(lambda row: \"Has Family\" if (row['SibSp'] > 0) | (row['Parch'] > 0) else \"No Family\", axis=1))['Survived'].mean()\n</code>\n\n", "metadata": {"problem_id": 157, "library_problem_id": 157, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 157}}
{"id": 158, "code": "```python\ndf['FamilyGroup'] = df.apply(lambda row: 'Has Family' if (row['Survived'] > 0) | (row['Parch'] > 0) else 'No Family', axis=1)\nresult = df.groupby('FamilyGroup')['SibSp'].mean()\n</code>\n\n", "metadata": {"problem_id": 158, "library_problem_id": 158, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 157}}
{"id": 159, "code": "```python\ndef categorize_family(row):\n    if (row['SibSp'] == 1) & (row['Parch'] == 1):\n        return \"Has Family\"\n    elif (row['SibSp'] == 0) & (row['Parch'] == 0):\n        return \"No Family\"\n    elif (row['SibSp'] == 0) & (row['Parch'] == 1):\n        return \"New Family\"\n    elif (row['SibSp'] == 1) & (row['Parch'] == 0):\n        return \"Old Family\"\n\ndf['FamilyGroup'] = df.apply(categorize_family, axis=1)\n\nresult = df.groupby('FamilyGroup')['Survived'].mean()\n</code>\n\n", "metadata": {"problem_id": 159, "library_problem_id": 159, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 157}}
{"id": 160, "code": "```python\nresult = df.groupby('cokey').apply(lambda x: x.sort_values('A'))\n```", "metadata": {"problem_id": 160, "library_problem_id": 160, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 160}}
{"id": 161, "code": "```python\nresult = df.groupby('cokey').apply(lambda x: x.sort_values('A', ascending=False))\n```\n\n</code>", "metadata": {"problem_id": 161, "library_problem_id": 161, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 160}}
{"id": 162, "code": "```python\ndf.columns = pd.MultiIndex.from_tuples(df.columns)\n```</code>", "metadata": {"problem_id": 162, "library_problem_id": 162, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 162}}
{"id": 163, "code": "```python\ndf.columns = pd.MultiIndex.from_tuples(df.columns)\ndf.columns.names = ['Caps', 'Middle', 'Lower']\n```</code>", "metadata": {"problem_id": 163, "library_problem_id": 163, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 162}}
{"id": 164, "code": "```python\ncaps = pd.unique([c[0] for c in df.columns])\nmiddle = pd.unique([c[1] for c in df.columns])\nlower = pd.unique([c[2] for c in df.columns])\n\nnew_cols = pd.MultiIndex.from_tuples(df.columns)\ndf.columns = new_cols\n```\n\n</code>", "metadata": {"problem_id": 164, "library_problem_id": 164, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 162}}
{"id": 165, "code": "```python\nresult = pd.DataFrame(list(zip(someTuple[0], someTuple[1])), columns=['birdType', 'birdCount'])\n</code>\n", "metadata": {"problem_id": 165, "library_problem_id": 165, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 165}}
{"id": 166, "code": "```python\nresult = df.groupby('a')['b'].agg(['mean', 'std'])\n```\n\n</code>", "metadata": {"problem_id": 166, "library_problem_id": 166, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 166}}
{"id": 167, "code": "```python\nresult = df.groupby('b')['a'].agg(['mean', 'std'])\n```\n\n</code>", "metadata": {"problem_id": 167, "library_problem_id": 167, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 166}}
{"id": 168, "code": "```python\nimport numpy as np\n\ndef softmax(series):\n    e = np.exp(series)\n    return e / e.sum()\n\ndef min_max_normalize(series):\n    min_val = series.min()\n    max_val = series.max()\n    return (series - min_val) / (max_val - min_val)\n\ndf['softmax'] = df.groupby('a')['b'].transform(softmax)\ndf['min-max'] = df.groupby('a')['b'].transform(min_max_normalize)\n</code>\n\n</code>", "metadata": {"problem_id": 168, "library_problem_id": 168, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 166}}
{"id": 169, "code": "```python\n    rows_to_drop = df[df.apply(lambda row: row.sum(), axis=1) == 0].index\n    cols_to_drop = df.columns[df.apply(lambda col: col.sum(), axis=0) == 0]\n    df = df.drop(rows_to_drop)\n    df = df.drop(cols_to_drop, axis=1)\n    result = df\n</code>", "metadata": {"problem_id": 169, "library_problem_id": 169, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 169}}
{"id": 170, "code": "```python\n    row_sums = df.sum(axis=1)\n    col_sums = df.sum(axis=0)\n    rows_to_keep = row_sums != 0\n    cols_to_keep = col_sums != 0\n    result = df.loc[rows_to_keep, cols_to_keep]\n```\n\n</code>", "metadata": {"problem_id": 170, "library_problem_id": 170, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 169}}
{"id": 171, "code": "```python\ncols_to_drop = df.columns[(df == 2).any()]\nrows_to_drop = df.index[(df == 2).any(axis=1)]\nresult = df.drop(cols_to_drop, axis=1).drop(rows_to_drop, axis=0)\n```\n\n</code>", "metadata": {"problem_id": 171, "library_problem_id": 171, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 169}}
{"id": 172, "code": "```python\n    rows_with_max = df[df.max(axis=1) == 2].index\n    cols_with_max = df.columns[df.max(axis=0) == 2]\n\n    df.loc[rows_with_max, :] = 0\n    df.loc[:, cols_with_max] = 0\n    result = df\n```\n\n</code>", "metadata": {"problem_id": 172, "library_problem_id": 172, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 169}}
{"id": 173, "code": "```python\nresult = s.sort_values().sort_index()\n```</code>", "metadata": {"problem_id": 173, "library_problem_id": 173, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 173}}
{"id": 174, "code": "```python\ndf = s.sort_values().reset_index()\ndf.columns = ['index', '1']\ndf = df.sort_values(by=['1', 'index'])\n</code>", "metadata": {"problem_id": 174, "library_problem_id": 174, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 173}}
{"id": 175, "code": "```python\nimport pandas as pd\n\ndf = pd.DataFrame({'A': [1, 2, 's', 3, 'b'],\n                   'B': ['green', 'red', 'blue', 'yellow', 'black']})\n\nmask = pd.to_numeric(df['A'], errors='coerce').notna()\nresult = df[mask]\n```\n\n</code>", "metadata": {"problem_id": 175, "library_problem_id": 175, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 175}}
{"id": 176, "code": "```python\nresult = df[df['A'].apply(lambda x: isinstance(x, str))]\n</code>\n", "metadata": {"problem_id": 176, "library_problem_id": 176, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 175}}
{"id": 177, "code": "```python\nmax_count = df.groupby(['Sp', 'Mt'])['count'].transform('max')\nresult = df[df['count'] == max_count]\n```\n\n</code>", "metadata": {"problem_id": 177, "library_problem_id": 177, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 177}}
{"id": 178, "code": "```python\ngrouped = df.groupby(['Sp', 'Mt'])\nmax_counts = grouped['count'].transform('max')\nresult = df[df['count'] == max_counts]\n```</code>", "metadata": {"problem_id": 178, "library_problem_id": 178, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 177}}
{"id": 179, "code": "```python\ngrouped = df.groupby(['Sp', 'Mt'])\ndf['min_count'] = grouped['count'].transform('min')\nresult = df[df['count'] == df['min_count']][['Sp', 'Mt', 'Value', 'count']]\n```</code>", "metadata": {"problem_id": 179, "library_problem_id": 179, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 177}}
{"id": 180, "code": "```python\nmax_count = df.groupby(['Sp', 'Value'])['count'].transform('max')\nresult = df[df['count'] == max_count]\n</code>", "metadata": {"problem_id": 180, "library_problem_id": 180, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 177}}
{"id": 181, "code": "```python\nfor index, row in df.iterrows():\n    if row['Member'] in dict:\n        df.loc[index, 'Date'] = dict[row['Member']]\n```\n\n</code>", "metadata": {"problem_id": 181, "library_problem_id": 181, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 181}}
{"id": 182, "code": "```python\ndef map_date(member):\n    return dict.get(member, '17/8/1926')\n\ndf['Date'] = df['Member'].apply(map_date)\n```\n\n</code>", "metadata": {"problem_id": 182, "library_problem_id": 182, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 181}}
{"id": 183, "code": "```python\n    for index, row in df.iterrows():\n        if row['Member'] in dict:\n            df.loc[index, 'Date'] = dict[row['Member']]\n    return df\n```", "metadata": {"problem_id": 183, "library_problem_id": 183, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 181}}
{"id": 184, "code": "```python\ndf['Date'] = df['Member'].map(dict)\ndf['Date'] = df['Date'].fillna('17/8/1926')\ndf['Date'] = pd.to_datetime(df['Date'])\ndf['Date'] = df['Date'].dt.strftime('%d-%b-%Y')\n```\n\n</code>", "metadata": {"problem_id": 184, "library_problem_id": 184, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 181}}
{"id": 185, "code": "```python\ndf['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%y')\ndf['Count_d'] = df['Date'].map(df.groupby('Date').size())\ndf['Count_m'] = df['Date'].map(df.groupby([df['Date'].dt.year, df['Date'].dt.month]).size())\ndf['Count_y'] = df['Date'].map(df.groupby(df['Date'].dt.year).size())\n```\n\n</code>", "metadata": {"problem_id": 185, "library_problem_id": 185, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 185}}
{"id": 186, "code": "```python\ndf['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%y')\ndf['Count_d'] = df.Date.map(df.groupby('Date').size())\ndf['YearMonth'] = df['Date'].dt.to_period('M')\ndf['Count_m'] = df.groupby('YearMonth')['Val'].transform('count')\ndf['Count_y'] = df.groupby(df['Date'].dt.year)['Val'].transform('count')\ndf['Count_Val'] = df.groupby('Val')['Date'].transform('count')\ndf = df.drop('YearMonth', axis=1)\n```\n\n</code>", "metadata": {"problem_id": 186, "library_problem_id": 186, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 185}}
{"id": 187, "code": "```python\ndf['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%y')\ndf['Count_d'] = df.groupby('Date')['Date'].transform('size')\ndf['Count_m'] = df.groupby([df['Date'].dt.year, df['Date'].dt.month])['Date'].transform('size')\ndf['Count_y'] = df.groupby(df['Date'].dt.year)['Date'].transform('size')\ndf['Count_w'] = df.groupby(df['Date'].dt.weekday)['Date'].transform('size')\ndf['Count_Val'] = df.groupby('Val')['Val'].transform('size')\n```\n\n</code>", "metadata": {"problem_id": 187, "library_problem_id": 187, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 185}}
{"id": 188, "code": "```python\ndef count_zeros(series):\n    return (series == 0).sum()\n\ndef count_nonzeros(series):\n    return (series != 0).sum()\n\nresult1 = df.groupby('Date')[['B', 'C']].apply(lambda x: x.apply(count_zeros))\nresult2 = df.groupby('Date')[['B', 'C']].apply(lambda x: x.apply(count_nonzeros))\n</code>\n", "metadata": {"problem_id": 188, "library_problem_id": 188, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 188}}
{"id": 189, "code": "```python\ndef count_even(series):\n    return (series % 2 == 0).sum()\n\ndef count_odd(series):\n    return (series % 2 != 0).sum()\n\nresult1 = df.groupby('Date').apply(lambda x: x[['B', 'C']].apply(count_even))\nresult2 = df.groupby('Date').apply(lambda x: x[['B', 'C']].apply(count_odd))\n</code>\n", "metadata": {"problem_id": 189, "library_problem_id": 189, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 188}}
{"id": 190, "code": "```python\nagg_dict = {'D': 'sum', 'E': 'mean'}\nresult = pd.pivot_table(df, values=['D', 'E'], rows=['B'], aggfunc=agg_dict)\n```", "metadata": {"problem_id": 190, "library_problem_id": 190, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 190}}
{"id": 191, "code": "```python\nresult = pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc={'D': np.sum, 'E': np.mean})\n```\n\n</code>", "metadata": {"problem_id": 191, "library_problem_id": 191, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 190}}
{"id": 192, "code": "```python\nresult = pd.pivot_table(df, values=['D','E'], rows=['B'], aggfunc={'D': np.sum,'E': np.mean})\n</code>\n", "metadata": {"problem_id": 192, "library_problem_id": 192, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 190}}
{"id": 193, "code": "```python\nagg_dict = {'D': np.max, 'E': np.min}\nresult = pd.pivot_table(df, values=['D', 'E'], rows=['B'], aggfunc=agg_dict)\n```\n\n</code>", "metadata": {"problem_id": 193, "library_problem_id": 193, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 190}}
{"id": 194, "code": "```python\nimport dask.dataframe as dd\nimport pandas as pd\n\ndf = pd.DataFrame([[\"A\", \"Z,Y\"], [\"B\", \"X\"], [\"C\", \"W,U,V\"]], index=[1,2,3], columns=['var1', 'var2'])\n\nddf = dd.from_pandas(df, npartitions=1)\n\ndef split_func(x):\n    if isinstance(x, str):\n        return x.split(',')\n    else:\n        return []\n\nddf['var2'] = ddf['var2'].map(split_func, meta=pd.Series(dtype='object'))\n\ndef explode(df):\n    df = df.explode('var2')\n    return df\n\nmeta = pd.DataFrame({\n    'var1': pd.Series(dtype='object'),\n    'var2': pd.Series(dtype='object')\n})\n\nresult = ddf.map_partitions(explode, meta=meta)\n```\n\n</code>", "metadata": {"problem_id": 194, "library_problem_id": 194, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 194}}
{"id": 195, "code": "```python\nimport dask.dataframe as dd\nimport dask.multiprocessing\nimport pandas as pd\n\ndf = pd.DataFrame([[\"A\", \"Z,Y\"], [\"B\", \"X\"], [\"C\", \"W,U,V\"]], index=[1,2,3], columns=['var1', 'var2'])\nddf = dd.from_pandas(df, npartitions=2)\n\ndef split_string(df):\n    df['var2'] = df['var2'].str.split(',')\n    return df\n\nddf = ddf.map_partitions(split_string, meta=ddf)\nlengths = ddf['var2'].apply(len, meta=('var2', 'int')).compute()\n\nddf = ddf.explode('var2')\n\nresult = ddf.repartition(npartitions=2)\n```\n\n</code>", "metadata": {"problem_id": 195, "library_problem_id": 195, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 194}}
{"id": 196, "code": "```python\ndef split_column(df):\n    df['var2'] = df['var2'].str.split('-')\n    df = df.explode('var2')\n    return df\n\nresult = split_column(df)\n```\n\n</code>", "metadata": {"problem_id": 196, "library_problem_id": 196, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 194}}
{"id": 197, "code": "```python\ndef count_special_char(string):\n    special_char = 0\n    for i in range(len(string)):\n        if string[i].isalpha():\n            continue\n        else:\n            special_char += 1\n    return special_char\n\ndf[\"new\"] = df[\"str\"].apply(count_special_char)\n```\n\n</code>", "metadata": {"problem_id": 197, "library_problem_id": 197, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 197}}
{"id": 198, "code": "```python\ndef count_alpha(string):\n    alpha_char = 0\n    for i in range(len(string)):\n        if(string[i].isalpha()):\n            alpha_char = alpha_char + 1\n    return alpha_char\ndf[\"new\"]=df[\"str\"].apply(count_alpha)\n</code>\n\n</code>", "metadata": {"problem_id": 198, "library_problem_id": 198, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 197}}
{"id": 199, "code": "```python\ndf[['fips', 'row']] = df['row'].str.split(n=1, expand=True)\n```\n\n</code>", "metadata": {"problem_id": 199, "library_problem_id": 199, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 199}}
{"id": 200, "code": "```python\ndf[['fips', 'row']] = df['row'].str.split(' ', n=1, expand=True)\n```</code>", "metadata": {"problem_id": 200, "library_problem_id": 200, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 199}}
{"id": 201, "code": "```python\ndf[['fips', 'medi', 'row']] = df['row'].str.split(n=2, expand=True)\n```\n\n</code>", "metadata": {"problem_id": 201, "library_problem_id": 201, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 199}}
{"id": 202, "code": "```python\ndf1 = df.copy()\ncols = ['2001', '2002', '2003', '2004', '2005', '2006']\n\nfor index, row in df.iterrows():\n    cumulative_sum = 0\n    non_zero_count = 0\n    for col in cols:\n        if row[col] != 0:\n            cumulative_sum += row[col]\n            non_zero_count += 1\n        if non_zero_count > 0:\n            df1.loc[index, col] = cumulative_sum / non_zero_count\n        else:\n            df1.loc[index, col] = 0\ndf = df1\n```\n\n</code>", "metadata": {"problem_id": 202, "library_problem_id": 202, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 202}}
{"id": 203, "code": "```python\n    df1 = df.copy()\n    cols = df1.columns[1:]\n    for index, row in df1.iterrows():\n        running_sum = 0\n        running_count = 0\n        for col in reversed(cols):\n            if row[col] != 0:\n                running_sum += row[col]\n                running_count += 1\n            if running_count > 0:\n                df1.loc[index, col] = running_sum / running_count\n            else:\n                df1.loc[index, col] = 0\n    df = df1\n```\n\n</code>", "metadata": {"problem_id": 203, "library_problem_id": 203, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 202}}
{"id": 204, "code": "```python\n    df_result = df.copy()\n    cols = ['2001', '2002', '2003', '2004', '2005', '2006']\n    for index, row in df.iterrows():\n        cumulative_sum = 0\n        cumulative_count = 0\n        for col in cols:\n            value = row[col]\n            if value != 0:\n                cumulative_sum += value\n                cumulative_count += 1\n            if cumulative_count > 0:\n                df_result.loc[index, col] = cumulative_sum / cumulative_count\n            else:\n                df_result.loc[index, col] = 0\n    return df_result\n```</code>", "metadata": {"problem_id": 204, "library_problem_id": 204, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 202}}
{"id": 205, "code": "```python\nyears = ['2006', '2005', '2004', '2003', '2002', '2001']\n\nfor index, row in df.iterrows():\n    sum_so_far = 0\n    count = 0\n    for year in years:\n        value = row[year]\n        if value != 0:\n            sum_so_far += value\n            count += 1\n        if count == 0:\n            avg = 0\n        else:\n            avg = sum_so_far / count\n        df.loc[index, year] = avg\n```\n\n</code>", "metadata": {"problem_id": 205, "library_problem_id": 205, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 202}}
{"id": 206, "code": "```python\ndf['label'] = 0\ndf.loc[0, 'label'] = 1\ndf['diff'] = df['Close'].diff()\ndf['label'] = df['diff'].apply(lambda x: 1 if x > 0 else 0)\ndf.loc[0, 'label'] = 1\ndf = df[['DateTime', 'Close', 'label']]\n```\n\n</code>", "metadata": {"problem_id": 206, "library_problem_id": 206, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 206}}
{"id": 207, "code": "```python\ndf['label'] = 0\ndf.loc[0, 'label'] = 1\ndf['diff'] = df['Close'].diff()\nfor i in range(1, len(df)):\n    if df['diff'][i] > 0:\n        df.loc[i, 'label'] = 1\n    elif df['diff'][i] < 0:\n        df.loc[i, 'label'] = -1\n    else:\n        df.loc[i, 'label'] = 0\ndf = df.drop('diff', axis=1)\n```\n\n</code>", "metadata": {"problem_id": 207, "library_problem_id": 207, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 206}}
{"id": 208, "code": "```python\ndf['label'] = df['Close'].diff()\ndf['label'] = df['label'].apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\ndf.loc[0, 'label'] = -1\ndf['DateTime'] = df['DateTime'].dt.strftime('%d-%b-%Y')\n</code>\n\n</code>", "metadata": {"problem_id": 208, "library_problem_id": 208, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 206}}
{"id": 209, "code": "```python\ndf['arrival_time'] = pd.to_datetime(df['arrival_time'], errors='coerce')\ndf['departure_time'] = pd.to_datetime(df['departure_time'])\ndf['Duration'] = df['arrival_time'].shift(-1) - df['departure_time']\n```\n\n</code>", "metadata": {"problem_id": 209, "library_problem_id": 209, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 209}}
{"id": 210, "code": "```python\ndf['arrival_time'] = pd.to_datetime(df['arrival_time'], errors='coerce')\ndf['departure_time'] = pd.to_datetime(df['departure_time'], errors='coerce')\ndf['Duration'] = df.groupby('id')['arrival_time'].shift(-1) - df['departure_time']\ndf['Duration'] = df['Duration'].dt.total_seconds()\n```\n\n</code>", "metadata": {"problem_id": 210, "library_problem_id": 210, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 209}}
{"id": 211, "code": "```python\ndf['arrival_time'] = pd.to_datetime(df['arrival_time'], errors='coerce')\ndf['departure_time'] = pd.to_datetime(df['departure_time'], errors='coerce')\ndf['Duration'] = (df['departure_time'].shift(-1) - df['arrival_time']).dt.total_seconds()\ndf['arrival_time'] = df['arrival_time'].dt.strftime('%d-%b-%Y %H:%M:%S')\ndf['departure_time'] = df['departure_time'].dt.strftime('%d-%b-%Y %H:%M:%S')\n```\n\n</code>", "metadata": {"problem_id": 211, "library_problem_id": 211, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 209}}
{"id": 212, "code": "```python\nresult = df.groupby('key1')['key2'].apply(lambda x: (x == 'one').sum()).reset_index(name='count')\n```\n\n</code>", "metadata": {"problem_id": 212, "library_problem_id": 212, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 212}}
{"id": 213, "code": "```python\nresult = df.groupby('key1')['key2'].apply(lambda x: (x == 'two').sum()).reset_index(name='count')\n```</code>", "metadata": {"problem_id": 213, "library_problem_id": 213, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 212}}
{"id": 214, "code": "```python\nresult = df['key2'].str.endswith('e').groupby(df['key1']).sum().reset_index()\nresult.rename(columns={'key2': 'count'}, inplace=True)\n```</code>", "metadata": {"problem_id": 214, "library_problem_id": 214, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 212}}
{"id": 215, "code": "```python\ndf.index = pd.to_datetime(df.index)\nmin_result = df.index.min()\nmax_result = df.index.max()\n</code>", "metadata": {"problem_id": 215, "library_problem_id": 215, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 215}}
{"id": 216, "code": "```python\ndf.index = pd.to_datetime(df.index)\nmode_result = df.index.mode()\nmedian_result = pd.to_datetime(df.index.astype('int64').median())\n```</code>", "metadata": {"problem_id": 216, "library_problem_id": 216, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 215}}
{"id": 217, "code": "```python\nmask1 = df['closing_price'] >= 99\nmask2 = df['closing_price'] <= 101\nfinal_mask = mask1 & mask2\nresult = df[final_mask]\n```\n\n</code>", "metadata": {"problem_id": 217, "library_problem_id": 217, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 217}}
{"id": 218, "code": "```python\nresult = df[(df['closing_price'] < 99) | (df['closing_price'] > 101)]\n</code>\n", "metadata": {"problem_id": 218, "library_problem_id": 218, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 217}}
{"id": 219, "code": "```python\nmin_diff = df.groupby(\"item\")[\"diff\"].min().reset_index()\ndf_min = pd.merge(df, min_diff, on=\"item\", suffixes=(\"\", \"_min\"))\nresult = df_min[df_min[\"diff\"] == df_min[\"diff_min\"]][[\"item\", \"diff\", \"otherstuff\"]]\n```</code>", "metadata": {"problem_id": 219, "library_problem_id": 219, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 219}}
{"id": 220, "code": "```python\ndf['SOURCE_NAME'] = df['SOURCE_NAME'].str.rsplit('_', n=1).str[0]\n</code>", "metadata": {"problem_id": 220, "library_problem_id": 220, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 220}}
{"id": 221, "code": "```python\ndef extract_after_last_underscore(s):\n    if '_' in s:\n        return s.split('_')[-1]\n    else:\n        return s\n\ndf['SOURCE_NAME'] = df['SOURCE_NAME'].apply(extract_after_last_underscore)\n```\n\n</code>", "metadata": {"problem_id": 221, "library_problem_id": 221, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 220}}
{"id": 222, "code": "```python\n    df['SOURCE_NAME'] = df['SOURCE_NAME'].str.rsplit('_', n=1).str[0]\n    return df\n```", "metadata": {"problem_id": 222, "library_problem_id": 222, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 220}}
{"id": 223, "code": "```python\nnan_count = df['Column_x'].isnull().sum()\nnum_zeros = int(nan_count // 2)\nnum_ones = nan_count - num_zeros\nnan_indices = df[df['Column_x'].isnull()].index\ndf.loc[nan_indices[:num_zeros], 'Column_x'] = 0\ndf.loc[nan_indices[num_zeros:], 'Column_x'] = 1\n```\n\n</code>", "metadata": {"problem_id": 223, "library_problem_id": 223, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 223}}
{"id": 224, "code": "```python\nnan_indices = df['Column_x'].isnull()\nnan_count = nan_indices.sum()\n\nfirst_30_percent = int(nan_count * 0.3)\nsecond_30_percent = int(nan_count * 0.3)\n\nnan_index_list = df[nan_indices].index.tolist()\n\ndf.loc[nan_index_list[:first_30_percent], 'Column_x'] = 0\ndf.loc[nan_index_list[first_30_percent:first_30_percent + second_30_percent], 'Column_x'] = 0.5\ndf.loc[nan_index_list[first_30_percent + second_30_percent:], 'Column_x'] = 1\n```\n\n</code>", "metadata": {"problem_id": 224, "library_problem_id": 224, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 223}}
{"id": 225, "code": "```python\nnan_count = df['Column_x'].isnull().sum()\nnum_zeros = nan_count // 2\nnum_ones = nan_count - num_zeros\nfill_array = np.concatenate([np.zeros(num_zeros), np.ones(num_ones)])\ndf['Column_x'] = df['Column_x'].fillna(pd.Series(fill_array, index=df.index[df['Column_x'].isnull()]))\n```\n\n</code>", "metadata": {"problem_id": 225, "library_problem_id": 225, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 223}}
{"id": 226, "code": "```python\ndef create_tuple_dataframe(dataframes):\n    rows = dataframes[0].shape[0]\n    cols = dataframes[0].shape[1]\n    \n    new_data = []\n    for i in range(rows):\n        row_data = []\n        for j in range(cols):\n            elements = tuple(df.iloc[i, j] for df in dataframes)\n            row_data.append(elements)\n        new_data.append(row_data)\n    \n    result_df = pd.DataFrame(new_data, columns=dataframes[0].columns)\n    return result_df\n\nresult = create_tuple_dataframe([a, b])\n</code>\n", "metadata": {"problem_id": 226, "library_problem_id": 226, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 226}}
{"id": 227, "code": "```python\ndef create_tuple_dataframe(*dfs):\n    return pd.DataFrame({col: tuple(df[col] for df in dfs) for col in dfs[0].columns})\n\nresult = create_tuple_dataframe(a, b, c)\n</code>", "metadata": {"problem_id": 227, "library_problem_id": 227, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 226}}
{"id": 228, "code": "```python\ndef create_tuple_dataframe(dfs):\n    max_len = max(len(df) for df in dfs)\n    \n    tuple_data = {}\n    for col in dfs[0].columns:\n        tuple_data[col] = []\n        for i in range(max_len):\n            tuples = []\n            for df in dfs:\n                if i < len(df):\n                    tuples.append(df[col].iloc[i])\n                else:\n                    tuples.append(np.nan)\n            tuple_data[col].append(tuple(tuples))\n    return pd.DataFrame(tuple_data)\n\nresult = create_tuple_dataframe([a,b])\n</code>", "metadata": {"problem_id": 228, "library_problem_id": 228, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 226}}
{"id": 229, "code": "```python\ndf['views_bin'] = pd.cut(df['views'], bins, right=True)\nresult = df.groupby(['username', 'views_bin']).size().unstack(fill_value=0)\nresult.columns = result.columns.astype(str)\n```</code>", "metadata": {"problem_id": 229, "library_problem_id": 229, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 229}}
{"id": 230, "code": "```python\ndf['views_binned'] = pd.cut(df['views'], bins=bins)\nresult = df.groupby(['username', 'views_binned']).size().unstack(fill_value=0)\n</code>\n", "metadata": {"problem_id": 230, "library_problem_id": 230, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 229}}
{"id": 231, "code": "```python\ndf['views_bins'] = pd.cut(df['views'], bins)\ngrouped = df.groupby(['username', 'views_bins'])\ncounts = grouped['views'].count()\nresult = counts.unstack(fill_value=0)\n```</code>", "metadata": {"problem_id": 231, "library_problem_id": 231, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 229}}
{"id": 232, "code": "```python\nresult = pd.DataFrame({'text': [', '.join(df['text'])]})\n</code>\n", "metadata": {"problem_id": 232, "library_problem_id": 232, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 232}}
{"id": 233, "code": "```python\nconcatenated_string = df['text'].str.cat(sep='-')\nresult = pd.DataFrame({'text': [concatenated_string]})\n```\n", "metadata": {"problem_id": 233, "library_problem_id": 233, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 232}}
{"id": 234, "code": "```python\nresult = pd.DataFrame({'text': [', '.join(df['text'][::-1])]})\n</code>\n", "metadata": {"problem_id": 234, "library_problem_id": 234, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 232}}
{"id": 235, "code": "```python\nresult = pd.Series(df['text'].str.cat(sep=', '), name='text')\n</code>\n", "metadata": {"problem_id": 235, "library_problem_id": 235, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 232}}
{"id": 236, "code": "```python\nresult = pd.Series(['-'.join(df['text'][::-1])], name='text')\n</code>\n", "metadata": {"problem_id": 236, "library_problem_id": 236, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 232}}
{"id": 237, "code": "```python\ndf_concat = pd.concat([df1, df2], axis=0)\ndf_merged = pd.merge(df_concat, df1[['id', 'city', 'district']], on='id', how='left', suffixes=('', '_df1'))\ndf_merged['city'] = df_merged['city'].fillna(df_merged['city_df1'])\ndf_merged['district'] = df_merged['district'].fillna(df_merged['district_df1'])\ndf_merged = df_merged.drop(['city_df1', 'district_df1'], axis=1)\nresult = df_merged[['id', 'city', 'district', 'date', 'value']]\n```\n\n</code>", "metadata": {"problem_id": 237, "library_problem_id": 237, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 237}}
{"id": 238, "code": "```python\ndf_concat = pd.concat([df1, df2], axis=0)\ndf_merged = pd.merge(df_concat, df1[['id', 'city', 'district']], on='id', how='left', suffixes=('', '_left'))\ndf_merged['city'] = df_merged['city'].fillna(df_merged['city_left']).drop('city_left', axis=1)\ndf_merged['district'] = df_merged['district'].fillna(df_merged['district_left']).drop('district_left', axis=1)\ndf_merged['date'] = pd.to_datetime(df_merged['date'], format='%Y/%m/%d', errors='coerce')\ndf_merged = df_merged.sort_values(by=['id', 'date'])\ndf_merged['date'] = df_merged['date'].dt.strftime('%d-%b-%Y')\nresult = df_merged\n```\n\n</code>", "metadata": {"problem_id": 238, "library_problem_id": 238, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 237}}
{"id": 239, "code": "```python\ndf_concat = pd.concat([df1, df2], axis=0)\nid_to_city_district = df1.set_index('id')[['city', 'district']].to_dict('index')\n\ndef fill_city_district(row):\n    if pd.isna(row['city']) and row['id'] in id_to_city_district:\n        row['city'] = id_to_city_district[row['id']]['city']\n        row['district'] = id_to_city_district[row['id']]['district']\n    return row\n\ndf_concat = df_concat.apply(fill_city_district, axis=1)\nresult = df_concat.sort_values(by=['id', 'date']).reset_index(drop=True)\n```\n\n</code>", "metadata": {"problem_id": 239, "library_problem_id": 239, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 237}}
{"id": 240, "code": "```python\nresult = pd.merge(C, D, on='A', how='left', suffixes=('_x', '_y'))\nresult['B'] = result['B_y'].fillna(result['B_x'])\nresult = result.drop(['B_x', 'B_y'], axis=1)\nresult = pd.concat([result, D[~D['A'].isin(C['A'])]], ignore_index=True)\nresult = result.fillna(0)\n```\n\n</code>", "metadata": {"problem_id": 240, "library_problem_id": 240, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 240}}
{"id": 241, "code": "```python\nresult = pd.merge(C, D, on='A', how='left', suffixes=('_x', '_y'))\nresult['B'] = result['B_x'].fillna(result['B_y'])\nresult = result[['A', 'B']]\n```\n\n</code>", "metadata": {"problem_id": 241, "library_problem_id": 241, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 240}}
{"id": 242, "code": "```python\nmerged = pd.merge(C, D, on='A', how='left', suffixes=('_C', '_D'))\nmerged['B'] = merged['B_D'].fillna(merged['B_C'])\nmerged['dulplicated'] = merged['A'].isin(D['A'])\nresult = merged[['A', 'B', 'dulplicated']]\n```\n\n</code>", "metadata": {"problem_id": 242, "library_problem_id": 242, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 240}}
{"id": 243, "code": "```python\ndef aggregate_transactions(group):\n    group = group.sort_values('time')\n    return group[['time', 'amount']].values.tolist()\n\nresult = df.groupby('user').apply(aggregate_transactions)\n</code>", "metadata": {"problem_id": 243, "library_problem_id": 243, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 243}}
{"id": 244, "code": "```python\ndef process_group(group):\n    tuples = list(zip(group['time'], group['amount']))\n    tuples.sort(key=lambda x: x[0])\n    return tuples\n\nresult = df.groupby('user').apply(process_group).to_frame(name='amount-time-tuple')\n```\n\n</code>", "metadata": {"problem_id": 244, "library_problem_id": 244, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 243}}
{"id": 245, "code": "```python\ndf['amount-time-tuple'] = list(zip(df['time'], df['amount']))\nresult = df.groupby('user')['amount-time-tuple'].apply(lambda x: sorted(x, reverse=True))\n```\n\n</code>", "metadata": {"problem_id": 245, "library_problem_id": 245, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 243}}
{"id": 246, "code": "```python\ndf = pd.DataFrame(series.tolist(), index=series.index)\n</code>\n", "metadata": {"problem_id": 246, "library_problem_id": 246, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 246}}
{"id": 247, "code": "```python\nnames = list(series.index)\ndata = list(series.values)\ndf = pd.DataFrame(data)\ndf.insert(0, 'name', names)\n```</code>", "metadata": {"problem_id": 247, "library_problem_id": 247, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 246}}
{"id": 248, "code": "```python\nresult = []\nfor col in df.columns:\n    if s in col and col != s:\n        result.append(col)\n</code>", "metadata": {"problem_id": 248, "library_problem_id": 248, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 248}}
{"id": 249, "code": "```python\nselected_columns = [col for col in df.columns if s in col and col != s]\nresult = df[selected_columns]\n</code>", "metadata": {"problem_id": 249, "library_problem_id": 249, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 248}}
{"id": 250, "code": "```python\nmatching_columns = []\nfor col in df.columns:\n    if s in col and col != s:\n        matching_columns.append(col)\n\nnew_names = {col: f'spike{i+1}' for i, col in enumerate(matching_columns)}\ndf_renamed = df.rename(columns=new_names)\nresult = df_renamed[new_names.values()]\n```\n\n</code>", "metadata": {"problem_id": 250, "library_problem_id": 250, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 248}}
{"id": 251, "code": "```python\nmax_len = df['codes'].apply(len).max()\nfor i in range(max_len):\n    df[f'code_{i}'] = df['codes'].apply(lambda x: x[i] if len(x) > i else pd.NA)\nresult = df\n```\n\n</code>", "metadata": {"problem_id": 251, "library_problem_id": 251, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 251}}
{"id": 252, "code": "```python\nmax_len = df['codes'].apply(len).max()\nfor i in range(max_len):\n    df[f'code_{i+1}'] = df['codes'].apply(lambda x: x[i] if len(x) > i else float('NaN'))\nresult = df.drop('codes', axis=1)\n```\n\n</code>", "metadata": {"problem_id": 252, "library_problem_id": 252, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 251}}
{"id": 253, "code": "```python\ndf['codes'] = df['codes'].apply(lambda x: sorted(x))\nresult = pd.DataFrame(df['codes'].tolist(), index=df.index)\nresult.columns = [f'code_{i+1}' for i in range(len(result.columns))]\n</code>", "metadata": {"problem_id": 253, "library_problem_id": 253, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 251}}
{"id": 254, "code": "```python\nresult = []\nfor lst in df['col1']:\n    result.extend(lst)\n</code>", "metadata": {"problem_id": 254, "library_problem_id": 254, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 254}}
{"id": 255, "code": "```python\nresult = ','.join([str(x) for sublist in df['col1'] for x in reversed(sublist)])\n</code>", "metadata": {"problem_id": 255, "library_problem_id": 255, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 254}}
{"id": 256, "code": "```python\nresult = ','.join(map(str, sum(df['col1'].tolist(), [])))\n```\n\n</code>", "metadata": {"problem_id": 256, "library_problem_id": 256, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 254}}
{"id": 257, "code": "```python\ndf['Time'] = df['Time'].dt.floor('2Min')\ndf = df.groupby('Time')['Value'].mean().reset_index()\n```\n\n</code>", "metadata": {"problem_id": 257, "library_problem_id": 257, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 257}}
{"id": 258, "code": "```python\ndf = df.set_index('Time').groupby(pd.Grouper(freq='3Min'))['Value'].sum().reset_index()\n```\n\n</code>", "metadata": {"problem_id": 258, "library_problem_id": 258, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 257}}
{"id": 259, "code": "```python\ndf['TIME'] = pd.to_datetime(df['TIME'])\ndf['RANK'] = df.groupby('ID')['TIME'].rank(ascending=True)\n```\n\n</code>", "metadata": {"problem_id": 259, "library_problem_id": 259, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 259}}
{"id": 260, "code": "```python\ndf['TIME'] = pd.to_datetime(df['TIME'])\ndf['RANK'] = df.groupby('ID')['TIME'].rank(ascending=False)\n```</code>", "metadata": {"problem_id": 260, "library_problem_id": 260, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 259}}
{"id": 261, "code": "```python\ndf['TIME'] = pd.to_datetime(df['TIME'])\ndf['RANK'] = df.groupby('ID')['TIME'].rank(ascending=False)\ndf['TIME'] = df['TIME'].dt.strftime('%d-%b-%Y %a %H:%M:%S')\n```\n\n</code>", "metadata": {"problem_id": 261, "library_problem_id": 261, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 259}}
{"id": 262, "code": "```python\nresult = df.loc[filt[df.index.get_level_values('a')].values]\n</code>", "metadata": {"problem_id": 262, "library_problem_id": 262, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 262}}
{"id": 263, "code": "```python\nresult = df[df.index.get_level_values('a').map(filt)]\n```</code>", "metadata": {"problem_id": 263, "library_problem_id": 263, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 262}}
{"id": 264, "code": "```python\nrow0 = df.iloc[0]\nrow8 = df.iloc[8]\ndifferent_cols = []\nfor col in df.columns:\n    if not (pd.isna(row0[col]) and pd.isna(row8[col])):\n        if row0[col] != row8[col]:\n            different_cols.append(col)\nresult = pd.Index(different_cols)\n</code>", "metadata": {"problem_id": 264, "library_problem_id": 264, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 264}}
{"id": 265, "code": "```python\nrow0 = df.iloc[0]\nrow8 = df.iloc[8]\nsame_cols = []\nfor col in df.columns:\n    if pd.isna(row0[col]) and pd.isna(row8[col]):\n        same_cols.append(col)\n    elif row0[col] == row8[col]:\n        same_cols.append(col)\n\nresult = pd.Index(same_cols)\n</code>", "metadata": {"problem_id": 265, "library_problem_id": 265, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 264}}
{"id": 266, "code": "```python\nrow0 = df.iloc[0]\nrow8 = df.iloc[8]\ndifferent_columns = []\nfor col in df.columns:\n    if pd.isna(row0[col]) and pd.isna(row8[col]):\n        continue\n    elif row0[col] != row8[col]:\n        different_columns.append(col)\nresult = different_columns\n```\n\n</code>", "metadata": {"problem_id": 266, "library_problem_id": 266, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 264}}
{"id": 267, "code": "```python\ndifferent_pairs = []\nfor col in df.columns:\n    val0 = df.loc[0, col]\n    val8 = df.loc[8, col]\n    if not ((pd.isna(val0) and pd.isna(val8)) or (val0 == val8)):\n        different_pairs.append((val0, val8))\n\nresult = different_pairs\n</code>", "metadata": {"problem_id": 267, "library_problem_id": 267, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 264}}
{"id": 268, "code": "```python\nts = pd.Series(df['Value'].values, index=df['Date'])\n</code>", "metadata": {"problem_id": 268, "library_problem_id": 268, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 268}}
{"id": 269, "code": "```python\nseries_list = []\nfor index, row in df.iterrows():\n    renamed_values = {}\n    for col in df.columns:\n        new_col_name = f\"{col}_{index + 1}\"\n        renamed_values[new_col_name] = row[col]\n    series_list.append(pd.Series(renamed_values))\n\nconcatenated_series = pd.concat(series_list)\ndf = pd.DataFrame([concatenated_series.values], columns=concatenated_series.index)\n</code>\n", "metadata": {"problem_id": 269, "library_problem_id": 269, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 269}}
{"id": 270, "code": "```python\ns = pd.Series(df.values.flatten())\ncolumns = [f'{col}_{i}' for i in range(df.shape[0]) for col in df.columns]\ndf = pd.DataFrame(s.values.reshape(1, -1), columns=columns)\n</code>\n", "metadata": {"problem_id": 270, "library_problem_id": 270, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 269}}
{"id": 271, "code": "```python\nimport numpy as np\ndf['dogs'] = df['dogs'].fillna(np.nan).round(2)\n```\n\n</code>", "metadata": {"problem_id": 271, "library_problem_id": 271, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 271}}
{"id": 272, "code": "```python\ndf['dogs'] = df['dogs'].fillna(0).round(2).replace(0, pd.NA)\ndf['cats'] = df['cats'].fillna(0).round(2).replace(0, pd.NA)\n```\n\n</code>", "metadata": {"problem_id": 272, "library_problem_id": 272, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 271}}
{"id": 273, "code": "```python\ndf['Sum'] = df.loc[:, list_of_my_columns].sum(axis=1)\n```\n\n</code>", "metadata": {"problem_id": 273, "library_problem_id": 273, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 273}}
{"id": 274, "code": "```python\ndf['Avg'] = df[list_of_my_columns].mean(axis=1)\n```\n\n</code>", "metadata": {"problem_id": 274, "library_problem_id": 274, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 273}}
{"id": 275, "code": "```python\ndf['Avg'] = df[list_of_my_columns].mean(axis=1)\ndf['Min'] = df[list_of_my_columns].min(axis=1)\ndf['Max'] = df[list_of_my_columns].max(axis=1)\ndf['Median'] = df[list_of_my_columns].median(axis=1)\n</code>", "metadata": {"problem_id": 275, "library_problem_id": 275, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 273}}
{"id": 276, "code": "```python\nresult = df.sort_index(level='time', sort_remaining=False)\n</code>", "metadata": {"problem_id": 276, "library_problem_id": 276, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 276}}
{"id": 277, "code": "```python\nresult = df.sort_values(by='VIM', kind='mergesort')\n</code>", "metadata": {"problem_id": 277, "library_problem_id": 277, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 276}}
{"id": 278, "code": "```python\ndates_to_remove = ['2020-02-17', '2020-02-18']\nresult = df[~df.index.normalize().isin(dates_to_remove)]\n```</code>", "metadata": {"problem_id": 278, "library_problem_id": 278, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 278}}
{"id": 279, "code": "```python\ndates_to_remove = ['2020-02-17', '2020-02-18']\ntry:\n    df.drop(pd.to_datetime(dates_to_remove), inplace=True)\nexcept KeyError as e:\n    print(f\"Error: {e}. One or more dates not found in the index.\")\n\ndf.index = pd.to_datetime(df.index)\nresult = df.copy()\nresult.index = result.index.strftime('%d-%b-%Y %A')\n```\n\n</code>", "metadata": {"problem_id": 279, "library_problem_id": 279, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 278}}
{"id": 280, "code": "```python\ncorr_unstacked = corr.stack()\nfiltered_corr = corr_unstacked[corr_unstacked > 0.3]\nresult = pd.DataFrame(filtered_corr, columns=['Pearson Correlation Coefficient']).rename_axis(['Col1', 'Col2'])\n</code>\n\n", "metadata": {"problem_id": 280, "library_problem_id": 280, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 280}}
{"id": 281, "code": "```python\nresult = corr.stack()[corr.stack() > 0.3]\n```</code>", "metadata": {"problem_id": 281, "library_problem_id": 281, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 280}}
{"id": 282, "code": "```python\nnew_cols = df.columns.tolist()\nnew_cols[-1] = 'Test'\ndf.columns = new_cols\nresult = df\n</code>\n", "metadata": {"problem_id": 282, "library_problem_id": 282, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 282}}
{"id": 283, "code": "```python\ncol_list = list(df.columns)\ncol_list[0] = 'Test'\ndf.columns = col_list\nresult = df\n```</code>", "metadata": {"problem_id": 283, "library_problem_id": 283, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 282}}
{"id": 284, "code": "```python\ndef most_frequent(row):\n    return row.value_counts().index[0], row.value_counts().iloc[0]\n\ndf['frequent'], df['freq_count'] = zip(*df.apply(most_frequent, axis=1))\n```\n\n</code>", "metadata": {"problem_id": 284, "library_problem_id": 284, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 284}}
{"id": 285, "code": "```python\nimport pandas as pd\n\ndf = pd.DataFrame({'bit1': [0, 2, 4],\n                   'bit2': [0, 2, 0],\n                   'bit3': [3, 0, 4],\n                   'bit4': [3, 0, 4],\n                   'bit5': [0, 2, 4]})\n\nfrequent_values = []\nfrequency_counts = []\n\nfor index, row in df.iterrows():\n    value_counts = row.value_counts()\n    most_frequent_value = value_counts.idxmax()\n    max_count = value_counts.max()\n    frequent_values.append(most_frequent_value)\n    frequency_counts.append(max_count)\n\ndf['frequent'] = frequent_values\ndf['freq_count'] = frequency_counts\n```\n\n</code>", "metadata": {"problem_id": 285, "library_problem_id": 285, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 284}}
{"id": 286, "code": "```python\ndef find_frequent(row):\n    value_counts = row.value_counts()\n    max_freq = value_counts.max()\n    frequent_values = list(value_counts[value_counts == max_freq].index)\n    return frequent_values, max_freq\n\ndf[['frequent', 'freq_count']] = df.apply(find_frequent, axis=1, result_type='expand')\n```\n\n</code>", "metadata": {"problem_id": 286, "library_problem_id": 286, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 284}}
{"id": 287, "code": "```python\ndf.replace('NULL', pd.NA, inplace=True)\ndf['bar'] = pd.to_numeric(df['bar'])\nresult = df.groupby(['id1', 'id2'])[['foo', 'bar']].mean()\n```\n\n</code>", "metadata": {"problem_id": 287, "library_problem_id": 287, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 287}}
{"id": 288, "code": "```python\ndf['bar'] = df['bar'].replace('NULL', 0)\ndf['bar'] = pd.to_numeric(df['bar'])\nresult = df.groupby(['id1', 'id2'])[['foo', 'bar']].mean()\n```\n\n</code>", "metadata": {"problem_id": 288, "library_problem_id": 288, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 287}}
{"id": 289, "code": "```python\nresult = pd.merge(df_a, df_b[['EntityNum', 'a_col']], on='EntityNum', how='left')\n```</code>", "metadata": {"problem_id": 289, "library_problem_id": 289, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 289}}
{"id": 290, "code": "```python\nresult = pd.merge(df_a, df_b, on='EntityNum', how='left')[['EntityNum', 'foo', 'b_col']]\n```</code>", "metadata": {"problem_id": 290, "library_problem_id": 290, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 289}}
{"id": 291, "code": "```python\nresult = a.shape\n</code>\n", "metadata": {"problem_id": 291, "library_problem_id": 0, "library": "Numpy", "test_case_cnt": 4, "perturbation_type": "Origin", "perturbation_origin_id": 0}}
{"id": 292, "code": "```python\nx = x[~np.isnan(x)]\n```</code>", "metadata": {"problem_id": 292, "library_problem_id": 1, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 1}}
{"id": 293, "code": "```python\nx = np.nan_to_num(x, nan=np.inf)\n```", "metadata": {"problem_id": 293, "library_problem_id": 2, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 1}}
{"id": 294, "code": "```python\nresult = [row[~np.isnan(row)].tolist() for row in x]\n</code>", "metadata": {"problem_id": 294, "library_problem_id": 3, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 1}}
{"id": 295, "code": "```python\nmax_val = np.max(a)\nb = np.zeros((a.size, max_val + 1))\nb[np.arange(a.size), a] = 1\n```\n\n</code>", "metadata": {"problem_id": 295, "library_problem_id": 4, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 4}}
{"id": 296, "code": "```python\nimport numpy as np\nb = np.zeros((len(a), np.max(a) + 1), dtype=int)\nb[np.arange(len(a)), a] = 1\n```\n\n</code>", "metadata": {"problem_id": 296, "library_problem_id": 5, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 4}}
{"id": 297, "code": "```python\n    min_a = np.min(a)\n    range_a = np.max(a) - min_a + 1\n    b = np.zeros((len(a), range_a), dtype=int)\n    row_indices = np.arange(len(a))\n    col_indices = a - min_a\n    b[row_indices, col_indices] = 1\n</code>", "metadata": {"problem_id": 297, "library_problem_id": 6, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 4}}
{"id": 298, "code": "```python\nsorted_indices = np.argsort(a)\nb = np.zeros((len(a), len(a)))\nb[np.arange(len(a)), sorted_indices] = 1\n```</code>", "metadata": {"problem_id": 298, "library_problem_id": 7, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 4}}
{"id": 299, "code": "```python\n    min_val = np.min(a)\n    max_val = np.max(a)\n    rows, cols = a.shape\n    b = np.zeros((rows * cols, max_val - min_val + 1), dtype=int)\n    a_flat = a.flatten()\n    indices = a_flat - min_val\n    row_indices = np.arange(rows * cols)\n    b[row_indices, indices] = 1\n</code>", "metadata": {"problem_id": 299, "library_problem_id": 8, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 4}}
{"id": 300, "code": "```python\nresult = np.percentile(a, p)\n```</code>", "metadata": {"problem_id": 300, "library_problem_id": 9, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 9}}
{"id": 301, "code": "```python\nB = A.reshape(-1, ncol)\n</code>\n", "metadata": {"problem_id": 301, "library_problem_id": 10, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 10}}
{"id": 302, "code": "```python\nimport numpy as np\n\ndef vec2matrix(arr, nrow):\n    if not isinstance(arr, np.ndarray) or arr.ndim != 1:\n        raise ValueError(\"Input must be a 1D numpy array.\")\n    if not isinstance(nrow, int) or nrow <= 0:\n        raise ValueError(\"Number of rows must be a positive integer.\")\n    if nrow > arr.size:\n        raise ValueError(\"Number of rows cannot be greater than the number of elements in the array.\")\n    if arr.size % nrow != 0:\n        raise ValueError(\"Number of elements in the array must be divisible by the number of rows.\")\n    \n    ncol = arr.size // nrow\n    return arr.reshape(nrow, ncol)\n\nB = vec2matrix(A, nrow)\n</code>\n", "metadata": {"problem_id": 302, "library_problem_id": 11, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 10}}
{"id": 303, "code": "```python\nnrows = len(A) // ncol\nnelements = nrows * ncol\nA_sliced = A[:nelements]\nB = A_sliced.reshape(nrows, ncol)\n```</code>", "metadata": {"problem_id": 303, "library_problem_id": 12, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 10}}
{"id": 304, "code": "```python\nimport numpy as np\nA = np.array([1,2,3,4,5,6,7])\nncol = 2\ndiscard = len(A) % ncol\nA_sliced = A[discard:]\nA_reversed = A_sliced[::-1]\nB = A_reversed.reshape(-1, ncol)\n```</code>", "metadata": {"problem_id": 304, "library_problem_id": 13, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 10}}
{"id": 305, "code": "```python\nimport numpy as np\n\ndef shift_array(arr, shift_value):\n    if shift_value == 0:\n        return arr\n    arr_size = arr.size\n    result = np.empty_like(arr)\n    result[:] = np.nan\n    if shift_value > 0:\n        result[shift_value:] = arr[:arr_size - shift_value]\n    else:\n        result[:arr_size + shift_value] = arr[-shift_value:]\n    return result\n\nresult = shift_array(a, shift)\n```</code>", "metadata": {"problem_id": 305, "library_problem_id": 14, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 14}}
{"id": 306, "code": "```python\nimport numpy as np\n\ndef shift_1d(arr, shift_amount):\n    new_arr = np.full(arr.shape, np.nan)\n    if shift_amount > 0:\n        new_arr[shift_amount:] = arr[:-shift_amount]\n    elif shift_amount < 0:\n        new_arr[:shift_amount] = arr[-shift_amount:]\n    else:\n        new_arr[:] = arr\n    return new_arr\n\ndef shift(arr, shift_amount):\n    shifted_arr = np.array([shift_1d(row, shift_amount) for row in arr])\n    return shifted_arr\n\nresult = shift(a, shift)\n```</code>", "metadata": {"problem_id": 306, "library_problem_id": 15, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 14}}
{"id": 307, "code": "```python\nimport numpy as np\n\ndef shift_array(arr, shift_value):\n    new_arr = np.full(arr.shape, np.nan)\n    if shift_value > 0:\n        new_arr[shift_value:] = arr[:-shift_value]\n    elif shift_value < 0:\n        new_arr[:shift_value] = arr[-shift_value:]\n    else:\n        new_arr[:] = arr\n    return new_arr\n\ndef shift(array_2d, shift_list):\n    if len(shift_list) != array_2d.shape[0]:\n        raise ValueError(\"The length of shift_list must be equal to the number of rows in array_2d.\")\n    \n    shifted_rows = []\n    for i, row in enumerate(array_2d):\n        shifted_row = shift_array(row, shift_list[i])\n        shifted_rows.append(shifted_row)\n    \n    return np.array(shifted_rows)\n\nresult = shift(a, shift)\n</code>\n", "metadata": {"problem_id": 307, "library_problem_id": 16, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 14}}
{"id": 308, "code": "```python\nnp.random.seed(42)\nr = np.random.randint(3, size=(100, 2000)) - 1\nr_old = r\nr_new = r\n```\n\n</code>", "metadata": {"problem_id": 308, "library_problem_id": 17, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 17}}
{"id": 309, "code": "```python\nresult = np.argmax(a)\n```\n", "metadata": {"problem_id": 309, "library_problem_id": 18, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 18}}
{"id": 310, "code": "```python\nimport numpy as np\na = np.array([[10,50,30],[60,20,40]])\nresult = np.argmin(a)\n```\n", "metadata": {"problem_id": 310, "library_problem_id": 19, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 18}}
{"id": 311, "code": "```python\nimport numpy as np\na = np.array([[10,50,30],[60,20,40]])\nmax_value = np.max(a)\nindices = np.where(a == max_value)\nmulti_index = [i[0] for i in indices]\nresult = np.ravel_multi_index(multi_index, a.shape, order='F')\n```\n", "metadata": {"problem_id": 311, "library_problem_id": 20, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 18}}
{"id": 312, "code": "```python\nresult = np.argmax(a)\n```</code>", "metadata": {"problem_id": 312, "library_problem_id": 21, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 18}}
{"id": 313, "code": "```python\n    return np.argmax(a)\n```", "metadata": {"problem_id": 313, "library_problem_id": 22, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 18}}
{"id": 314, "code": "```python\nflattened_a = a.flatten()\nmax_index = np.argmax(flattened_a)\nflattened_a_copy = flattened_a.copy()\nflattened_a_copy[max_index] = -1\nsecond_largest_index = np.argmax(flattened_a_copy)\nresult = np.unravel_index(second_largest_index, a.shape)\n```</code>", "metadata": {"problem_id": 314, "library_problem_id": 23, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 18}}
{"id": 315, "code": "```python\na = a[:, ~np.any(np.isnan(a), axis=0)]\n```</code>", "metadata": {"problem_id": 315, "library_problem_id": 24, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 24}}
{"id": 316, "code": "```python\na = a[~np.isnan(a).any(axis=1)]\n```</code>", "metadata": {"problem_id": 316, "library_problem_id": 25, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 24}}
{"id": 317, "code": "```python\nimport numpy as np\na = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nresult = np.array(a)\n```\n", "metadata": {"problem_id": 317, "library_problem_id": 26, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 26}}
{"id": 318, "code": "```python\na = a[:, permutation]\n```</code>", "metadata": {"problem_id": 318, "library_problem_id": 27, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 27}}
{"id": 319, "code": "```python\nresult = a[permutation]\n```</code>", "metadata": {"problem_id": 319, "library_problem_id": 28, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 27}}
{"id": 320, "code": "```python\nresult = np.unravel_index(np.argmin(a), a.shape)\n</code>", "metadata": {"problem_id": 320, "library_problem_id": 29, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 29}}
{"id": 321, "code": "```python\nresult = np.unravel_index(np.argmax(a), a.shape)\n</code>\n", "metadata": {"problem_id": 321, "library_problem_id": 30, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 29}}
{"id": 322, "code": "```python\nimport numpy as np\na = np.array([[1, 0], [0, 2]])\nmin_val = np.min(a)\nrows, cols = np.where(a == min_val)\nresult = []\nfor i in range(len(rows)):\n    result.append([rows[i], cols[i]])\n```</code>", "metadata": {"problem_id": 322, "library_problem_id": 31, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 29}}
{"id": 323, "code": "```python\nresult = np.sin(np.radians(degree))\n```</code>", "metadata": {"problem_id": 323, "library_problem_id": 32, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 32}}
{"id": 324, "code": "```python\nresult = np.cos(np.radians(degree))\n```</code>", "metadata": {"problem_id": 324, "library_problem_id": 33, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 32}}
{"id": 325, "code": "```python\nimport numpy as np\nnumber = np.random.randint(0, 360)\nsin_degree = np.sin(np.radians(number))\nsin_radian = np.sin(number)\nif abs(sin_degree) > abs(sin_radian):\n    result = 0\nelse:\n    result = 1\n</code>\n", "metadata": {"problem_id": 325, "library_problem_id": 34, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 32}}
{"id": 326, "code": "```python\nresult = np.degrees(np.arcsin(value))\n</code>\n", "metadata": {"problem_id": 326, "library_problem_id": 35, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 32}}
{"id": 327, "code": "```python\nimport numpy as np\nimport math\n\ndef pad(A, length):\n    if len(A) >= length:\n        return A\n    else:\n        pad_size = length - len(A)\n        return np.concatenate([A, np.zeros(pad_size)])\n\ndef nearest_multiple_1024(x):\n    return int(math.ceil(x / 1024) * 1024)\n\ndef pad_to_nearest_1024(A):\n    length = nearest_multiple_1024(len(A))\n    return pad(A, length)\n\nA = np.array([1,2,3,4,5])\nlength = 8\nresult = pad(A, length)\n</code>\n", "metadata": {"problem_id": 327, "library_problem_id": 36, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 36}}
{"id": 328, "code": "```python\nimport numpy as np\n\ndef pad(A, length):\n    if length <= len(A):\n        return np.concatenate((A[:length], np.zeros(len(A) - length, dtype=A.dtype))) if len(A) > length else A[:length]\n    else:\n        new_array = np.zeros(length, dtype=A.dtype)\n        new_array[:len(A)] = A\n        return new_array\n\ndef pad_to_multiple(A):\n    target_length = (len(A) + 1023) // 1024 * 1024\n    return pad(A, target_length)\n\nA = np.array([1,2,3,4,5])\nlength = 8\nresult = pad(A, length)\n</code>\n", "metadata": {"problem_id": 328, "library_problem_id": 37, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 36}}
{"id": 329, "code": "```python\na = np.power(a, power)\n```", "metadata": {"problem_id": 329, "library_problem_id": 38, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 38}}
{"id": 330, "code": "```python\n        return np.power(a, power)\n    ### END SOLUTION\n```", "metadata": {"problem_id": 330, "library_problem_id": 39, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 38}}
{"id": 331, "code": "```python\nimport fractions\nfraction = fractions.Fraction(numerator, denominator)\nresult = (fraction.numerator, fraction.denominator)\n```\n", "metadata": {"problem_id": 331, "library_problem_id": 40, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 40}}
{"id": 332, "code": "```python\n    import math\n    gcd_value = math.gcd(numerator, denominator)\n    numerator = numerator // gcd_value\n    denominator = denominator // gcd_value\n    return (numerator, denominator)\n### END SOLUTION\n</code>\n```", "metadata": {"problem_id": 332, "library_problem_id": 41, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 40}}
{"id": 333, "code": "```python\nimport math\nimport numpy as np\n\nif denominator == 0:\n    result = (np.nan, np.nan)\nelse:\n    gcd = math.gcd(numerator, denominator)\n    result = (numerator // gcd, denominator // gcd)\n```\n", "metadata": {"problem_id": 333, "library_problem_id": 42, "library": "Numpy", "test_case_cnt": 4, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 40}}
{"id": 334, "code": "```python\nimport numpy as np\n\ndef elementwise_average(*arrays):\n    if not all(isinstance(arr, np.ndarray) for arr in arrays):\n        raise ValueError(\"All inputs must be NumPy arrays.\")\n    \n    if len(set(arr.shape for arr in arrays)) > 1:\n        raise ValueError(\"All input arrays must have the same shape.\")\n    \n    sum_array = np.sum(arrays, axis=0)\n    average_array = sum_array / len(arrays)\n    return average_array\n\na = np.array([10, 20, 30])\nb = np.array([30, 20, 20])\nc = np.array([50, 20, 40])\n\nresult = elementwise_average(a, b, c)\n</code>\n", "metadata": {"problem_id": 334, "library_problem_id": 43, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 43}}
{"id": 335, "code": "```python\nimport numpy as np\na = np.array([10, 20, 30])\nb = np.array([30, 20, 20])\nc = np.array([50, 20, 40])\nresult = np.maximum.reduce([a,b,c])\n```\n", "metadata": {"problem_id": 335, "library_problem_id": 44, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 43}}
{"id": 336, "code": "```python\n    rows, cols = a.shape\n    row_indices = np.arange(min(rows, cols))\n    col_indices = cols - 1 - row_indices\n    result = a[row_indices, col_indices]\n```", "metadata": {"problem_id": 336, "library_problem_id": 45, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 45}}
{"id": 337, "code": "```python\nrows, cols = a.shape\nrow_indices = np.arange(min(rows, cols))\ncol_indices = cols - 1 - row_indices\nresult = a[row_indices, col_indices]\n```\n\n</code>", "metadata": {"problem_id": 337, "library_problem_id": 46, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 45}}
{"id": 338, "code": "```python\nrows, cols = a.shape\nrow_indices = np.arange(rows)\ncol_indices = cols - 1 - row_indices\nresult = a[row_indices, col_indices]\n```</code>", "metadata": {"problem_id": 338, "library_problem_id": 47, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 45}}
{"id": 339, "code": "```python\n    rows, cols = a.shape\n    diagonals = []\n    for col in range(cols):\n        diagonal = []\n        r, c = rows - 1, col\n        while r >= 0 and c < cols:\n            diagonal.append(a[r, c])\n            r -= 1\n            c += 1\n        diagonals.append(np.array(diagonal))\n    result = diagonals\n</code>", "metadata": {"problem_id": 339, "library_problem_id": 48, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 45}}
{"id": 340, "code": "```python\nresult = []\nfor row in range(X.shape[0]):\n    for col in range(X.shape[1]):\n        result.append(X[row, col])\n```</code>", "metadata": {"problem_id": 340, "library_problem_id": 49, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 49}}
{"id": 341, "code": "```python\nimport numpy as np\nX = np.random.randint(2, 10, (5, 6))\nresult = []\nfor x in np.nditer(X, order='C'):\n    result.append(x.item())\n</code>\n", "metadata": {"problem_id": 341, "library_problem_id": 50, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 49}}
{"id": 342, "code": "```python\n    result = []\n    for x in np.nditer(X):\n        result.append(x.item())\n    return result\n### END SOLUTION\n```", "metadata": {"problem_id": 342, "library_problem_id": 51, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 49}}
{"id": 343, "code": "```python\nresult = []\nfor j in range(X.shape[1]):\n    for i in range(X.shape[0]):\n        result.append(X[i, j])\n</code>\n```", "metadata": {"problem_id": 343, "library_problem_id": 52, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 49}}
{"id": 344, "code": "```python\nresult = np.array([int(d) for d in mystr])\n</code>\n", "metadata": {"problem_id": 344, "library_problem_id": 53, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 53}}
{"id": 345, "code": "```python\nresult = np.cumsum(a[:, col] * multiply_number)\n```</code>", "metadata": {"problem_id": 345, "library_problem_id": 54, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 54}}
{"id": 346, "code": "```python\na[row] = a[row] * multiply_number\nresult = np.cumsum(a[row])\n```\n", "metadata": {"problem_id": 346, "library_problem_id": 55, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 54}}
{"id": 347, "code": "```python\na[row, :] = a[row, :] / divide_number\nresult = np.prod(a[row, :])\n```\n", "metadata": {"problem_id": 347, "library_problem_id": 56, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 54}}
{"id": 348, "code": "```python\nimport numpy as np\n\ndef is_linearly_independent(vectors):\n    if len(vectors) == 0:\n        return True\n    return np.linalg.matrix_rank(np.array(vectors)) == len(vectors)\n\nindependent_vectors = []\nfor row in a:\n    temp_vectors = independent_vectors + [row]\n    if is_linearly_independent(temp_vectors):\n        independent_vectors.append(row)\n\nresult = np.array(independent_vectors)\n</code>\n", "metadata": {"problem_id": 348, "library_problem_id": 57, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 57}}
{"id": 349, "code": "```python\nresult = a.shape[1]\n</code>\n", "metadata": {"problem_id": 349, "library_problem_id": 58, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 58}}
{"id": 350, "code": "```python\n    n_a = len(a)\n    n_b = len(b)\n    mean_a = np.mean(a)\n    mean_b = np.mean(b)\n    var_a = np.var(a, ddof=1)\n    var_b = np.var(b, ddof=1)\n    t = (mean_a - mean_b) / np.sqrt(var_a/n_a + var_b/n_b)\n    df = ( (var_a/n_a + var_b/n_b)**2 ) / ( ((var_a/n_a)**2)/(n_a-1) + ((var_b/n_b)**2)/(n_b-1) )\n    p_value = scipy.stats.t.cdf(t, df) * 2 if t < 0 else (1 - scipy.stats.t.cdf(t, df)) * 2\n</code>", "metadata": {"problem_id": 350, "library_problem_id": 59, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 59}}
{"id": 351, "code": "```python\na = a[~np.isnan(a)]\nb = b[~np.isnan(b)]\nn_a = len(a)\nn_b = len(b)\nif n_a > 1 and n_b > 1:\n    mean_a = np.mean(a)\n    mean_b = np.mean(b)\n    var_a = np.var(a, ddof=1)\n    var_b = np.var(b, ddof=1)\n    pooled_variance = ((n_a - 1) * var_a + (n_b - 1) * var_b) / (n_a + n_b - 2)\n    t_statistic = (mean_a - mean_b) / np.sqrt(pooled_variance * (1/n_a + 1/n_b))\n    degrees_of_freedom = n_a + n_b - 2\n    p_value = scipy.stats.t.sf(np.abs(t_statistic), degrees_of_freedom) * 2\nelse:\n    p_value = np.nan\n</code>\n", "metadata": {"problem_id": 351, "library_problem_id": 60, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 59}}
{"id": 352, "code": "```python\npooled_variance = ((anobs - 1) * avar + (bnobs - 1) * bvar) / (anobs + bnobs - 2)\nt_statistic = (amean - bmean) / np.sqrt(pooled_variance * (1 / anobs + 1 / bnobs))\ndegrees_of_freedom = anobs + bnobs - 2\np_value = 2 * (1 - scipy.stats.t.cdf(abs(t_statistic), degrees_of_freedom))\n</code>\n", "metadata": {"problem_id": 352, "library_problem_id": 61, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 59}}
{"id": 353, "code": "```python\nimport numpy as np\nA=np.asarray([[1,1,1], [1,1,2], [1,1,3], [1,1,4]])\nB=np.asarray([[0,0,0], [1,0,2], [1,0,3], [1,0,4], [1,1,0], [1,1,1], [1,1,4]])\n\nB_set = set(map(tuple, B))\nresult = []\nfor row in A:\n    if tuple(row) not in B_set:\n        result.append(row)\noutput = np.asarray(result)\n```</code>", "metadata": {"problem_id": 353, "library_problem_id": 62, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 62}}
{"id": 354, "code": "```python\nimport numpy as np\nA=np.asarray([[1,1,1], [1,1,2], [1,1,3], [1,1,4]])\nB=np.asarray([[0,0,0], [1,0,2], [1,0,3], [1,0,4], [1,1,0], [1,1,1], [1,1,4]])\n\na_list = [tuple(row) for row in A]\nb_list = [tuple(row) for row in B]\n\na_not_b = [x for x in a_list if x not in b_list]\nb_not_a = [x for x in b_list if x not in a_list]\n\nresult_list = a_not_b + b_not_a\n\noutput = np.asarray(result_list)\n```</code>", "metadata": {"problem_id": 354, "library_problem_id": 63, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Semantic", "perturbation_origin_id": 62}}
{"id": 355, "code": "```python\nimport numpy as np\na = np.random.rand(3, 3, 3)\nb = np.arange(3*3*3).reshape((3, 3, 3))\nsort_indices = np.argsort(a, axis=0)\nc = np.take_along_axis(b, sort_indices, axis=0)\n```</code>", "metadata": {"problem_id": 355, "library_problem_id": 64, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 64}}
{"id": 356, "code": "```python\nimport numpy as np\na = np.random.rand(3, 3, 3)\nb = np.arange(3*3*3).reshape((3, 3, 3))\nsort_indices = np.argsort(a, axis=0)\nc = b[sort_indices, np.arange(b.shape[1])[:, None], np.arange(b.shape[2])]\n```</code>", "metadata": {"problem_id": 356, "library_problem_id": 65, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 64}}
{"id": 357, "code": "```python\nsort_indices = np.argsort(a, axis=0)[::-1]\nc = np.take_along_axis(b, sort_indices, axis=0)\n```</code>", "metadata": {"problem_id": 357, "library_problem_id": 66, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 64}}
{"id": 358, "code": "```python\nsums = np.sum(a, axis=(1, 2))\nindices = np.argsort(sums)\nresult = b[indices]\n```</code>", "metadata": {"problem_id": 358, "library_problem_id": 67, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 64}}
{"id": 359, "code": "```python\na = np.delete(a, 2, axis=1)\n```", "metadata": {"problem_id": 359, "library_problem_id": 68, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 68}}
{"id": 360, "code": "```python\na = np.delete(a, 2, axis=0)\n</code>\n", "metadata": {"problem_id": 360, "library_problem_id": 69, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 68}}
{"id": 361, "code": "```python\na = np.delete(a, [0, 2], axis=1)\n```\n", "metadata": {"problem_id": 361, "library_problem_id": 70, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 68}}
{"id": 362, "code": "```python\nvalid_del_col = del_col[del_col < a.shape[1]]\nmask = np.ones(a.shape[1], dtype=bool)\nmask[valid_del_col] = False\nresult = a[:, mask]\n```\n\n</code>", "metadata": {"problem_id": 362, "library_problem_id": 71, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 68}}
{"id": 363, "code": "```python\na = np.insert(a, pos, element)\n</code>\n", "metadata": {"problem_id": 363, "library_problem_id": 72, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 72}}
{"id": 364, "code": "```python\na = np.insert(a, pos, element, axis=0)\n</code>\n", "metadata": {"problem_id": 364, "library_problem_id": 73, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 72}}
{"id": 365, "code": "```python\n    a = np.insert(a, pos, element)\n    return a\n```", "metadata": {"problem_id": 365, "library_problem_id": 74, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 72}}
{"id": 366, "code": "```python\nresult = []\nj = 0\nfor i in range(a.shape[0]):\n    if j < len(pos) and i == pos[j]:\n        result.append(element[j])\n        j += 1\n    result.append(a[i])\nif j < len(pos):\n    for k in range(j, len(pos)):\n        result.append(element[k])\na = np.array(result)\n</code>\n", "metadata": {"problem_id": 366, "library_problem_id": 75, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 72}}
{"id": 367, "code": "```python\nimport copy\nresult = copy.deepcopy(array_of_arrays)\n</code>\n", "metadata": {"problem_id": 367, "library_problem_id": 76, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 76}}
{"id": 368, "code": "```python\nresult = np.all(a[1:] == a[0])\n</code>\n", "metadata": {"problem_id": 368, "library_problem_id": 77, "library": "Numpy", "test_case_cnt": 5, "perturbation_type": "Origin", "perturbation_origin_id": 77}}
{"id": 369, "code": "```python\nresult = np.all(a == a[:, 0])\n```", "metadata": {"problem_id": 369, "library_problem_id": 78, "library": "Numpy", "test_case_cnt": 5, "perturbation_type": "Semantic", "perturbation_origin_id": 77}}
{"id": 370, "code": "```python\n    if a.size == 0:\n        return True\n    if a.shape[0] <= 1:\n        return True\n    return np.all(a[1:] == a[0])\n```", "metadata": {"problem_id": 370, "library_problem_id": 79, "library": "Numpy", "test_case_cnt": 5, "perturbation_type": "Surface", "perturbation_origin_id": 77}}
{"id": 371, "code": "```python\nimport numpy as np\n\ndef simpson_2d_weights(x_size, y_size):\n    weights = np.ones((y_size, x_size))\n    weights[1:-1, 1:-1] = 4\n    weights[1:-1, 0] = 2\n    weights[1:-1, -1] = 2\n    weights[0, 1:-1] = 2\n    weights[-1, 1:-1] = 2\n    weights[0, 0] = 1\n    weights[0, -1] = 1\n    weights[-1, 0] = 1\n    weights[-1, -1] = 1\n    return weights\n\ndef evaluate_function(x, y):\n    X, Y = np.meshgrid(x, y)\n    return np.cos(X)**4 + np.sin(Y)**2\n\ndef integrate_2d(function_values, weights, dx, dy):\n    return dx * dy / 9 * np.sum(function_values * weights)\n\nx = np.linspace(0, 1, 20)\ny = np.linspace(0, 1, 30)\n\nweights = simpson_2d_weights(len(x), len(y))\nfunction_values = evaluate_function(x, y)\ndx = x[1] - x[0]\ndy = y[1] - y[0]\nresult = integrate_2d(function_values, weights, dx, dy)\n```</code>", "metadata": {"problem_id": 371, "library_problem_id": 80, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 80}}
{"id": 372, "code": "```python\n    X, Y = np.meshgrid(x, y)\n    func_values = (np.cos(X)**4) + (np.sin(Y)**2)\n    \n    def simpson_weights(n):\n        weights = np.ones(n)\n        weights[1:-1:2] = 4\n        weights[2:-1:2] = 2\n        return weights\n    \n    x_weights = simpson_weights(len(x))\n    y_weights = simpson_weights(len(y))\n    \n    weights_2d = np.outer(y_weights, x_weights)\n    \n    weighted_values = func_values * weights_2d\n    \n    integral_value = np.sum(weighted_values)\n    \n    dx = x[1] - x[0]\n    dy = y[1] - y[0]\n    \n    integral_value *= dx * dy / 9\n    \n    return integral_value\n### END SOLUTION\n</code>", "metadata": {"problem_id": 372, "library_problem_id": 81, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 80}}
{"id": 373, "code": "```python\nimport numpy as np\n\ndef ecdf(x):\n  x_sorted = np.sort(x)\n  cdf = np.arange(1, len(x)+1) / len(x)\n  return x_sorted, cdf\n\ngrades = np.array((93.5,93,60.8,94.5,82,87.5,91.5,99.5,86,93.5,92.5,78,76,69,94.5,\n          89.5,92.8,78,65.5,98,98.5,92.3,95.5,76,91,95,61))\n\nsorted_grades, result = ecdf(grades)\n</code>\n", "metadata": {"problem_id": 373, "library_problem_id": 82, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 82}}
{"id": 374, "code": "```python\nimport numpy as np\n\ndef ecdf(x):\n  # normalize X to sum to 1\n  x = np.sort(x)\n  n = len(x)\n  y = np.arange(1, n+1) / n\n  return x, y\n\ngrades = np.array((93.5,93,60.8,94.5,82,87.5,91.5,99.5,86,93.5,92.5,78,76,69,94.5,\n          89.5,92.8,78,65.5,98,98.5,92.3,95.5,76,91,95,61))\neval = np.array([88, 87, 62])\n\nx, y = ecdf(grades)\nresult = np.interp(eval, x, y)\n```</code>", "metadata": {"problem_id": 374, "library_problem_id": 83, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 82}}
{"id": 375, "code": "```python\nimport numpy as np\n\ndef ecdf(x):\n    x = np.sort(x)\n    n = len(x)\n    if n == 0:\n        return np.array([])\n    return np.arange(1, n + 1) / n\n\ngrades = np.array((93.5,93,60.8,94.5,82,87.5,91.5,99.5,86,93.5,92.5,78,76,69,94.5,\n          89.5,92.8,78,65.5,98,98.5,92.3,95.5,76,91,95,61))\nthreshold = 0.5\n\nlongest_interval = (None, None)\nmax_length = 0\n\nfor i in range(len(grades)):\n    for j in range(i, len(grades)):\n        low_val = grades[i]\n        high_val = grades[j]\n        interval = grades[(grades >= low_val) & (grades <= high_val)]\n        \n        if len(interval) > 0:\n            ecdf_values = ecdf(grades[grades <= high_val])\n            \n            valid_interval = True\n            for val in interval:\n                ecdf_index = np.where(np.sort(grades) == val)[0][0]\n                ecdf_value = ecdf(grades)[ecdf_index]\n                if ecdf_value >= threshold:\n                    valid_interval = False\n                    break\n            \n            if valid_interval:\n                current_length = high_val - low_val\n                if current_length > max_length:\n                    max_length = current_length\n                    longest_interval = (low_val, high_val)\n\nif longest_interval == (None, None):\n    low, high = None, None\nelse:\n    low, high = longest_interval[0], longest_interval[1]\n```</code>", "metadata": {"problem_id": 375, "library_problem_id": 84, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 82}}
{"id": 376, "code": "```python\nnum_ones = int(size * one_ratio)\nnum_zeros = size - num_ones\nones_array = np.ones(num_ones, dtype=int)\nzeros_array = np.zeros(num_zeros, dtype=int)\ncombined_array = np.concatenate((ones_array, zeros_array))\nnp.random.shuffle(combined_array)\nnums = combined_array\n```", "metadata": {"problem_id": 376, "library_problem_id": 85, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 85}}
{"id": 377, "code": "```python\na_np = a.numpy()\n```\n", "metadata": {"problem_id": 377, "library_problem_id": 86, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 86}}
{"id": 378, "code": "```python\na_pt = torch.from_numpy(a)\n```", "metadata": {"problem_id": 378, "library_problem_id": 87, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 86}}
{"id": 379, "code": "```python\na_np = a.numpy()\n</code>\n", "metadata": {"problem_id": 379, "library_problem_id": 88, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 88}}
{"id": 380, "code": "```python\na_tf = tf.convert_to_tensor(a)\n```", "metadata": {"problem_id": 380, "library_problem_id": 89, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 88}}
{"id": 381, "code": "```python\nresult = np.argsort(a)[::-1]\n```</code>", "metadata": {"problem_id": 381, "library_problem_id": 90, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 90}}
{"id": 382, "code": "```python\nresult = np.argsort(a).tolist()\n</code>\n", "metadata": {"problem_id": 382, "library_problem_id": 91, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 90}}
{"id": 383, "code": "```python\nresult = np.argsort(a)[::-1][:N].tolist()\n```\n\n</code>", "metadata": {"problem_id": 383, "library_problem_id": 92, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 90}}
{"id": 384, "code": "```python\nimport numpy as np\nA = np.arange(16).reshape(4, 4)\nn = 5\nresult = np.linalg.matrix_power(A, n)\n```</code>", "metadata": {"problem_id": 384, "library_problem_id": 93, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 93}}
{"id": 385, "code": "```python\nresult = a.reshape(a.shape[0]//2, 2, a.shape[1]//2, 2).transpose(0,2,1,3).reshape(-1, 2, 2)\n```\n", "metadata": {"problem_id": 385, "library_problem_id": 94, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 94}}
{"id": 386, "code": "```python\npatches = []\nfor i in range(a.shape[0] - 1):\n    for j in range(a.shape[1] - 1):\n        patch = a[i:i+2, j:j+2]\n        patches.append(patch)\nresult = patches\n</code>\n", "metadata": {"problem_id": 386, "library_problem_id": 95, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 94}}
{"id": 387, "code": "```python\nresult = a.reshape(2, 2, 2, 2).transpose(0, 2, 1, 3).reshape(-1, 2, 2)\n```", "metadata": {"problem_id": 387, "library_problem_id": 96, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 94}}
{"id": 388, "code": "```python\n    num_patches_row = a.shape[0] // patch_size\n    num_patches_col = a.shape[1] // patch_size\n    result = []\n    for i in range(0, num_patches_row * patch_size, patch_size):\n        for j in range(0, num_patches_col * patch_size, patch_size):\n            patch = a[i:i+patch_size, j:j+patch_size]\n            result.append(patch)\n</code>\n```", "metadata": {"problem_id": 388, "library_problem_id": 97, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 94}}
{"id": 389, "code": "```python\nresult = a.reshape(h, w)\n```</code>", "metadata": {"problem_id": 389, "library_problem_id": 98, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 94}}
{"id": 390, "code": "```python\nnum_rows = a.shape[0] // patch_size\nnum_cols = a.shape[1] // patch_size\nresult = []\nfor i in range(num_rows):\n    for j in range(num_cols):\n        patch = a[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size]\n        result.append(patch)\n</code>\n", "metadata": {"problem_id": 390, "library_problem_id": 99, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 94}}
{"id": 391, "code": "```python\nresult = a[:, low:high]\n</code>", "metadata": {"problem_id": 391, "library_problem_id": 100, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 100}}
{"id": 392, "code": "```python\nresult = a[low:high]\n</code>", "metadata": {"problem_id": 392, "library_problem_id": 101, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 100}}
{"id": 393, "code": "```python\nimport numpy as np\na = np.array([[ 0,  1,  2,  3, 5, 6, 7, 8],\n              [ 4,  5,  6,  7, 5, 3, 2, 5],\n              [ 8,  9, 10, 11, 4, 5, 3, 5]])\nlow = 1\nhigh = 10\nmax_col = a.shape[1] - 1\nhigh = min(high, max_col)\nresult = a[:, low:high+1]\n```", "metadata": {"problem_id": 393, "library_problem_id": 102, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 100}}
{"id": 394, "code": "```python\nstring = string.strip()\nstring = ' '.join(string.split())\nrows = string.replace(']', '').replace('[', '').split(',')\ncols = rows[0].split()\nrows_count = len(rows)\ncols_count = len(cols)\na = np.fromstring(string.replace(']', '').replace('[', ''), sep=' ')\na = a.reshape((rows_count, cols_count))\n</code>\n", "metadata": {"problem_id": 394, "library_problem_id": 103, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 103}}
{"id": 395, "code": "```python\ndef loguniform(n, min_val, max_val, base):\n    if min_val <= 0 or max_val <= 0:\n        raise ValueError(\"min_val and max_val must be positive\")\n    if min_val >= max_val:\n        raise ValueError(\"min_val must be less than max_val\")\n\n    log_min = np.log(min_val)/np.log(base)\n    log_max = np.log(max_val)/np.log(base)\n    \n    log_values = np.random.uniform(log_min, log_max, n)\n    return base ** log_values\n\nresult = loguniform(n, min, max, np.e)\n</code>\n", "metadata": {"problem_id": 395, "library_problem_id": 104, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 104}}
{"id": 396, "code": "```python\ndef loguniform(n, min_log, max_log):\n    log_uniform = np.random.uniform(min_log, max_log, n)\n    uniform = np.exp(log_uniform)\n    return uniform\n\nresult = loguniform(n, min, max)\n</code>\n", "metadata": {"problem_id": 396, "library_problem_id": 105, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 104}}
{"id": 397, "code": "```python\nimport numpy as np\ndef f(min=1, max=np.e, n=10000):\n    # return the solution in this function\n    # result = f(min=1, max=np.e, n=10000)\n    ### BEGIN SOLUTION\n    def loguniform(n, min, max, base=np.e):\n        if min <= 0 or max <= 0:\n            raise ValueError(\"min and max must be positive numbers\")\n        if min >= max:\n            raise ValueError(\"min must be less than max\")\n        if not isinstance(n, int) or n <= 0:\n            raise ValueError(\"n must be a positive integer\")\n\n        log_min = np.log(min) / np.log(base)\n        log_max = np.log(max) / np.log(base)\n        uniform_values = np.random.uniform(log_min, log_max, n)\n        return base ** uniform_values\n    return loguniform(n, min, max)\n    ### END SOLUTION\n</code>", "metadata": {"problem_id": 397, "library_problem_id": 106, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 104}}
{"id": 398, "code": "```python\nB = pd.Series(index=A.index, dtype='float64')\nB[0] = a * A[0]\nfor t in range(1, len(A)):\n    B[t] = a * A[t] + b * B[t-1]\n</code>", "metadata": {"problem_id": 398, "library_problem_id": 107, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 107}}
{"id": 399, "code": "```python\nB = pd.Series(np.zeros(len(A)))\nB[0] = a * A[0]\nif len(A) > 1:\n    B[1] = a * A[1] + b * B[0]\n    for t in range(2, len(A)):\n        B[t] = a * A[t] + b * B[t-1] + c * B[t-2]\n</code>", "metadata": {"problem_id": 399, "library_problem_id": 108, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 107}}
{"id": 400, "code": "```python\nresult = np.array([]).reshape((0,))\n```</code>", "metadata": {"problem_id": 400, "library_problem_id": 109, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 109}}
{"id": 401, "code": "```python\nresult = np.empty((3, 0))\n```</code>", "metadata": {"problem_id": 401, "library_problem_id": 110, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 109}}
{"id": 402, "code": "```python\nimport numpy as np\n\ndef sub2ind(dims, *index):\n    if len(dims) != len(index):\n        raise ValueError(\"Number of subscripts must match number of dimensions.\")\n\n    linear_index = 0\n    multiplier = 1\n    for i, dim in enumerate(dims):\n        if not (0 <= index[i] < dim):\n            raise ValueError(f\"Index {index[i]} is out of bounds for dimension {i} with size {dim}.\")\n        linear_index += index[i] * multiplier\n        multiplier *= dim\n    return linear_index\n\ndims = (3, 4, 2)\na = np.random.rand(*dims)\nindex = (1, 0, 1)\nresult = sub2ind(dims, *index) -1\n</code>\n", "metadata": {"problem_id": 402, "library_problem_id": 111, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 111}}
{"id": 403, "code": "```python\ndef sub2ind(dims, index):\n    linear_index = 0\n    multiplier = 1\n    if len(dims) != len(index):\n        raise ValueError(\"Dimensions and index must have the same length.\")\n    for i in range(len(dims)):\n        if not (0 <= index[i] < dims[i]):\n            raise IndexError(\"Index is out of bounds.\")\n        linear_index += index[i] * multiplier\n        multiplier *= dims[i]\n    return linear_index\n\nresult = sub2ind(dims, index)\n</code>\n", "metadata": {"problem_id": 403, "library_problem_id": 112, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 111}}
{"id": 404, "code": "```python\nvalues = np.zeros(2, dtype=[('a', 'i4'), ('b', 'f4'), ('c', 'f4')])\ndf = pd.DataFrame(values, index=index)\n```\n\n</code>", "metadata": {"problem_id": 404, "library_problem_id": 113, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 113}}
{"id": 405, "code": "```python\nresult = np.zeros(np.max(accmap)+1)\nnp.add.at(result, accmap, a)\n```</code>", "metadata": {"problem_id": 405, "library_problem_id": 114, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 114}}
{"id": 406, "code": "```python\nresult = np.zeros(np.bincount(index).size)\nfor i, val in enumerate(a):\n    result[index[i]] = max(result[index[i]], val)\n</code>\n", "metadata": {"problem_id": 406, "library_problem_id": 115, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 114}}
{"id": 407, "code": "```python\nimport numpy as np\noffset = abs(np.min(accmap)) if np.min(accmap) < 0 else 0\nshifted_accmap = accmap + offset\nsize = np.max(shifted_accmap) + 1\nresult = np.bincount(shifted_accmap, weights=a, minlength=size)\n```</code>", "metadata": {"problem_id": 407, "library_problem_id": 116, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 114}}
{"id": 408, "code": "```python\nimport numpy as np\nresult = np.full(np.max(index) + 1, np.inf)\nfor i, idx in enumerate(index):\n    result[idx] = min(result[idx], a[i])\nresult = np.array([x for x in result if x != np.inf])\n```\n\n</code>", "metadata": {"problem_id": 408, "library_problem_id": 117, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 114}}
{"id": 409, "code": "```python\nx = np.array(x)\ny = np.array(y)\nz = elementwise_function(x, y)\n```</code>", "metadata": {"problem_id": 409, "library_problem_id": 118, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 118}}
{"id": 410, "code": "```python\nimport numpy as np\n\nprobabilit = [0.333, 0.334, 0.333]\nlista_elegir = [(3, 3), (3, 4), (3, 5)]\nsamples = 1000\n\nprobabilit = np.array(probabilit)\nprobabilit /= probabilit.sum()\nresult = np.random.choice(lista_elegir, samples, p=probabilit)\n</code>\n", "metadata": {"problem_id": 410, "library_problem_id": 119, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 119}}
{"id": 411, "code": "```python\ndef pad_and_slice(array, row_slice, col_slice):\n    row_start, row_end = row_slice.start, row_slice.stop\n    col_start, col_end = col_slice.start, col_slice.stop\n    \n    row_pad_before = max(0, -row_start)\n    row_pad_after = max(0, row_end - array.shape[0])\n    col_pad_before = max(0, -col_start)\n    col_pad_after = max(0, col_end - array.shape[1])\n    \n    pad_width = ((row_pad_before, row_pad_after), (col_pad_before, col_pad_after))\n    padded_array = np.pad(array, pad_width, mode='constant')\n    \n    row_start += row_pad_before\n    row_end += row_pad_before\n    col_start += col_pad_before\n    col_end += col_pad_before\n    \n    return padded_array[row_start:row_end, col_start:col_end]\n\nresult = pad_and_slice(a, slice(low_index, high_index), slice(low_index, high_index))\n```</code>", "metadata": {"problem_id": 411, "library_problem_id": 120, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 120}}
{"id": 412, "code": "```python\nresult = x[x >= 0]\n```</code>", "metadata": {"problem_id": 412, "library_problem_id": 121, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 121}}
{"id": 413, "code": "```python\nimport numpy as np\nx = np.array([-2+1j, -1.4, -1.1, 0, 1.2, 2.2+2j, 3.1, 4.4, 8.3, 9.9, 10+0j, 14, 16.2])\nresult = x[x.imag != 0]\n```\n\n</code>", "metadata": {"problem_id": 413, "library_problem_id": 122, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 121}}
{"id": 414, "code": "```python\nn_bins = len(data) // bin_size\ntruncated_data = data[:n_bins * bin_size]\nreshaped_data = truncated_data.reshape((n_bins, bin_size))\nbin_data_mean = np.mean(reshaped_data, axis=1)\n```</code>", "metadata": {"problem_id": 414, "library_problem_id": 123, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 123}}
{"id": 415, "code": "```python\nn_bins = len(data) // bin_size\nreshaped_data = data[:n_bins * bin_size].reshape((n_bins, bin_size))\nbin_data_max = np.max(reshaped_data, axis=1)\n```</code>", "metadata": {"problem_id": 415, "library_problem_id": 124, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 123}}
{"id": 416, "code": "```python\nimport numpy as np\ndata = np.array([[4, 2, 5, 6, 7],\n[ 5, 4, 3, 5, 7]])\nbin_size = 3\n\nnum_bins = data.shape[1] // bin_size\ntruncated_data = data[:, :num_bins * bin_size]\nreshaped_data = truncated_data.reshape(data.shape[0], num_bins, bin_size)\nbin_data_mean = np.mean(reshaped_data, axis=2)\n```", "metadata": {"problem_id": 416, "library_problem_id": 125, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 123}}
{"id": 417, "code": "```python\nreversed_data = np.flip(data)\nnum_bins = len(data) // bin_size\nbinned_data = reversed_data[:num_bins * bin_size].reshape((num_bins, bin_size))\nbin_data_mean = np.flip(np.mean(binned_data, axis=1))\n```\n\n</code>", "metadata": {"problem_id": 417, "library_problem_id": 126, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 123}}
{"id": 418, "code": "```python\nimport numpy as np\n\nnum_bins = data.shape[1] // bin_size\ntruncated_length = num_bins * bin_size\nif truncated_length > 0:\n    sliced_data = data[:, -truncated_length:]\n    bin_data = sliced_data.reshape(data.shape[0], num_bins, bin_size)\n    bin_data_mean = np.mean(bin_data, axis=2)\nelse:\n    bin_data_mean = np.array([])\n```\n\n</code>", "metadata": {"problem_id": 418, "library_problem_id": 127, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 123}}
{"id": 419, "code": "```python\n    data = np.array(data)\n    num_bins = data.shape[1] // bin_size\n    start_index = data.shape[1] % bin_size\n    binned_data = []\n    for row in data:\n        if start_index != 0:\n            row = row[start_index:]\n        row = row.reshape((num_bins, bin_size))\n        binned_data.append(np.mean(row, axis=1))\n    bin_data_mean = np.array(binned_data)\n```</code>", "metadata": {"problem_id": 419, "library_problem_id": 128, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 123}}
{"id": 420, "code": "```python\ndef smoothclamp(x, min, max):\n    if min > max:\n        return min\n    if x < min:\n        return min\n    if x > max:\n        return max\n    margin = (max - min) * 0.1\n    if min <= x <= min + margin:\n        def smoothstep(x):\n            return 3 * x**2 - 2 * x**3\n        normalized_x = (x - min) / margin\n        return min + smoothstep(normalized_x) * margin\n    if max - margin <= x <= max:\n        def smoothstep(x):\n            return 3 * x**2 - 2 * x**3\n        normalized_x = (x - (max - margin)) / margin\n        return max - smoothstep(normalized_x) * margin\n    return x\n```</code>", "metadata": {"problem_id": 420, "library_problem_id": 129, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 129}}
{"id": 421, "code": "```python\ndef smoothstep(t, N):\n    t = np.clip(t, 0.0, 1.0)\n    result = t**N * (np.poly1d([np.math.factorial(N + 1) / (np.math.factorial(N + 1 - k) * np.math.factorial(k)) * (-1)**k for k in range(N + 1)][::-1]))(t)\n    return result\n\ndef smoothclamp(x, min_val, max_val, N):\n    if min_val > max_val:\n        min_val, max_val = max_val, min_val\n\n    if max_val == min_val:\n        return float(min_val)\n\n    t = (x - min_val) / (max_val - min_val)\n    t = smoothstep(t, N)\n    \n    return float(min_val + t * (max_val - min_val))\n```</code>", "metadata": {"problem_id": 421, "library_problem_id": 130, "library": "Numpy", "test_case_cnt": 4, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 129}}
{"id": 422, "code": "```python\nimport numpy as np\n\ndef circular_shift(arr, shift):\n    shifted_arr = np.roll(arr, shift)\n    return shifted_arr\n\ndef cross_correlation(arr1, arr2):\n    return np.sum(arr1 * arr2)\n\ndef circular_cross_correlation(a, b):\n    results = []\n    for shift in range(len(b)):\n        shifted_b = circular_shift(b, shift)\n        correlation = cross_correlation(a, shifted_b)\n        results.append(correlation)\n    return np.array(results)\n\nresult = circular_cross_correlation(a, b)\n```\n\n</code>", "metadata": {"problem_id": 422, "library_problem_id": 131, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 131}}
{"id": 423, "code": "```python\nresult = df.unstack('colu').unstack('major').values.reshape(4,15,5)\n```</code>", "metadata": {"problem_id": 423, "library_problem_id": 132, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 132}}
{"id": 424, "code": "```python\nresult = df.values.reshape(15, 5, 4).transpose(0, 2, 1)\n```</code>", "metadata": {"problem_id": 424, "library_problem_id": 133, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 132}}
{"id": 425, "code": "```python\nimport numpy as np\na = np.array([1, 2, 3, 4, 5])\nm = 8\n\ndef int_to_binary_array(num, m):\n    binary_array = np.zeros(m, dtype=int)\n    for i in range(m - 1, -1, -1):\n        binary_array[m - 1 - i] = (num >> i) & 1\n    return binary_array\n\nresult = np.stack([int_to_binary_array(num, m) for num in a])\n</code>", "metadata": {"problem_id": 425, "library_problem_id": 134, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 134}}
{"id": 426, "code": "```python\n    def int_to_binary_array(num, m):\n        binary = bin(num)[2:]\n        if len(binary) < m:\n            binary = '0' * (m - len(binary)) + binary\n        elif len(binary) > m:\n            binary = binary[-m:]\n        return np.array([int(bit) for bit in binary])\n\n    result = np.stack([int_to_binary_array(num, m) for num in a])\n```\n\n</code>", "metadata": {"problem_id": 426, "library_problem_id": 135, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 134}}
{"id": 427, "code": "```python\nbinary_arrays = []\nfor num in a:\n    binary_string = bin(num)[2:].zfill(m)\n    binary_array = np.array([int(bit) for bit in binary_string])\n    binary_arrays.append(binary_array)\nstacked_array = np.stack(binary_arrays)\nresult = np.bitwise_xor.reduce(stacked_array)\n</code>\n", "metadata": {"problem_id": 427, "library_problem_id": 136, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 134}}
{"id": 428, "code": "```python\nimport numpy as np\na = np.array([0, 1, 2, 5, 6, 7, 8, 8, 8, 10, 29, 32, 45])\nmean = np.mean(a)\nstd = np.std(a)\nlower_bound = mean - 3 * std\nupper_bound = mean + 3 * std\nresult = (lower_bound, upper_bound)\n</code>\n", "metadata": {"problem_id": 428, "library_problem_id": 137, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 137}}
{"id": 429, "code": "```python\nmean = np.mean(a)\nstd = np.std(a)\nlower_bound = mean - 2 * std\nupper_bound = mean + 2 * std\nresult = (lower_bound, upper_bound)\n```", "metadata": {"problem_id": 429, "library_problem_id": 138, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 137}}
{"id": 430, "code": "```python\n    mean = np.mean(a)\n    std = np.std(a)\n    lower_bound = mean - 3 * std\n    upper_bound = mean + 3 * std\n    return (lower_bound, upper_bound)\n### END SOLUTION\n</code>\n```", "metadata": {"problem_id": 430, "library_problem_id": 139, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 137}}
{"id": 431, "code": "```python\nimport numpy as np\nmean = np.mean(a)\nstd = np.std(a)\nlower_bound = mean - 2 * std\nupper_bound = mean + 2 * std\nresult = (a < lower_bound) | (a > upper_bound)\n```</code>", "metadata": {"problem_id": 431, "library_problem_id": 140, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 137}}
{"id": 432, "code": "```python\nimport numpy as np\nDataArray = np.arange(-5.5, 10.5)\npercentile = 50\nimport numpy.ma as ma\nmasked_data = ma.masked_where(DataArray < 0, DataArray)\nprob = np.percentile(masked_data.compressed(), percentile)\n</code>", "metadata": {"problem_id": 432, "library_problem_id": 141, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 141}}
{"id": 433, "code": "```python\na = np.array([[0, 3, 1, 3], [3, 0, 0, 0], [1, 0, 0, 0], [3, 0, 0, 0]])\nzero_rows = 0\nzero_cols = 0\na[zero_rows, :] = 0\na[:, zero_cols] = 0\n```\n\n</code>", "metadata": {"problem_id": 433, "library_problem_id": 142, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 142}}
{"id": 434, "code": "```python\nimport numpy as np\na = np.array([[0, 3, 1, 3], [3, 0, 0, 0], [1, 0, 0, 0], [3, 0, 0, 0]])\nzero_rows = [1, 3]\nzero_cols = [1, 2]\n\na = np.copy(a)\nfor row in zero_rows:\n    a[row, :] = 0\nfor col in zero_cols:\n    a[:, col] = 0\n</code>", "metadata": {"problem_id": 434, "library_problem_id": 143, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 142}}
{"id": 435, "code": "```python\na[1, :] = 0\na[:, 0] = 0\n</code>\n", "metadata": {"problem_id": 435, "library_problem_id": 144, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 142}}
{"id": 436, "code": "```python\nmax_ind = np.argmax(a, axis=1)\nmask = np.zeros_like(a, dtype=bool)\nmask[np.arange(a.shape[0]), max_ind] = True\n```\n\n</code>", "metadata": {"problem_id": 436, "library_problem_id": 145, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 145}}
{"id": 437, "code": "```python\nimport numpy as np\na = np.array([[0, 1], [2, 1], [4, 8]])\nmin_ind = np.argmin(a, axis=1)\nmask = np.zeros(a.shape, dtype=bool)\nrow_ind = np.arange(a.shape[0])\nmask[row_ind, min_ind] = True\n</code>\n", "metadata": {"problem_id": 437, "library_problem_id": 146, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 145}}
{"id": 438, "code": "```python\npost = np.array(post)\ndistance = np.array(distance)\ncorrelation_matrix = np.corrcoef(post, distance)\nresult = correlation_matrix[0, 1]\n```\n\n</code>", "metadata": {"problem_id": 438, "library_problem_id": 147, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 147}}
{"id": 439, "code": "```python\nimport numpy as np\nX = np.random.randint(2, 10, (5, 6))\nN = X.shape[1]\nM = X.shape[0]\nresult = np.zeros((N, M, M))\nfor i in range(N):\n    xi = X[:, i]\n    result[i, :, :] = np.outer(xi, xi)\n```\n", "metadata": {"problem_id": 439, "library_problem_id": 148, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 148}}
{"id": 440, "code": "```python\nimport numpy as np\n\nN, M, _ = Y.shape\nX = np.zeros((M, N))\nfor i in range(N):\n    eigenvalues, eigenvectors = np.linalg.eig(Y[i])\n    largest_eigenvalue_index = np.argmax(eigenvalues)\n    largest_eigenvector = eigenvectors[:, largest_eigenvalue_index]\n    x_i = largest_eigenvector * np.sqrt(eigenvalues[largest_eigenvalue_index])\n    X[:, i] = x_i\n</code></code>", "metadata": {"problem_id": 440, "library_problem_id": 149, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 148}}
{"id": 441, "code": "```python\nis_contained = number in a\n```</code>", "metadata": {"problem_id": 441, "library_problem_id": 150, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 150}}
{"id": 442, "code": "```python\nmask = ~np.isin(A, B)\nC = A[mask]\n```</code>", "metadata": {"problem_id": 442, "library_problem_id": 151, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 151}}
{"id": 443, "code": "```python\nC = A[np.isin(A, B)]\n```", "metadata": {"problem_id": 443, "library_problem_id": 152, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 151}}
{"id": 444, "code": "```python\nranges = list(zip(B[:-1], B[1:]))\nC = A[np.logical_or.reduce([((A > r[0]) & (A < r[1])) if r[0]!=r[1] else ((A > r[0]) & (A < r[1])) for r in ranges])]\n```</code>", "metadata": {"problem_id": 444, "library_problem_id": 153, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 151}}
{"id": 445, "code": "```python\nrank = rankdata(a)\nmax_rank = np.max(rank)\nresult = (max_rank + 1 - rank).astype(int)\n</code>\n", "metadata": {"problem_id": 445, "library_problem_id": 154, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 154}}
{"id": 446, "code": "```python\nindexed_array = [(value, index) for index, value in enumerate(a)]\nsorted_array = sorted(indexed_array, key=lambda x: (x[0], -x[1]), reverse=True)\nresult = np.empty_like(a, dtype=int)\nfor i, (value, index) in enumerate(sorted_array):\n    result[index] = len(a) - 1 - i\n</code>\n", "metadata": {"problem_id": 446, "library_problem_id": 155, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 154}}
{"id": 447, "code": "```python\n    ranked = rankdata(a).astype(int)\n    max_rank = np.max(ranked)\n    reversed_rank = max_rank + 1 - ranked\n    return reversed_rank\n```", "metadata": {"problem_id": 447, "library_problem_id": 156, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 154}}
{"id": 448, "code": "```python\nimport numpy as np\nx_dists = np.array([[ 0, -1, -2],\n                 [ 1,  0, -1],\n                 [ 2,  1,  0]])\n\ny_dists = np.array([[ 0, 1, -2],\n                 [ -1,  0, 1],\n                 [ -2,  1,  0]])\ndists = np.stack((x_dists, y_dists), axis=-1)\n```</code>", "metadata": {"problem_id": 448, "library_problem_id": 157, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 157}}
{"id": 449, "code": "```python\nimport numpy as np\nx_dists = np.array([[ 0, -1, -2],\n                 [ 1,  0, -1],\n                 [ 2,  1,  0]])\n\ny_dists = np.array([[ 0, -1, -2],\n                 [ 1,  0, -1],\n                 [ 2,  1,  0]])\ndists = np.stack((x_dists, y_dists), axis=-1)\n```", "metadata": {"problem_id": 449, "library_problem_id": 158, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 157}}
{"id": 450, "code": "```python\nresult = a[:, second, third]\n```\n\n</code>", "metadata": {"problem_id": 450, "library_problem_id": 159, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 159}}
{"id": 451, "code": "```python\narr = np.zeros((20, 10, 10, 2))\n```", "metadata": {"problem_id": 451, "library_problem_id": 160, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 160}}
{"id": 452, "code": "```python\nl1 = np.sum(np.abs(X), axis=1)\nresult = X / l1.reshape(-1, 1)\n```</code>", "metadata": {"problem_id": 452, "library_problem_id": 161, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 161}}
{"id": 453, "code": "```python\nnorms = LA.norm(X, ord=2, axis=1, keepdims=True)\nresult = X / norms\n```</code>", "metadata": {"problem_id": 453, "library_problem_id": 162, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 161}}
{"id": 454, "code": "```python\nnorms = np.max(np.abs(X), axis=1, keepdims=True)\nresult = X / norms\n```\n\n</code>", "metadata": {"problem_id": 454, "library_problem_id": 163, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 161}}
{"id": 455, "code": "```python\nimport numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame({'properties_path': ['/za/', '/en/', 'blog/article', 'credit-card-readers/', 'signup', 'complete', 'promo', np.nan]})\n\nconditions = [\n    df[\"properties_path\"].str.contains('blog', na=False),\n    df[\"properties_path\"].str.contains('credit-card-readers/|machines|poss|team|transaction_fees', na=False),\n    df[\"properties_path\"].str.contains('signup|sign-up|create-account|continue|checkout', na=False),\n    df[\"properties_path\"].str.contains('complete', na=False),\n    df[\"properties_path\"] == '/za/',\n    df[\"properties_path\"].str.contains('promo', na=False)\n]\n\nchoices = [\"blog\", \"info_pages\", \"signup\", \"completed\", \"home_page\", \"promo\"]\n\ndf[\"page_type\"] = np.select(conditions, choices, default=np.nan)\nresult = df\n</code></code>", "metadata": {"problem_id": 455, "library_problem_id": 164, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 164}}
{"id": 456, "code": "```python\nn = a.shape[0]\nresult = np.zeros((n, n))\nfor i in range(n):\n    for j in range(n):\n        result[i, j] = np.linalg.norm(a[i] - a[j])\n</code></code>", "metadata": {"problem_id": 456, "library_problem_id": 165, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 165}}
{"id": 457, "code": "```python\nn = a.shape[0]\nresult = np.zeros((n, n))\nfor i in range(n):\n    for j in range(i, n):\n        distance = np.linalg.norm(a[i] - a[j])\n        result[i, j] = distance\n        result[j, i] = distance\n```\n\n</code>", "metadata": {"problem_id": 457, "library_problem_id": 166, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 165}}
{"id": 458, "code": "```python\nn = a.shape[0]\nresult = np.zeros((n, n))\nfor i in range(n):\n    for j in range(i, n):\n        result[i, j] = np.linalg.norm(a[i] - a[j])\n```</code>", "metadata": {"problem_id": 458, "library_problem_id": 167, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 165}}
{"id": 459, "code": "```python\nNA = np.asarray(A, dtype=float)\nAVG = np.mean(NA, axis=0)\n```", "metadata": {"problem_id": 459, "library_problem_id": 168, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 168}}
{"id": 460, "code": "```python\nimport numpy as np\n\ndef convert_to_float(x):\n    if x == 'inf':\n        return np.inf\n    else:\n        return float(x)\n\nA = ['inf', '33.33', '33.33', '33.37']\nNA = np.array([convert_to_float(x) for x in A])\nAVG = np.mean(NA)\n```\n", "metadata": {"problem_id": 460, "library_problem_id": 169, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 168}}
{"id": 461, "code": "```python\nimport numpy as np\nnew_A = []\nfor s in A:\n    if s == 'np.inf':\n        new_A.append(np.inf)\n    else:\n        new_A.append(float(s))\nAVG = np.mean(np.asarray(new_A))\n```\n", "metadata": {"problem_id": 461, "library_problem_id": 170, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 168}}
{"id": 462, "code": "```python\nfiltered_arr = a[a != 0]\nresult_list = []\nif len(filtered_arr) > 0:\n    result_list.append(filtered_arr[0])\n    for i in range(1, len(filtered_arr)):\n        if filtered_arr[i] != filtered_arr[i-1]:\n            result_list.append(filtered_arr[i])\nresult = np.array(result_list)\n```\n\n</code>", "metadata": {"problem_id": 462, "library_problem_id": 171, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 171}}
{"id": 463, "code": "```python\n    filtered_arr = a[a != 0]\n    unique_arr = []\n    if filtered_arr.size > 0:\n        unique_arr.append(filtered_arr[0])\n        for i in range(1, len(filtered_arr)):\n            if filtered_arr[i] != filtered_arr[i-1]:\n                unique_arr.append(filtered_arr[i])\n    result = np.array(unique_arr).reshape(-1, 1)\n```", "metadata": {"problem_id": 463, "library_problem_id": 172, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 171}}
{"id": 464, "code": "```python\nlat_flat = lat.flatten()\nlon_flat = lon.flatten()\nval_flat = val.flatten()\ndf = pd.DataFrame({'lat': lat_flat, 'lon': lon_flat, 'val': val_flat})\n</code>\n", "metadata": {"problem_id": 464, "library_problem_id": 173, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 173}}
{"id": 465, "code": "```python\n    lat_flat = lat.flatten()\n    lon_flat = lon.flatten()\n    val_flat = val.flatten()\n    df = pd.DataFrame({'lat': lat_flat, 'lon': lon_flat, 'val': val_flat})\n    return df\n### END SOLUTION\n```", "metadata": {"problem_id": 465, "library_problem_id": 174, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 173}}
{"id": 466, "code": "```python\nlat_flat = lat.flatten()\nlon_flat = lon.flatten()\nval_flat = val.flatten()\ndf = pd.DataFrame({'lat': lat_flat, 'lon': lon_flat, 'val': val_flat})\ndf['maximum'] = df.max(axis=1)\n</code>\n", "metadata": {"problem_id": 466, "library_problem_id": 175, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 173}}
{"id": 467, "code": "```python\ndef rolling_window_2d(array, window_size):\n    result = []\n    rows, cols = array.shape\n    window_rows, window_cols = window_size\n    for i in range(rows):\n        for j in range(cols):\n            row_start = i - window_rows // 2\n            row_end = i + window_rows // 2 + 1\n            col_start = j - window_cols // 2\n            col_end = j + window_cols // 2 + 1\n\n            row_start_clip = max(0, row_start)\n            row_end_clip = min(rows, row_end)\n            col_start_clip = max(0, col_start)\n            col_end_clip = min(cols, col_end)\n\n            result.append(array[row_start_clip:row_end_clip, col_start_clip:col_end_clip])\n    return result\n\nresult = rolling_window_2d(a, size)\n</code>\n", "metadata": {"problem_id": 467, "library_problem_id": 176, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 176}}
{"id": 468, "code": "```python\nresult = []\nrows, cols = a.shape\nfor i in range(rows):\n    for j in range(cols):\n        row_start = max(0, i - size[0] // 2)\n        row_end = min(rows, i + size[0] // 2 + 1)\n        col_start = max(0, j - size[1] // 2)\n        col_end = min(cols, j + size[1] // 2 + 1)\n        result.append(a[row_start:row_end, col_start:col_end])\n```\n\n</code>", "metadata": {"problem_id": 468, "library_problem_id": 177, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 176}}
{"id": 469, "code": "```python\nimport numpy as np\nresult = np.nanmean(a)\n```\n", "metadata": {"problem_id": 469, "library_problem_id": 178, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 178}}
{"id": 470, "code": "```python\n    a_finite = a[np.isfinite(a)]\n    if len(a_finite) == 0:\n        return np.inf + 0j\n    else:\n        return np.mean(a_finite)\n### END SOLUTION\n</code>\n```", "metadata": {"problem_id": 470, "library_problem_id": 179, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 178}}
{"id": 471, "code": "```python\n    slicing_strings = [slice(None)] * (Z.ndim - 1) + [slice(-1, None)]\n    result = Z[tuple(slicing_strings)]\n</code>", "metadata": {"problem_id": 471, "library_problem_id": 180, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 180}}
{"id": 472, "code": "```python\nimport numpy as np\nndim = np.ndim(a)\nresult = a[(-1,) + (slice(None),) * (ndim - 1)]\n```</code>", "metadata": {"problem_id": 472, "library_problem_id": 181, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 180}}
{"id": 473, "code": "```python\nimport numpy as np\n\ndef are_equal(arr1, arr2):\n    return np.array_equal(arr1, arr2)\n\ndef is_member(arr, arr_list):\n    for element in arr_list:\n        if are_equal(arr, element):\n            return True\n    return False\n\ndef remove_array(arr, arr_list):\n    for i, element in enumerate(arr_list):\n        if are_equal(arr, element):\n            del arr_list[i]\n            return arr_list\n    return arr_list\n\nc = np.array([[[ 75, 763]],\n              [[ 57, 763]],\n              [[ 57, 749]],\n              [[ 75, 749]]])\nCNTS = [np.array([[[  78, 1202]],\n                  [[  63, 1202]],\n                  [[  63, 1187]],\n                  [[  78, 1187]]]),\n        np.array([[[ 75, 763]],\n                  [[ 57, 763]],\n                  [[ 57, 749]],\n                  [[ 75, 749]]]),\n        np.array([[[ 72, 742]],\n                  [[ 58, 742]],\n                  [[ 57, 741]],\n                  [[ 57, 727]],\n                  [[ 58, 726]],\n                  [[ 72, 726]]]),\n        np.array([[[ 66, 194]],\n                  [[ 51, 194]],\n                  [[ 51, 179]],\n                  [[ 66, 179]]])]\n\nresult = is_member(c, CNTS)\n</code>", "metadata": {"problem_id": 473, "library_problem_id": 182, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 182}}
{"id": 474, "code": "```python\nimport numpy as np\n\ndef array_in_list(arr, list_of_arrs):\n    def compare_arrays(arr1, arr2):\n        return np.array_equal(arr1, arr2, equal_nan=True)\n\n    for element in list_of_arrs:\n        if compare_arrays(arr, element):\n            return True\n    return False\n\nc = np.array([[[ 75, 763]],\n              [[ 57, 763]],\n              [[ np.nan, 749]],\n              [[ 75, 749]]])\nCNTS = [np.array([[[  np.nan, 1202]],\n                  [[  63, 1202]],\n                  [[  63, 1187]],\n                  [[  78, 1187]]]),\n        np.array([[[ 75, 763]],\n                  [[ 57, 763]],\n                  [[ np.nan, 749]],\n                  [[ 75, 749]]]),\n        np.array([[[ 72, 742]],\n                  [[ 58, 742]],\n                  [[ 57, 741]],\n                  [[ 57, np.nan]],\n                  [[ 58, 726]],\n                  [[ 72, 726]]]),\n        np.array([[[ np.nan, 194]],\n                  [[ 51, 194]],\n                  [[ 51, 179]],\n                  [[ 66, 179]]])]\n\nresult = array_in_list(c, CNTS)\n```</code>", "metadata": {"problem_id": 474, "library_problem_id": 183, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 182}}
{"id": 475, "code": "```python\nx = np.array([0, 1])\ny = np.array([0, 1])\nf = intp.interp2d(x, y, np.arange(0, 4, 1).reshape(2, 2), kind='linear')\nresult = f(x_new, y_new)\n```</code>", "metadata": {"problem_id": 475, "library_problem_id": 184, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 184}}
{"id": 476, "code": "```python\ndf = pd.DataFrame(data)\ndf[name] = df.groupby('D')['Q'].cumsum()\n```</code>", "metadata": {"problem_id": 476, "library_problem_id": 185, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 185}}
{"id": 477, "code": "```python\ni = np.diag(i)\n```</code>", "metadata": {"problem_id": 477, "library_problem_id": 186, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 186}}
{"id": 478, "code": "```python\nimport numpy as np\na = np.array([[1,0,2,3],[0,5,3,4],[2,3,2,10],[3,4, 10, 7]])\na = np.diag(np.diag(a))\n```\n", "metadata": {"problem_id": 478, "library_problem_id": 187, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 187}}
{"id": 479, "code": "```python\nstart = pd.to_datetime(start)\nend = pd.to_datetime(end)\ntotal_duration = end - start\nfractions = np.linspace(0, 1, n)\ntime_deltas = total_duration * fractions\nresult = start + time_deltas\n```</code>", "metadata": {"problem_id": 479, "library_problem_id": 188, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 188}}
{"id": 480, "code": "```python\nresult = -1\nfor i in range(len(x)):\n    if x[i] == a and y[i] == b:\n        result = i\n        break\n```</code>", "metadata": {"problem_id": 480, "library_problem_id": 189, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 189}}
{"id": 481, "code": "```python\nresult = np.where((x == a) & (y == b))[0]\n```\n\n</code>", "metadata": {"problem_id": 481, "library_problem_id": 190, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Semantic", "perturbation_origin_id": 189}}
{"id": 482, "code": "```python\nA = np.vstack([x**2, x, np.ones(len(x))]).T\nresult = np.linalg.lstsq(A, y, rcond=None)[0]\n</code>\n", "metadata": {"problem_id": 482, "library_problem_id": 191, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 191}}
{"id": 483, "code": "```python\nimport numpy as np\nx = [-1, 2, 5, 100]\ny = [123, 456, 789, 1255]\ndegree = 3\nresult = np.polyfit(x, y, degree)\n```</code>", "metadata": {"problem_id": 483, "library_problem_id": 192, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 191}}
{"id": 484, "code": "```python\ndf = df.apply(lambda x: x - a[x.name], axis=1)\n```\n\n</code>", "metadata": {"problem_id": 484, "library_problem_id": 193, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 193}}
{"id": 485, "code": "```python\nresult = np.einsum('ijz,zk->ijk', A, B)\n```\n\n</code>", "metadata": {"problem_id": 485, "library_problem_id": 194, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 194}}
{"id": 486, "code": "```python\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\na = np.array([[-1, 2], [-0.5, 6]])\na_reshaped = a.reshape(-1, 1)\nscaler = MinMaxScaler()\nresult = scaler.fit_transform(a_reshaped).reshape(a.shape)\n```</code>", "metadata": {"problem_id": 486, "library_problem_id": 195, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 195}}
{"id": 487, "code": "```python\nresult = np.zeros_like(arr)\nfor i in range(arr.shape[0]):\n    row = arr[i, :]\n    min_val = np.min(row)\n    max_val = np.max(row)\n    if max_val == min_val:\n        result[i, :] = np.zeros_like(row)\n    else:\n        result[i, :] = (row - min_val) / (max_val - min_val)\n</code>", "metadata": {"problem_id": 487, "library_problem_id": 196, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 195}}
{"id": 488, "code": "```python\noriginal_shape = a.shape\na_reshaped = a.reshape(a.shape[0], -1)\nscaler = MinMaxScaler()\na_normalized = scaler.fit_transform(a_reshaped)\nresult = a_normalized.reshape(original_shape)\n```\n\n</code>", "metadata": {"problem_id": 488, "library_problem_id": 197, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 195}}
{"id": 489, "code": "```python\narr_copy = arr.copy()\nmask1 = arr_copy < -10\nmask2 = arr_copy >= 15\narr_copy[mask1] = 0\narr_copy[mask2] = 30\nmask3 = (arr_copy >= -10) & (arr_copy < 15)\narr_copy[mask3] = arr_copy[mask3] + 5\narr = arr_copy\n```\n\n</code>", "metadata": {"problem_id": 489, "library_problem_id": 198, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 198}}
{"id": 490, "code": "```python\n    arr_copy = arr.copy()\n    for row in range(arr.shape[0]):\n        mask1 = arr_copy[row] < n1[row]\n        mask2 = arr_copy[row] >= n2[row]\n        mask3 = (arr_copy[row] >= n1[row]) & (arr_copy[row] < n2[row])\n        arr_copy[row][mask1] = 0\n        arr_copy[row][mask2] = 30\n        arr_copy[row][mask3] = arr_copy[row][mask3] + 5\n    arr = arr_copy\n```</code>", "metadata": {"problem_id": 490, "library_problem_id": 199, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 198}}
{"id": 491, "code": "```python\ntolerance = 1e-8\nresult = np.sum(np.abs(s1 - s2) > tolerance)\n</code>\n", "metadata": {"problem_id": 491, "library_problem_id": 200, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 200}}
{"id": 492, "code": "```python\nimport numpy as np\n\ndef is_close(a, b, rtol=1e-05, atol=1e-08, equal_nan=True):\n    return np.isclose(a, b, rtol=rtol, atol=atol, equal_nan=equal_nan)\n\nare_close = [is_close(s1[i], s2[i]) for i in range(len(s1))]\nnot_close = np.logical_not(are_close)\nresult = np.sum(not_close)\n```</code>", "metadata": {"problem_id": 492, "library_problem_id": 201, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 200}}
{"id": 493, "code": "```python\nimport numpy as np\n\ndef all_arrays_equal(list_of_arrays):\n    if not list_of_arrays:\n        return True\n    \n    reference_array = list_of_arrays[0]\n    \n    for array in list_of_arrays[1:]:\n        if not np.array_equal(reference_array, array):\n            return False\n    \n    return True\n\nresult = all_arrays_equal(a)\n</code>\n", "metadata": {"problem_id": 493, "library_problem_id": 202, "library": "Numpy", "test_case_cnt": 5, "perturbation_type": "Origin", "perturbation_origin_id": 202}}
{"id": 494, "code": "```python\nresult = True\nfor arr in a:\n    result = result and np.isnan(arr).any()\n```\n", "metadata": {"problem_id": 494, "library_problem_id": 203, "library": "Numpy", "test_case_cnt": 5, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 202}}
{"id": 495, "code": "```python\nimport numpy as np\na = np.ones((41, 13))\nshape = (93, 13)\n\ndef pad_array(array, target_shape):\n    padding_rows = target_shape[0] - array.shape[0]\n    padding_cols = target_shape[1] - array.shape[1]\n    padding = [(0, padding_rows), (0, padding_cols)]\n    return np.pad(array, padding, mode='constant', constant_values=0)\n\nresult = pad_array(a, shape)\n</code>", "metadata": {"problem_id": 495, "library_problem_id": 204, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 204}}
{"id": 496, "code": "```python\ndef zeropad_array(array, target_shape):\n    row_pad = target_shape[0] - array.shape[0]\n    col_pad = target_shape[1] - array.shape[1]\n    pad_width = ((0, row_pad), (0, col_pad))\n    result = np.pad(array, pad_width=pad_width, mode='constant', constant_values=0)\n    return result\n\nresult = zeropad_array(a, shape)\n</code>", "metadata": {"problem_id": 496, "library_problem_id": 205, "library": "Numpy", "test_case_cnt": 4, "perturbation_type": "Surface", "perturbation_origin_id": 204}}
{"id": 497, "code": "```python\nimport numpy as np\n\ndef pad_array(array, target_shape, padding_value):\n    pad_rows = target_shape[0] - array.shape[0]\n    pad_cols = target_shape[1] - array.shape[1]\n    pad_width = ((0, pad_rows), (0, pad_cols))\n    return np.pad(array, pad_width=pad_width, mode='constant', constant_values=padding_value)\n\nresult = pad_array(a, shape, element)\n</code>\n", "metadata": {"problem_id": 497, "library_problem_id": 206, "library": "Numpy", "test_case_cnt": 4, "perturbation_type": "Semantic", "perturbation_origin_id": 204}}
{"id": 498, "code": "```python\n    padded_arr = np.zeros(shape)\n    padded_arr[:arr.shape[0], :arr.shape[1]] = arr\n    return padded_arr\n```", "metadata": {"problem_id": 498, "library_problem_id": 207, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 204}}
{"id": 499, "code": "```python\nrow_pad = shape[0] - a.shape[0]\ncol_pad = shape[1] - a.shape[1]\ntop = row_pad // 2\nbottom = row_pad - top\nleft = col_pad // 2\nright = col_pad - left\nresult = np.pad(a, pad_width=((top, bottom), (left, right)), mode='constant', constant_values=0)\n</code>\n", "metadata": {"problem_id": 499, "library_problem_id": 208, "library": "Numpy", "test_case_cnt": 4, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 204}}
{"id": 500, "code": "```python\na = a.reshape(a.shape[0]//3,3)\n</code>\n", "metadata": {"problem_id": 500, "library_problem_id": 209, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 209}}
{"id": 501, "code": "```python\nrow_indices = np.arange(a.shape[0])\ncol_indices = np.arange(a.shape[1])\nrow_indices, col_indices = np.meshgrid(row_indices, col_indices, indexing='ij')\nresult = a[row_indices, col_indices, b]\n```\n", "metadata": {"problem_id": 501, "library_problem_id": 210, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 210}}
{"id": 502, "code": "```python\nrows, cols = np.indices(b.shape)\nresult = a[rows, cols, b]\n```</code>", "metadata": {"problem_id": 502, "library_problem_id": 211, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 210}}
{"id": 503, "code": "```python\nresult = a[np.arange(a.shape[0])[:,None], np.arange(a.shape[1]), b]\n```</code>", "metadata": {"problem_id": 503, "library_problem_id": 212, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 210}}
{"id": 504, "code": "```python\nrows, cols = b.shape\nresult = np.sum(a[np.arange(rows)[:, None], np.arange(cols), b])\n```</code>", "metadata": {"problem_id": 504, "library_problem_id": 213, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 210}}
{"id": 505, "code": "```python\nimport numpy as np\na = np.array( \n    [[[ 0,  1, 2, 3],\n     [ 2,  3, 4, 5],\n     [ 4,  5, 6, 7]],\n    [[ 6,  7, 8, 9],\n     [ 8,  9, 10, 11],\n     [10, 11, 12, 13]],\n    [[12, 13, 14, 15],\n     [14, 15, 16, 17],\n     [16, 17, 18, 19]]]\n)\nb = np.array( \n    [[0, 1, 2],\n    [2, 1, 3],\n[1, 0, 3]]\n)\nresult = 0\nfor i in np.ndindex(b.shape):\n    result += np.sum(a[i[0], i[1], np.arange(a.shape[2]) != b[i]])\n</code>\n", "metadata": {"problem_id": 505, "library_problem_id": 214, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 210}}
{"id": 506, "code": "```python\nresult = df['b'].where((df['a'] > 1) & (df['a'] <= 4), np.nan)\n```\n\n</code>", "metadata": {"problem_id": 506, "library_problem_id": 215, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 215}}
{"id": 507, "code": "```python\nimport numpy as np\nim = np.array([[0,0,0,0,0,0],\n               [0,0,1,1,1,0],\n               [0,1,1,0,1,0],\n               [0,0,0,1,1,0],\n               [0,0,0,0,0,0]])\n\nfirst_row = np.argmax(np.any(im, axis=1))\nlast_row = np.where(np.any(im, axis=1))[0][-1]\nfirst_col = np.argmax(np.any(im, axis=0))\nlast_col = np.where(np.any(im, axis=0))[0][-1]\n\nresult = im[first_row:last_row+1, first_col:last_col+1]\n```</code>", "metadata": {"problem_id": 507, "library_problem_id": 216, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 216}}
{"id": 508, "code": "```python\nimport numpy as np\n\ndef truncate_array(arr):\n    row_indices = np.where(np.any(arr, axis=1))[0]\n    col_indices = np.where(np.any(arr, axis=0))[0]\n    \n    if len(row_indices) == 0 or len(col_indices) == 0:\n        return np.array([])\n\n    row_start, row_end = row_indices[0], row_indices[-1]\n    col_start, col_end = col_indices[0], col_indices[-1]\n    \n    truncated_arr = arr[row_start:row_end+1, col_start:col_end+1]\n    return truncated_arr\n\nA = np.array([[0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 1, 0, 0, 0, 0],\n           [0, 0, 1, 1, 0, 0, 0],\n           [0, 0, 0, 0, 1, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0]])\n\nresult = truncate_array(A)\n</code>\n", "metadata": {"problem_id": 508, "library_problem_id": 217, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 216}}
{"id": 509, "code": "```python\n    rows = np.any(im == 0, axis=1)\n    cols = np.any(im == 0, axis=0)\n    r_start, r_end = 0, len(rows)\n    c_start, c_end = 0, len(cols)\n    while r_start < r_end and not rows[r_start]:\n        r_start += 1\n    while r_end > r_start and not rows[r_end-1]:\n        r_end -= 1\n    while c_start < c_end and not cols[c_start]:\n        c_start += 1\n    while c_end > c_start and not cols[c_end-1]:\n        c_end -= 1\n    result = im[r_start:r_end, c_start:c_end]\n    if result.size == 0:\n        result = np.array([])\n```", "metadata": {"problem_id": 509, "library_problem_id": 218, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 216}}
{"id": 510, "code": "```python\n    rows = np.any(im != 0, axis=1)\n    cols = np.any(im != 0, axis=0)\n    im = im[rows][:, cols]\n    if im.size == 0:\n        result = np.array([])\n    else:\n        result = im\n```</code>", "metadata": {"problem_id": 510, "library_problem_id": 219, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 216}}
{"id": 511, "code": "```python\nplt.plot(x, y, marker='o', linestyle='-', label='x-y')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Scatter plot of x vs y')\nplt.legend()\nplt.show()\n```", "metadata": {"problem_id": 511, "library_problem_id": 0, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 0}}
{"id": 512, "code": "```python\nplt.minorticks_on()\nplt.tick_params(axis='y', which='minor')\nplt.show()\n```", "metadata": {"problem_id": 512, "library_problem_id": 1, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 1}}
{"id": 513, "code": "```python\nfrom matplotlib.ticker import AutoMinorLocator\n\nax = plt.gca()\nax.xaxis.set_minor_locator(AutoMinorLocator())\nax.yaxis.set_minor_locator(AutoMinorLocator())\nplt.show()\n```", "metadata": {"problem_id": 513, "library_problem_id": 2, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 1}}
{"id": 514, "code": "```python\nplt.minorticks_on()\nplt.show()\n```", "metadata": {"problem_id": 514, "library_problem_id": 3, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 1}}
{"id": 515, "code": "```python\nnum_lines = 4\nline_styles = ['-', '--', '-.', ':']\nfor i in range(num_lines):\n    y = np.random.rand(10)\n    plt.plot(x, y, linestyle=line_styles[i % len(line_styles)], label=f'Line {i+1}')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Multiple Lines with Different Styles')\nplt.legend()\nplt.show()\n```", "metadata": {"problem_id": 515, "library_problem_id": 4, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 4}}
{"id": 516, "code": "```python\nline_styles = ['-', '--', ':', '-.']\nnum_lines = len(line_styles)\nfor i in range(num_lines):\n    y = np.random.rand(10)\n    plt.plot(x, y, linestyle=line_styles[i], label=f'Line {i+1}')\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Multiple Lines with Different Styles')\nplt.legend()\nplt.show()\n```", "metadata": {"problem_id": 516, "library_problem_id": 5, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 4}}
{"id": 517, "code": "```python\nplt.plot(x, y, marker='d', linestyle='-', linewidth=0.5)\nplt.show()\n```", "metadata": {"problem_id": 517, "library_problem_id": 6, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 4}}
{"id": 518, "code": "```python\nplt.plot(x, y, marker='D', markersize=12)\nplt.show()\n```", "metadata": {"problem_id": 518, "library_problem_id": 7, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 4}}
{"id": 519, "code": "```python\nax.set(ylim=(0, 40))\n```", "metadata": {"problem_id": 519, "library_problem_id": 8, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 8}}
{"id": 520, "code": "```python\nplt.axvspan(2, 4, alpha=0.3, color='red')\nplt.show()\n```", "metadata": {"problem_id": 520, "library_problem_id": 9, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 9}}
{"id": 521, "code": "```python\nplt.plot([0, 1], [0, 2])\nplt.show()\n```", "metadata": {"problem_id": 521, "library_problem_id": 10, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 10}}
{"id": 522, "code": "```python\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 2])\nplt.show()\n```", "metadata": {"problem_id": 522, "library_problem_id": 11, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 10}}
{"id": 523, "code": "```python\nseaborn.relplot(x=\"Height (cm)\", y=\"Weight (kg)\", hue=\"Gender\", data=df)\nplt.show()\n```", "metadata": {"problem_id": 523, "library_problem_id": 12, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 12}}
{"id": 524, "code": "```python\nsns.set()\nplt.plot(x, y)\nplt.show()\n```", "metadata": {"problem_id": 524, "library_problem_id": 13, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 13}}
{"id": 525, "code": "```python\nsns.lineplot(x=x, y=y)\nplt.show()\n```", "metadata": {"problem_id": 525, "library_problem_id": 14, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 13}}
{"id": 526, "code": "```python\nplt.plot(x, y, marker='+', linewidth=7)\nplt.show()\n```", "metadata": {"problem_id": 526, "library_problem_id": 15, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 15}}
{"id": 527, "code": "```python\nplt.legend(fontsize=20)\n```", "metadata": {"problem_id": 527, "library_problem_id": 16, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 16}}
{"id": 528, "code": "```python\nplt.plot(x, y, label='xyz')\nplt.legend(title='xyz')\nplt.title('Plot of Cosine', fontsize=20)\nplt.show()\n```", "metadata": {"problem_id": 528, "library_problem_id": 17, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 16}}
{"id": 529, "code": "```python\nl.set_markerfacecolor(\"C0\")\nl.set_alpha(0.2)\n```", "metadata": {"problem_id": 529, "library_problem_id": 18, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 18}}
{"id": 530, "code": "```python\nl.set_markeredgecolor(\"black\")\n```", "metadata": {"problem_id": 530, "library_problem_id": 19, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 18}}
{"id": 531, "code": "```python\nl.set_color('red')\nl.set_markerfacecolor('red')\nl.set_markeredgecolor('red')\n```", "metadata": {"problem_id": 531, "library_problem_id": 20, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 18}}
{"id": 532, "code": "```python\nplt.xticks(rotation=45, ha='right')\nplt.legend()\nplt.tight_layout()\nplt.show()\n```", "metadata": {"problem_id": 532, "library_problem_id": 21, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 21}}
{"id": 533, "code": "```python\nplt.xticks(rotation=45)\nplt.show()\n```", "metadata": {"problem_id": 533, "library_problem_id": 22, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 21}}
{"id": 534, "code": "```python\nplt.xticks([0, 2, 4, 6], ['0', '2', '4', '6'])\nplt.legend()\nplt.show()\n```", "metadata": {"problem_id": 534, "library_problem_id": 23, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 21}}
{"id": 535, "code": "```python\nplt.legend()\n```", "metadata": {"problem_id": 535, "library_problem_id": 24, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 24}}
{"id": 536, "code": "```python\nplt.imshow(H, cmap='viridis')\nplt.colorbar()\nplt.show()\n```", "metadata": {"problem_id": 536, "library_problem_id": 25, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 25}}
{"id": 537, "code": "```python\nplt.imshow(H, cmap='gray')\nplt.show()\n```", "metadata": {"problem_id": 537, "library_problem_id": 26, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 25}}
{"id": 538, "code": "```python\nplt.xlabel(\"X\", loc=\"right\")\nplt.plot(x, y)\nplt.show()\n```", "metadata": {"problem_id": 538, "library_problem_id": 27, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 27}}
{"id": 539, "code": "```python\ng.axes.set_xticklabels(g.axes.get_xticklabels(), rotation=90)\n```", "metadata": {"problem_id": 539, "library_problem_id": 28, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 28}}
{"id": 540, "code": "```python\nimport textwrap\nwrapped_title = textwrap.fill(myTitle, 50)\nplt.title(wrapped_title)\nplt.show()\n```", "metadata": {"problem_id": 540, "library_problem_id": 29, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 29}}
{"id": 541, "code": "```python\nplt.plot(x, y)\nplt.gca().invert_yaxis()\nplt.show()\n```", "metadata": {"problem_id": 541, "library_problem_id": 30, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 30}}
{"id": 542, "code": "```python\nplt.xticks([0, 1.5])\nplt.show()\n```", "metadata": {"problem_id": 542, "library_problem_id": 31, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 31}}
{"id": 543, "code": "```python\nplt.yticks([-1, 1])\nplt.show()\n```", "metadata": {"problem_id": 543, "library_problem_id": 32, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 31}}
{"id": 544, "code": "```python\nplt.plot(z, label='z')\nplt.plot(y, label='y')\nplt.plot(x, label='x')\nplt.xlabel('Index')\nplt.ylabel('Value')\nplt.title('Overlapping Plots')\nplt.legend()\nplt.show()\n```", "metadata": {"problem_id": 544, "library_problem_id": 33, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 33}}
{"id": 545, "code": "```python\nplt.scatter(x, y, edgecolor='black', facecolor='blue')\nplt.show()\n```", "metadata": {"problem_id": 545, "library_problem_id": 34, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 34}}
{"id": 546, "code": "```python\nplt.gca().xaxis.set_major_locator(plt.MultipleLocator(1))\nplt.gca().yaxis.set_major_locator(plt.MultipleLocator(1))\nplt.plot(x,y)\nplt.show()\n```", "metadata": {"problem_id": 546, "library_problem_id": 35, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 35}}
{"id": 547, "code": "```python\nfrom matplotlib.ticker import ScalarFormatter\nplt.gca().yaxis.set_major_formatter(ScalarFormatter(useOffset=False))\nplt.show()\n```", "metadata": {"problem_id": 547, "library_problem_id": 36, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 36}}
{"id": 548, "code": "```python\nax = sns.lineplot(x=x, y=y, linestyle='--')\nplt.show()\n```", "metadata": {"problem_id": 548, "library_problem_id": 37, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 37}}
{"id": 549, "code": "```python\nfig, ax = plt.subplots(2, 1, sharex=True)\nax[0].plot(x, y1)\nax[1].plot(x, y2)\nplt.show()\n```", "metadata": {"problem_id": 549, "library_problem_id": 38, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 38}}
{"id": 550, "code": "```python\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.plot(x, y1)\nax2.plot(x, y2)\n\nax1.spines[['top', 'bottom', 'left', 'right']].set_visible(False)\nax2.spines[['top', 'bottom', 'left', 'right']].set_visible(False)\n\nplt.show()\n```", "metadata": {"problem_id": 550, "library_problem_id": 39, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 38}}
{"id": 551, "code": "```python\nplt.xlabel('')\n```", "metadata": {"problem_id": 551, "library_problem_id": 40, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 40}}
{"id": 552, "code": "```python\nax = plt.gca()\nax.set_xticklabels([])\n```", "metadata": {"problem_id": 552, "library_problem_id": 41, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 40}}
{"id": 553, "code": "```python\nxticks = plt.xticks()[0]\nnew_xticks = np.unique(np.append(xticks, [3, 4]))\nplt.xticks(new_xticks)\nplt.grid(axis='x')\nplt.axvline(x=3, color='gray', linestyle='--')\nplt.axvline(x=4, color='gray', linestyle='--')\n```", "metadata": {"problem_id": 553, "library_problem_id": 42, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 42}}
{"id": 554, "code": "```python\nplt.yticks([3, 4])\nplt.grid(axis='y', which='major', linestyle='-', linewidth=0.5, color='gray')\nplt.show()\n```", "metadata": {"problem_id": 554, "library_problem_id": 43, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 42}}
{"id": 555, "code": "```python\nplt.yticks([3, 4])\nplt.grid(axis='y', which='major', linestyle='-')\nplt.xticks([1, 2])\nplt.grid(axis='x', which='major', linestyle='-')\nplt.show()\n```", "metadata": {"problem_id": 555, "library_problem_id": 44, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 42}}
{"id": 556, "code": "```python\nplt.grid(True)\nplt.show()\n```", "metadata": {"problem_id": 556, "library_problem_id": 45, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 42}}
{"id": 557, "code": "```python\nplt.legend(loc=\"lower right\")\nplt.show()\n```", "metadata": {"problem_id": 557, "library_problem_id": 46, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 46}}
{"id": 558, "code": "```python\nfig, axes = plt.subplots(ncols=2, nrows=2, figsize=(8, 6))\nplt.tight_layout()\naxes = axes.flatten()\n\nfor ax in axes:\n    ax.set_ylabel(r\"$\\ln\\left(\\frac{x_a-x_b}{x_a-x_c}\\right)$\")\n    ax.set_xlabel(r\"$\\ln\\left(\\frac{x_a-x_d}{x_a-x_e}\\right)$\")\n\nplt.show()\n```", "metadata": {"problem_id": 558, "library_problem_id": 47, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 47}}
{"id": 559, "code": "```python\nplt.plot(x, y, label='Y')\nplt.plot(x, z, label='Z')\nplt.legend()\nplt.show()\n```", "metadata": {"problem_id": 559, "library_problem_id": 48, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 48}}
{"id": 560, "code": "```python\nax.xaxis.tick_top()\nax.xaxis.set_label_position('top')\n```", "metadata": {"problem_id": 560, "library_problem_id": 49, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 49}}
{"id": 561, "code": "```python\nplt.plot(x, y)\nplt.xlabel(\"X\", labelpad=20)\nplt.show()\n```", "metadata": {"problem_id": 561, "library_problem_id": 50, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 50}}
{"id": 562, "code": "```python\nplt.plot(x, y)\nplt.xticks([])\nplt.show()\n```", "metadata": {"problem_id": 562, "library_problem_id": 51, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 51}}
{"id": 563, "code": "```python\nplt.plot(x, y)\nplt.gca().yaxis.tick_right()\nplt.gca().yaxis.set_label_position(\"right\")\nplt.show()\n```", "metadata": {"problem_id": 563, "library_problem_id": 52, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 52}}
{"id": 564, "code": "```python\nplt.plot(x, y)\nplt.ylabel(\"Y\", rotation=270, labelpad=20)\nplt.gca().yaxis.set_ticks_position('left')\nplt.gca().yaxis.set_label_position(\"right\")\nplt.show()\n```", "metadata": {"problem_id": 564, "library_problem_id": 53, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 52}}
{"id": 565, "code": "```python\njoint_plot = sns.jointplot(x='total_bill', y='tip', data=tips, kind='reg', scatter_kws={'color':'green'}, line_kws={'color':'green'})\n```", "metadata": {"problem_id": 565, "library_problem_id": 54, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 54}}
{"id": 566, "code": "```python\njoint = sns.jointplot(x='total_bill', y='tip', data=tips, kind='reg', line_kws={'color': 'green'})\n```", "metadata": {"problem_id": 566, "library_problem_id": 55, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 54}}
{"id": 567, "code": "```python\nsns.jointplot(x='total_bill', y='tip', data=tips, kind='reg')\nplt.show()\n```", "metadata": {"problem_id": 567, "library_problem_id": 56, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 54}}
{"id": 568, "code": "```python\nax = df.plot(x=\"celltype\", y=[\"s1\", \"s2\"], kind=\"bar\")\nplt.xticks(rotation=0)\nplt.show()\n```", "metadata": {"problem_id": 568, "library_problem_id": 57, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 57}}
{"id": 569, "code": "```python\nax = df.plot(x=\"celltype\", y=[\"s1\", \"s2\"], kind=\"bar\", rot=45)\nplt.show()\n```", "metadata": {"problem_id": 569, "library_problem_id": 58, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 57}}
{"id": 570, "code": "```python\nplt.plot(y, x)\nplt.xlabel(\"X\", color='red')\nplt.tick_params(axis='x', colors='red')\nplt.show()\n```", "metadata": {"problem_id": 570, "library_problem_id": 59, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 59}}
{"id": 571, "code": "```python\nplt.plot(x, y)\nplt.xlabel('X')\nplt.gca().spines['bottom'].set_color('red')\nplt.show()\n```", "metadata": {"problem_id": 571, "library_problem_id": 60, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 59}}
{"id": 572, "code": "```python\nplt.plot(x, y)\nplt.xticks(fontsize=10, rotation='vertical')\nplt.yticks(fontsize=10)\nplt.show()\n```", "metadata": {"problem_id": 572, "library_problem_id": 61, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 61}}
{"id": 573, "code": "```python\nx_coords = [0.22058956, 0.33088437, 2.20589566]\nfor x in x_coords:\n    plt.axvline(x=x)\nplt.show()\n```", "metadata": {"problem_id": 573, "library_problem_id": 62, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 62}}
{"id": 574, "code": "```python\nplt.imshow(rand_mat)\nplt.xticks(numpy.arange(len(xlabels)), labels=xlabels, rotation=0)\nplt.yticks(numpy.arange(len(ylabels)), labels=ylabels)\nplt.gca().xaxis.tick_top()\nplt.gca().invert_yaxis()\nplt.show()\n```", "metadata": {"problem_id": 574, "library_problem_id": 63, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 63}}
{"id": 575, "code": "```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\n\nrc(\"mathtext\", default=\"regular\")\n\ntime = np.arange(10)\ntemp = np.random.random(10) * 30\nSwdown = np.random.random(10) * 100 - 10\nRn = np.random.random(10) * 100 - 10\n\nfig = plt.figure()\nax = fig.add_subplot(111)\nline1, = ax.plot(time, Swdown, \"-\", label=\"Swdown\")\nline2, = ax.plot(time, Rn, \"-\", label=\"Rn\")\nax2 = ax.twinx()\nline3, = ax2.plot(time, temp, \"-r\", label=\"temp\")\n\nlines = [line1, line2, line3]\nlabels = [line.get_label() for line in lines]\nax.legend(lines, labels, loc=0)\n\nax.grid()\nax.set_xlabel(\"Time (h)\")\nax.set_ylabel(r\"Radiation ($MJ\\,m^{-2}\\,d^{-1}$)\")\nax2.set_ylabel(r\"Temperature ($^\\circ$C)\")\nax2.set_ylim(0, 35)\nax.set_ylim(-20, 100)\nplt.show()\nplt.clf()\n```", "metadata": {"problem_id": 575, "library_problem_id": 64, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 64}}
{"id": 576, "code": "```python\nfig, axes = plt.subplots(1, 2)\naxes[0].plot(x, y)\naxes[0].set_title(\"Y\")\naxes[1].plot(x, y)\naxes[1].set_title(\"Y\")\nplt.show()\n```", "metadata": {"problem_id": 576, "library_problem_id": 65, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 65}}
{"id": 577, "code": "```python\nsns.scatterplot(x=\"bill_length_mm\", y=\"bill_depth_mm\", data=df, s=30)\nplt.show()\n```", "metadata": {"problem_id": 577, "library_problem_id": 66, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 66}}
{"id": 578, "code": "```python\nplt.scatter(b, a)\nfor i in range(len(a)):\n    plt.annotate(c[i], (b[i], a[i]))\nplt.xlabel(\"b\")\nplt.ylabel(\"a\")\nplt.title(\"Scatter plot of a vs b with annotations from c\")\nplt.show()\n```", "metadata": {"problem_id": 578, "library_problem_id": 67, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 67}}
{"id": 579, "code": "```python\nplt.plot(x, y, label='y over x')\nplt.legend(title='Legend Title')\nplt.show()\n```", "metadata": {"problem_id": 579, "library_problem_id": 68, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 68}}
{"id": 580, "code": "```python\nplt.plot(x, y, label=\"y over x\")\nlegend = plt.legend(title=\"Legend\")\nlegend.get_title().set_fontweight('bold')\nplt.show()\n```", "metadata": {"problem_id": 580, "library_problem_id": 69, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 68}}
{"id": 581, "code": "```python\nn, bins, patches = plt.hist(x)\nfor patch in patches:\n    patch.set_edgecolor('black')\n    patch.set_linewidth(1.2)\nplt.show()\n```", "metadata": {"problem_id": 581, "library_problem_id": 70, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 70}}
{"id": 582, "code": "```python\nfig, axes = plt.subplots(1, 2, gridspec_kw={'width_ratios': [3, 1]})\naxes[0].plot(x, y)\naxes[1].plot(x, y**2)\nplt.show()\n```", "metadata": {"problem_id": 582, "library_problem_id": 71, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 71}}
{"id": 583, "code": "```python\nplt.hist(x, bins, alpha=0.5)\nplt.hist(y, bins, alpha=0.5)\nplt.show()\n```", "metadata": {"problem_id": 583, "library_problem_id": 72, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 72}}
{"id": 584, "code": "```python\nplt.hist([x, y], label=['x', 'y'], histtype='bar')\nplt.xlabel('Value')\nplt.ylabel('Frequency')\nplt.title('Grouped Histogram of x and y')\nplt.legend(loc='upper right')\nplt.show()\n```", "metadata": {"problem_id": 584, "library_problem_id": 73, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 72}}
{"id": 585, "code": "```python\nimport numpy as np\n\nm = (d - b) / (c - a)\nb_intercept = b - m * a\nx = np.linspace(0, 5, 100)\ny = m * x + b_intercept\nplt.plot(x, y)\nplt.xlim(0, 5)\nplt.ylim(0, 5)\nplt.show()\n```", "metadata": {"problem_id": 585, "library_problem_id": 74, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 74}}
{"id": 586, "code": "```python\nfig, axes = plt.subplots(1, 2)\nim = axes[0].imshow(x)\naxes[1].imshow(y)\nfig.colorbar(im, ax=axes.ravel().tolist())\nplt.show()\n```", "metadata": {"problem_id": 586, "library_problem_id": 75, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 75}}
{"id": 587, "code": "```python\nplt.plot(x[:, 0], label='a')\nplt.plot(x[:, 1], label='b')\nplt.legend()\nplt.show()\n```", "metadata": {"problem_id": 587, "library_problem_id": 76, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 76}}
{"id": 588, "code": "```python\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\naxs[0].plot(x, y)\naxs[1].plot(a, z)\nfig.suptitle('Y and Z')\n```", "metadata": {"problem_id": 588, "library_problem_id": 77, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 77}}
{"id": 589, "code": "```python\nx_coords, y_coords = zip(*points)\nplt.plot(x_coords, y_coords)\nplt.yscale('log')\nplt.show()\n```", "metadata": {"problem_id": 589, "library_problem_id": 78, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 78}}
{"id": 590, "code": "```python\nplt.plot(x, y)\nplt.title('y vs x', fontsize=20)\nplt.xlabel('x', fontsize=18)\nplt.ylabel('y', fontsize=16)\nplt.show()\n```", "metadata": {"problem_id": 590, "library_problem_id": 79, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 79}}
{"id": 591, "code": "```python\nax.plot(x, y)\nax.set_xticks(x)\nax.set_xticklabels(range(1, 11))\nax.set_yticks(y)\nax.set_yticklabels(range(1, 11))\n```", "metadata": {"problem_id": 591, "library_problem_id": 80, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 80}}
{"id": 592, "code": "```python\nfor i, line in enumerate(lines):\n    (x1, y1), (x2, y2) = line\n    plt.plot([x1, x2], [y1, y2], color=c[i])\nplt.show()\n```", "metadata": {"problem_id": 592, "library_problem_id": 81, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 81}}
{"id": 593, "code": "```python\nimport matplotlib.ticker as ticker\nplt.loglog(x, y, marker='o')\nplt.gca().xaxis.set_major_formatter(ticker.LogFormatter())\nplt.gca().yaxis.set_major_formatter(ticker.LogFormatter())\nplt.show()\n```", "metadata": {"problem_id": 593, "library_problem_id": 82, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 82}}
{"id": 594, "code": "```python\nax = df.plot(marker='.')\nplt.show()\n```", "metadata": {"problem_id": 594, "library_problem_id": 83, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 83}}
{"id": 595, "code": "```python\nplt.hist(data, weights=np.ones(len(data)) / len(data))\nplt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: '{:.0%}'.format(x)))\nplt.yticks(np.arange(0, 0.5, 0.1))\nplt.show()\n```", "metadata": {"problem_id": 595, "library_problem_id": 84, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 84}}
{"id": 596, "code": "```python\nplt.plot(x, y, marker='o', alpha=0.5)\nplt.show()\n```", "metadata": {"problem_id": 596, "library_problem_id": 85, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 85}}
{"id": 597, "code": "```python\nfig, axes = plt.subplots(1, 2, figsize=(10, 5))\naxes[0].plot(x, y, label='y')\naxes[1].plot(z, a, label='a')\naxes[0].set_xlabel('x')\naxes[0].set_ylabel('y')\naxes[1].set_xlabel('z')\naxes[1].set_ylabel('a')\nfig.legend()\nplt.show()\n```", "metadata": {"problem_id": 597, "library_problem_id": 86, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 86}}
{"id": 598, "code": "```python\nfig, axes = plt.subplots(1, 2)\nsns.regplot(x=\"bill_length_mm\", y=\"bill_depth_mm\", data=df, ax=axes[0])\nsns.regplot(x=\"bill_length_mm\", y=\"flipper_length_mm\", data=df, ax=axes[1])\nplt.show()\n```", "metadata": {"problem_id": 598, "library_problem_id": 87, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 87}}
{"id": 599, "code": "```python\nlabels = [item.get_text() for item in ax.get_xticklabels()]\nlabels[1] = 'second'\nax.set_xticklabels(labels)\n```", "metadata": {"problem_id": 599, "library_problem_id": 88, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 88}}
{"id": 600, "code": "```python\nplt.plot(x, y, label='$\\\\lambda$')\nplt.legend()\nplt.show()\n```", "metadata": {"problem_id": 600, "library_problem_id": 89, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 89}}
{"id": 601, "code": "```python\nextra_ticks = [2.1, 3, 7.6]\ncurrent_ticks = plt.xticks()[0]\ncombined_ticks = np.concatenate((current_ticks, extra_ticks))\nplt.xticks(np.sort(combined_ticks))\n```", "metadata": {"problem_id": 601, "library_problem_id": 90, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 90}}
{"id": 602, "code": "```python\nplt.xticks(rotation=-60, ha='left')\n```", "metadata": {"problem_id": 602, "library_problem_id": 91, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 91}}
{"id": 603, "code": "```python\nplt.yticks(rotation=-60)\nplt.xticks(verticalalignment='top')\nplt.show()\n```", "metadata": {"problem_id": 603, "library_problem_id": 92, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 91}}
{"id": 604, "code": "```python\nfor label in plt.gca().xaxis.get_ticklabels():\n    label.set_alpha(0.5)\n```", "metadata": {"problem_id": 604, "library_problem_id": 93, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 91}}
{"id": 605, "code": "```python\nplt.margins(x=0, y=0.1)\nplt.show()\n```", "metadata": {"problem_id": 605, "library_problem_id": 94, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 94}}
{"id": 606, "code": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\nplt.plot(x, y)\n\nplt.gca().yaxis.set_major_locator(plt.FixedLocator(plt.gca().get_yticks()))\nplt.subplots_adjust(left=0)\nplt.xlim(left=-0.1)\n```", "metadata": {"problem_id": 606, "library_problem_id": 95, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 94}}
{"id": 607, "code": "```python\nfig, ax = plt.subplots(1, 2)\nax[0].plot(x, y)\nax[1].plot(x, y)\nfig.suptitle('Figure')\nplt.show()\n```", "metadata": {"problem_id": 607, "library_problem_id": 96, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 96}}
{"id": 608, "code": "```python\ndf.plot()\nplt.xlabel(\"X\")\nplt.ylabel(\"Y\")\nplt.show()\n```", "metadata": {"problem_id": 608, "library_problem_id": 97, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 97}}
{"id": 609, "code": "```python\n<code>\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\nplt.scatter(x, y, marker='v', hatch='||||')\nplt.show()\n</code>\n```", "metadata": {"problem_id": 609, "library_problem_id": 98, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 98}}
{"id": 610, "code": "```python\nplt.scatter(x, y, edgecolors='none', hatch='|')\nplt.show()\n```", "metadata": {"problem_id": 610, "library_problem_id": 99, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 98}}
{"id": 611, "code": "```python\nplt.scatter(x, y, marker='*', hatch='*')\nplt.show()\n```", "metadata": {"problem_id": 611, "library_problem_id": 100, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 98}}
{"id": 612, "code": "```python\n<code>\nplt.scatter(x, y, s=100, marker='*', hatch='|')\nplt.show()\n</code>\n```", "metadata": {"problem_id": 612, "library_problem_id": 101, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 98}}
{"id": 613, "code": "```python\nplt.xlim(0, 10)\nplt.ylim(0, 10)\nplt.imshow(data, extent=[1, 5, 1, 4])\nplt.show()\n```", "metadata": {"problem_id": 613, "library_problem_id": 102, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 102}}
{"id": 614, "code": "```python\nplt.stem(x, y, orientation='horizontal')\nplt.show()\n```", "metadata": {"problem_id": 614, "library_problem_id": 103, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 103}}
{"id": 615, "code": "```python\nkeys = list(d.keys())\nvalues = list(d.values())\ncolors = [c[key] for key in keys]\nplt.bar(keys, values, color=colors)\nplt.xticks(keys)\nplt.show()\n```", "metadata": {"problem_id": 615, "library_problem_id": 104, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 104}}
{"id": 616, "code": "```python\n<code>\nplt.axvline(x=3, color='r', linestyle='-', label='cutoff')\nplt.legend()\n</code>\n```", "metadata": {"problem_id": 616, "library_problem_id": 105, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 105}}
{"id": 617, "code": "```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nlabels = [\"a\", \"b\"]\nheight = [3, 4]\n\nangles = np.linspace(0, 2*np.pi, len(labels), endpoint=False)\nwidth = np.pi / 4\n\nfig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\nax.bar(angles, height, width=width, bottom=0.0)\nax.set_xticks(angles)\nax.set_xticklabels(labels)\nplt.show()\n```", "metadata": {"problem_id": 617, "library_problem_id": 106, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 106}}
{"id": 618, "code": "```python\nplt.pie(data, labels=l, wedgeprops={'width': 0.4})\nplt.show()\n```", "metadata": {"problem_id": 618, "library_problem_id": 107, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 107}}
{"id": 619, "code": "```python\nplt.plot(y, x)\nplt.grid(color='blue', linestyle='--')\nplt.show()\n```", "metadata": {"problem_id": 619, "library_problem_id": 108, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 108}}
{"id": 620, "code": "```python\nplt.plot(x, y)\nplt.minorticks_on()\nplt.grid(which='minor', linestyle='--', color='gray')\nplt.grid(which='major', visible=False)\nplt.show()\n```", "metadata": {"problem_id": 620, "library_problem_id": 109, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 109}}
{"id": 621, "code": "```python\nplt.pie(sizes, labels=labels, colors=colors, textprops={'weight': 'bold'})\nplt.show()\n```", "metadata": {"problem_id": 621, "library_problem_id": 110, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 110}}
{"id": 622, "code": "```python\nplt.pie(sizes, labels=labels, colors=colors, textprops={'fontweight': 'bold'})\nplt.show()\n```", "metadata": {"problem_id": 622, "library_problem_id": 111, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 111}}
{"id": 623, "code": "```python\nplt.plot(x, y, marker='o', markerfacecolor='none', markeredgecolor='black')\nplt.show()\n```", "metadata": {"problem_id": 623, "library_problem_id": 112, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 112}}
{"id": 624, "code": "```python\nplt.axvline(x=55, color=\"green\")\n```", "metadata": {"problem_id": 624, "library_problem_id": 113, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 113}}
{"id": 625, "code": "```python\n# Specify the x-axis positions for the blue bars\nx = np.arange(len(blue_bar))\n# Specify the width of the bars\nwidth = 0.35\n# Plot the blue bars\nplt.bar(x - width/2, blue_bar, width, label='Blue')\n# Plot the orange bars\nplt.bar(x + width/2, orange_bar, width, label='Orange')\n# Add some text for labels, title and custom x-axis tick labels, etc.\nplt.ylabel('Values')\nplt.title('Blue and Orange Bars')\nplt.xticks(x, ['A', 'B', 'C'])\nplt.legend()\nplt.tight_layout()\nplt.show()\n```", "metadata": {"problem_id": 625, "library_problem_id": 114, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 114}}
{"id": 626, "code": "```python\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\nax1.plot(x, y, label='y vs x')\nax2.plot(a, z, label='z vs a')\nax1.legend()\nplt.show()\n```", "metadata": {"problem_id": 626, "library_problem_id": 115, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 115}}
{"id": 627, "code": "```python\nplt.scatter(x, y, c=y, cmap='Spectral')\nplt.show()\n```", "metadata": {"problem_id": 627, "library_problem_id": 116, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 116}}
{"id": 628, "code": "```python\nplt.plot(x, y)\nplt.xticks(np.arange(min(x), max(x)+1, 1.0))\nplt.show()\n```", "metadata": {"problem_id": 628, "library_problem_id": 117, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 117}}
{"id": 629, "code": "```python\ng = sns.catplot(x=\"sex\", y=\"bill_length_mm\", col=\"species\", data=df, kind=\"bar\", sharey=False)\n```", "metadata": {"problem_id": 629, "library_problem_id": 118, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 118}}
{"id": 630, "code": "```python\nfig, ax = plt.subplots()\ncircle = plt.Circle((0.5, 0.5), 0.2, color='blue')\nax.add_patch(circle)\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\nplt.show()\n```", "metadata": {"problem_id": 630, "library_problem_id": 119, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 119}}
{"id": 631, "code": "```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.arange(10)\n\nplt.plot(x, y)\nplt.title(r'$\\bf{\\phi}$')\nplt.show()\n```", "metadata": {"problem_id": 631, "library_problem_id": 120, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 120}}
{"id": 632, "code": "```python\nplt.plot(x, y, label=\"Line\")\nplt.legend(handletextpad=0.1)\nplt.show()\n```", "metadata": {"problem_id": 632, "library_problem_id": 121, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 121}}
{"id": 633, "code": "```python\nplt.plot(x, y, label='Line')\nplt.legend(handlelength=0.3)\nplt.show()\n```", "metadata": {"problem_id": 633, "library_problem_id": 122, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 121}}
{"id": 634, "code": "```python\nplt.legend(ncol=2)\nplt.show()\n```", "metadata": {"problem_id": 634, "library_problem_id": 123, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 121}}
{"id": 635, "code": "```python\nplt.legend()\nplt.plot(x[2], y[2], marker='o', color='C0')\nplt.plot(x[7], y[7], marker='o', color='C0')\nplt.show()\n```", "metadata": {"problem_id": 635, "library_problem_id": 124, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 121}}
{"id": 636, "code": "```python\nplt.imshow(data, cmap='viridis')\nplt.colorbar()\nplt.show()\n```", "metadata": {"problem_id": 636, "library_problem_id": 125, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 125}}
{"id": 637, "code": "```python\nplt.plot(x, y)\nplt.title(r'$\\bf{Figure}$ 1')\nplt.show()\n```", "metadata": {"problem_id": 637, "library_problem_id": 126, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 126}}
{"id": 638, "code": "```python\ng = sns.pairplot(df, x_vars=[\"x\"], y_vars=[\"y\"], hue=\"id\")\nplt.legend([],[], frameon=False)\n```", "metadata": {"problem_id": 638, "library_problem_id": 127, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 127}}
{"id": 639, "code": "```python\nplt.plot(x, y)\nplt.gca().invert_xaxis()\nplt.show()\n```", "metadata": {"problem_id": 639, "library_problem_id": 128, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 128}}
{"id": 640, "code": "```python\nplt.scatter(x, y, clip_on=False)\nplt.show()\n```", "metadata": {"problem_id": 640, "library_problem_id": 129, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 129}}
{"id": 641, "code": "```python\nplt.scatter(x, y, facecolors='red', edgecolors='black')\nplt.show()\n```", "metadata": {"problem_id": 641, "library_problem_id": 130, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 130}}
{"id": 642, "code": "```python\nfig, axes = plt.subplots(2, 2, figsize=(15, 15))\nfor ax in axes.flatten():\n    ax.plot(x, y)\nplt.show()\n```", "metadata": {"problem_id": 642, "library_problem_id": 131, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 131}}
{"id": 643, "code": "```python\nplt.hist(x, range=(0, 10), bins=5, rwidth=0.95)\nplt.show()\n```", "metadata": {"problem_id": 643, "library_problem_id": 132, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 132}}
{"id": 644, "code": "```python\nplt.plot(x, y, 'b-', label='y')\nplt.fill_between(x, y - error, y + error, color='b', alpha=0.2, label='Error')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Plot of y vs x with Error Shading')\nplt.legend()\nplt.show()\n```", "metadata": {"problem_id": 644, "library_problem_id": 133, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 133}}
{"id": 645, "code": "```python\nplt.axvline(x=0, color='white')\nplt.axhline(y=0, color='white')\nplt.show()\n```", "metadata": {"problem_id": 645, "library_problem_id": 134, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 134}}
{"id": 646, "code": "```python\nax.errorbar(box_position, box_height, yerr=box_errors, fmt='none', color=c)\n```", "metadata": {"problem_id": 646, "library_problem_id": 135, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 135}}
{"id": 647, "code": "```python\nfig, ax = plt.subplots(1, 2)\nax[0].plot(x, y)\nax[0].set_title('Y')\nax[1].plot(a, z)\nax[1].set_title('Z')\nax[1].title.set_position([.5, 1.1])\nplt.show()\n```", "metadata": {"problem_id": 647, "library_problem_id": 136, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 136}}
{"id": 648, "code": "```python\nfig, axes = plt.subplots(4, 4, figsize=(5, 5))\nfor ax in axes.flatten():\n    ax.plot(x, y)\n    ax.tick_params(axis='both', labelsize=8)\nplt.tight_layout()\nplt.show()\n```", "metadata": {"problem_id": 648, "library_problem_id": 137, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 137}}
{"id": 649, "code": "```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nd = np.random.random((10, 10))\n\nplt.figure(figsize=(8, 8))\nplt.matshow(d)\nplt.show()\n```", "metadata": {"problem_id": 649, "library_problem_id": 138, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 138}}
{"id": 650, "code": "```python\nfig, ax = plt.subplots(figsize=(12, 4))\nax.axis('off')\ntable = plt.table(cellText=df.values, colLabels=df.columns, loc='center')\ntable.set_bbox([0, 0, 1, 1])\nplt.show()\n```", "metadata": {"problem_id": 650, "library_problem_id": 139, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 139}}
{"id": 651, "code": "```python\nplt.plot(x, y)\nplt.tick_params(axis='x', top=True, bottom=True, labeltop=True, labelbottom=True)\nplt.show()\n```", "metadata": {"problem_id": 651, "library_problem_id": 140, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 140}}
{"id": 652, "code": "```python\n<code>\nplt.plot(x, y)\nplt.tick_params(axis='x', top=True, bottom=True, labeltop=True, labelbottom=True)\nplt.show()\n</code>\n```", "metadata": {"problem_id": 652, "library_problem_id": 141, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 140}}
{"id": 653, "code": "```python\nplt.plot(y, x)\nplt.xticks([])\nplt.show()\n```", "metadata": {"problem_id": 653, "library_problem_id": 142, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 140}}
{"id": 654, "code": "```python\ng = sns.catplot(x=\"time\", y=\"pulse\", hue=\"kind\", col=\"diet\", data=df, kind=\"scatter\")\ng.set_titles(\"Group: {col_name}\")\n```", "metadata": {"problem_id": 654, "library_problem_id": 143, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 143}}
{"id": 655, "code": "```python\ng = sns.catplot(x=\"time\", y=\"pulse\", hue=\"kind\", col=\"diet\", data=df)\ng.set_xlabels(\"Exercise Time\")\n```", "metadata": {"problem_id": 655, "library_problem_id": 144, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 143}}
{"id": 656, "code": "```python\ng = sns.catplot(x=\"time\", y=\"pulse\", hue=\"kind\", col=\"diet\", data=df, kind=\"scatter\")\ng.set(ylabel=\"\")\n```", "metadata": {"problem_id": 656, "library_problem_id": 145, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 143}}
{"id": 657, "code": "```python\nplt.plot(x, y, label=\"y\")\nplt.legend(fontsize=8)\nplt.show()\n```", "metadata": {"problem_id": 657, "library_problem_id": 146, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 146}}
{"id": 658, "code": "```python\nplt.figure(figsize=(5, 5), dpi=300)\nplt.plot(x, y)\nplt.show()\n```", "metadata": {"problem_id": 658, "library_problem_id": 147, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 147}}
{"id": 659, "code": "```python\nplt.plot(x, y, label=\"y\")\nplt.legend(frameon=False)\nplt.show()\n```", "metadata": {"problem_id": 659, "library_problem_id": 148, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 148}}
{"id": 660, "code": "```python\nplt.plot(t, a, label='sin(t)')\nplt.plot(t, b, label='cos(t)')\nplt.plot(t, c, label='sin(t) + cos(t)')\nplt.xlabel('t')\nplt.ylabel('amplitude')\nplt.title('Sine, Cosine, and their Sum')\nplt.legend()\nplt.grid(True)\nplt.show()\n```", "metadata": {"problem_id": 660, "library_problem_id": 149, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 149}}
{"id": 661, "code": "```python\nax = sns.stripplot(data=df, x=\"sex\", y=\"bill_length_mm\", hue=\"species\")\nax.legend_.remove()\n```", "metadata": {"problem_id": 661, "library_problem_id": 150, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 150}}
{"id": 662, "code": "```python\ng = sns.FacetGrid(df, row=\"b\")\ng.map(sns.pointplot, \"a\", \"c\")\nfor ax in g.axes.flat:\n    ax.set_xticks(np.arange(1, 31, 1))\n    ax.set_xticklabels(np.arange(1, 31, 2))\n```", "metadata": {"problem_id": 662, "library_problem_id": 151, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 151}}
{"id": 663, "code": "```python\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(x, y, z)\nax.view_init(50, 100)\nplt.show()\n```", "metadata": {"problem_id": 663, "library_problem_id": 152, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 152}}
{"id": 664, "code": "```python\nplt.plot(x, y)\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False, labelbottom=False, labelleft=False)\nplt.show()\n```", "metadata": {"problem_id": 664, "library_problem_id": 153, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 153}}
{"id": 665, "code": "```python\ngs = gridspec.GridSpec(nrow, ncol)\nfor row in range(nrow):\n    for col in range(ncol):\n        ax = fig.add_subplot(gs[row, col])\n        ax.imshow(x)\n        ax.set_xticks([])\n        ax.set_yticks([])\nplt.subplots_adjust(wspace=0, hspace=0)\nplt.show()\n```", "metadata": {"problem_id": 665, "library_problem_id": 154, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 154}}
{"id": 666, "code": "```python\nx.assign(1)\nresult = int(x.numpy())\n```\n\n</code>", "metadata": {"problem_id": 666, "library_problem_id": 0, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 0}}
{"id": 667, "code": "```python\nx.assign(114514)\nresult = int(x.numpy())\n```\n", "metadata": {"problem_id": 667, "library_problem_id": 1, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 0}}
{"id": 668, "code": "```python\nlabels = tf.constant(labels)\nnum_classes = 10\nresult = tf.one_hot(labels, depth=num_classes, dtype=tf.int32)\n```\n\n</code>", "metadata": {"problem_id": 668, "library_problem_id": 2, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 2}}
{"id": 669, "code": "```python\nnum_classes = 10\nindices = tf.expand_dims(tf.range(len(labels)), axis=1)\nupdates = tf.zeros(len(labels), dtype=tf.int32)\nshape = [len(labels)]\nlabel_indices = tf.expand_dims(labels, axis=1)\nindices = tf.concat([indices, label_indices], axis=1)\nresult = tf.ones((len(labels), num_classes), dtype=tf.int32)\nresult = tf.tensor_scatter_nd_update(result, indices, updates)\n```\n\n</code>", "metadata": {"problem_id": 669, "library_problem_id": 3, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 2}}
{"id": 670, "code": "```python\nresult = tf.one_hot(labels, depth=10, dtype=tf.int32)\n```\n\n</code>", "metadata": {"problem_id": 670, "library_problem_id": 4, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 2}}
{"id": 671, "code": "```python\n    num_classes = 10\n    labels = tf.constant(labels, dtype=tf.int32)\n    indices = tf.range(num_classes)\n    one_hot = tf.cast(tf.equal(tf.expand_dims(labels, 1), tf.expand_dims(indices, 0)), tf.int32)\n    return one_hot\n### END SOLUTION\n```", "metadata": {"problem_id": 671, "library_problem_id": 5, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 2}}
{"id": 672, "code": "```python\nnum_classes = 10\nlabels_tensor = tf.constant(labels, dtype=tf.int32)\nresult = tf.ones((tf.shape(labels_tensor)[0], num_classes), dtype=tf.int32)\nindices = tf.stack([tf.range(tf.shape(labels_tensor)[0]), labels_tensor], axis=1)\nresult = tf.tensor_scatter_nd_update(result, indices, tf.zeros(tf.shape(labels_tensor), dtype=tf.int32))\n```\n\n</code>", "metadata": {"problem_id": 672, "library_problem_id": 6, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 2}}
{"id": 673, "code": "```python\ndef my_map_func(i):\n  return tf.data.Dataset.from_tensor_slices([i, i+1, i+2])\nds = tf.data.Dataset.from_tensor_slices(input)\nds = ds.flat_map(my_map_func)\niterator = tf.compat.v1.data.make_one_shot_iterator(ds)\nelement = iterator.get_next()\nresult = []\nwith tf.compat.v1.Session() as sess:\n  try:\n    while True:\n      result.append(sess.run(element))\n  except tf.errors.OutOfRangeError:\n    pass\n</code>", "metadata": {"problem_id": 673, "library_problem_id": 7, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 7}}
{"id": 674, "code": "```python\n    dataset = tf.data.Dataset.from_tensor_slices(input)\n    dataset = dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices(tf.range(x, x + 3)))\n    iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n    next_element = iterator.get_next()\n    result = []\n    with tf.compat.v1.Session() as sess:\n        try:\n            while True:\n                result.append(sess.run(next_element))\n        except tf.errors.OutOfRangeError:\n            pass\n    return result\n```</code>", "metadata": {"problem_id": 674, "library_problem_id": 8, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 7}}
{"id": 675, "code": "```python\nlengths = tf.constant(lengths)\nmax_len = 8\nrange_tensor = tf.range(max_len)\nmask = tf.expand_dims(lengths, axis=1) > range_tensor\nresult = tf.cast(mask, tf.int32)\n```\n\n</code>", "metadata": {"problem_id": 675, "library_problem_id": 9, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 9}}
{"id": 676, "code": "```python\noutput_length = 8\nresult = tf.stack([tf.cast(tf.range(output_length) >= l, tf.int32) for l in lengths])\n```\n\n</code>", "metadata": {"problem_id": 676, "library_problem_id": 10, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 9}}
{"id": 677, "code": "```python\nlengths = tf.constant(lengths)\nmax_len = 8\nmask = tf.sequence_mask(lengths, maxlen=max_len)\nresult = tf.cast(mask, dtype=tf.float32)\n```\n\n</code>", "metadata": {"problem_id": 677, "library_problem_id": 11, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 9}}
{"id": 678, "code": "```python\n    max_len = 8\n    range_tensor = tf.range(max_len)\n    masks = []\n    for length in lengths:\n        mask = tf.cast(range_tensor < length, tf.int32)\n        masks.append(mask)\n    result = tf.stack(masks)\n    return result\n```", "metadata": {"problem_id": 678, "library_problem_id": 12, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 9}}
{"id": 679, "code": "```python\nmax_length = 8\nrange_tensor = tf.range(max_length)\nresult = tf.cast(tf.less(range_tensor, tf.expand_dims(lengths, 1)), tf.float32)\n```\n\n</code>", "metadata": {"problem_id": 679, "library_problem_id": 13, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 9}}
{"id": 680, "code": "```python\na_grid, b_grid = tf.meshgrid(a, b)\nstacked = tf.stack([a_grid, b_grid], axis=-1)\nresult = tf.reshape(stacked, [tf.size(a) * tf.size(b), 2])\n</code>\n", "metadata": {"problem_id": 680, "library_problem_id": 14, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 14}}
{"id": 681, "code": "```python\n    a_reshaped = tf.reshape(a, [-1, 1])\n    b_reshaped = tf.reshape(b, [1, -1])\n    a_tiled = tf.tile(a_reshaped, [1, tf.shape(b)[0]])\n    b_tiled = tf.tile(b_reshaped, [tf.shape(a)[0], 1])\n    result = tf.stack([tf.reshape(a_tiled, [-1]), tf.reshape(b_tiled, [-1])], axis=1)\n    return result\n```", "metadata": {"problem_id": 681, "library_problem_id": 15, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 14}}
{"id": 682, "code": "```python\nresult = tf.squeeze(a, axis=2)\n```\n", "metadata": {"problem_id": 682, "library_problem_id": 16, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 16}}
{"id": 683, "code": "```python\nresult = tf.reshape(a, (50, 100, 1, 512))\n```", "metadata": {"problem_id": 683, "library_problem_id": 17, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 16}}
{"id": 684, "code": "```python\nresult = tf.reshape(a, (1, 50, 100, 1, 512))\n</code>\n", "metadata": {"problem_id": 684, "library_problem_id": 18, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 16}}
{"id": 685, "code": "```python\nresult = tf.reduce_sum(A, axis=1)\n```\n", "metadata": {"problem_id": 685, "library_problem_id": 19, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 19}}
{"id": 686, "code": "```python\nresult = tf.math.reduce_prod(A, axis=1)\n```</code>", "metadata": {"problem_id": 686, "library_problem_id": 20, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 19}}
{"id": 687, "code": "```python\nimport tensorflow as tf\nA = tf.constant([-0.5, -0.1, 0, 0.1, 0.5, 2], dtype=tf.float32)\nresult = tf.math.reciprocal(A)\n```\n", "metadata": {"problem_id": 687, "library_problem_id": 21, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 19}}
{"id": 688, "code": "```python\n  result = tf.reduce_sum(tf.square(tf.subtract(a, b)), axis=1)\n</code>\n", "metadata": {"problem_id": 688, "library_problem_id": 22, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 22}}
{"id": 689, "code": "```python\nsquared_difference = tf.square(tf.subtract(a, b))\nresult = tf.reduce_sum(squared_difference, axis=0)\n```\n\n</code>", "metadata": {"problem_id": 689, "library_problem_id": 23, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 22}}
{"id": 690, "code": "```python\n    return tf.reduce_sum(tf.square(tf.subtract(A, B)), axis=1)\n    ### END SOLUTION\n```", "metadata": {"problem_id": 690, "library_problem_id": 24, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 22}}
{"id": 691, "code": "```python\nindices = tf.stack([y, z], axis=1)\nresult = tf.gather_nd(x, indices)\n</code>\n", "metadata": {"problem_id": 691, "library_problem_id": 25, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 25}}
{"id": 692, "code": "```python\nindices = tf.stack([row, col], axis=1)\nresult = tf.gather_nd(x, indices)\n</code>\n", "metadata": {"problem_id": 692, "library_problem_id": 26, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 25}}
{"id": 693, "code": "```python\n    indices = tf.stack([y, z], axis=1)\n    result = tf.gather_nd(x, indices)\n    return result\n    ### END SOLUTION\n</code>\n```", "metadata": {"problem_id": 693, "library_problem_id": 27, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 25}}
{"id": 694, "code": "```python\n    A_expanded = tf.expand_dims(A, axis=1)\n    B_expanded = tf.expand_dims(B, axis=0)\n    result = tf.reduce_sum(A_expanded * B_expanded, axis=3)\n```\n", "metadata": {"problem_id": 694, "library_problem_id": 28, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 28}}
{"id": 695, "code": "```python\nresult = tf.matmul(A, tf.transpose(B, perm=[0, 2, 1]))\ntf.assert_equal(tf.shape(result), tf.constant([10, 20, 20], dtype=tf.int32))\n```</code>", "metadata": {"problem_id": 695, "library_problem_id": 29, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 28}}
{"id": 696, "code": "```python\ntensor = tf.constant(x)\ndecoded_tensor = tf.strings.decode_utf8(tensor)\nresult = decoded_tensor.numpy().tolist()\n```\n\n</code>", "metadata": {"problem_id": 696, "library_problem_id": 30, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 30}}
{"id": 697, "code": "```python\n    result = []\n    for byte_string in x:\n        decoded_unicode = tf.strings.unicode_decode(byte_string, 'UTF-8', errors='ignore')\n        decoded_string = decoded_unicode.numpy().decode('utf-8')\n        result.append(decoded_string)\n    return result\n```</code>", "metadata": {"problem_id": 697, "library_problem_id": 31, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 30}}
{"id": 698, "code": "```python\n    mask = tf.cast(x != 0, dtype=tf.float32)\n    sum_x = tf.reduce_sum(x, axis=-2)\n    count_x = tf.reduce_sum(mask, axis=-2)\n    result = tf.where(count_x > 0, sum_x / count_x, tf.zeros_like(sum_x))\n```\n\n</code>", "metadata": {"problem_id": 698, "library_problem_id": 32, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 32}}
{"id": 699, "code": "```python\nmask = tf.cast(tf.math.reduce_any(tf.math.not_equal(x, 0), axis=-1, keepdims=True), tf.float32)\nnum_non_zeros = tf.reduce_sum(mask, axis=-2, keepdims=True)\nmean = tf.reduce_sum(x * mask, axis=-2, keepdims=True) / (num_non_zeros + tf.keras.backend.epsilon())\nvariance = tf.reduce_sum(((x - mean)**2) * mask, axis=-2, keepdims=True) / (num_non_zeros + tf.keras.backend.epsilon())\nresult = tf.squeeze(variance, axis=[-1,-2])\n```\n\n</code>", "metadata": {"problem_id": 699, "library_problem_id": 33, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 32}}
{"id": 700, "code": "```python\n    mask = tf.math.not_equal(x, 0)\n    sum_x = tf.reduce_sum(tf.where(mask, x, tf.zeros_like(x)), axis=-2)\n    count = tf.reduce_sum(tf.cast(mask, tf.float32), axis=-2)\n    result = tf.where(tf.equal(count, 0), tf.zeros_like(sum_x), sum_x / count)\n    return result\n```</code>", "metadata": {"problem_id": 700, "library_problem_id": 34, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 32}}
{"id": 701, "code": "```python\ntf.random.set_seed(10)\nA = tf.random.normal([100,100])\nB = tf.random.normal([100,100])\nresult = tf.reduce_sum(tf.matmul(A,B))\n```\n", "metadata": {"problem_id": 701, "library_problem_id": 35, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 35}}
{"id": 702, "code": "```python\nresult = tf.argmax(a, axis=1)\n```", "metadata": {"problem_id": 702, "library_problem_id": 36, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 36}}
{"id": 703, "code": "```python\nresult = tf.argmax(a, axis=1)\n```", "metadata": {"problem_id": 703, "library_problem_id": 37, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 36}}
{"id": 704, "code": "```python\n    return tf.argmax(a, axis=1)\n```", "metadata": {"problem_id": 704, "library_problem_id": 38, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 36}}
{"id": 705, "code": "```python\nresult = tf.argmin(a, axis=0)\n```\n\n</code>", "metadata": {"problem_id": 705, "library_problem_id": 39, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 36}}
{"id": 706, "code": "```python\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nimport numpy as np\n\nnetwork_layout = []\nfor i in range(3):\n    network_layout.append(8)\n\nmodel = Sequential()\n\ninputdim = 4\nactivation = 'relu'\noutputdim = 2\nopt='rmsprop'\nepochs = 2\n#Adding input layer and first hidden layer\nmodel.add(Dense(network_layout[0],\n                name=\"Input\",\n                input_dim=inputdim,\n                kernel_initializer='he_normal',\n                activation=activation))\n\n#Adding the rest of hidden layer\nfor numneurons in network_layout[1:]:\n    model.add(Dense(numneurons,\n                    kernel_initializer = 'he_normal',\n                    activation=activation))\n\n#Adding the output layer\nmodel.add(Dense(outputdim,\n                name=\"Output\",\n                kernel_initializer=\"he_normal\",\n                activation=\"relu\"))\n\n#Compiling the model\nmodel.compile(optimizer=opt,loss='mse',metrics=['mse','mae','mape'])\nmodel.summary()\n\n# Generate dummy data for training\nXtrain = np.random.rand(100, inputdim)\nytrain = np.random.rand(100, outputdim)\nXtest = np.random.rand(50, inputdim)\nytest = np.random.rand(50, outputdim)\n\n#Training the model\nhistory = model.fit(x=Xtrain, y=ytrain, validation_data=(Xtest, ytest), batch_size=32, epochs=epochs)\n\n# Save the model in SavedModel format\nmodel.save('my_model', save_format='tf')\n```\n\n</code>", "metadata": {"problem_id": 706, "library_problem_id": 40, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 40}}
{"id": 707, "code": "```python\ntf.random.set_seed(seed_x)\nresult = tf.random.uniform(shape=[10], minval=1, maxval=5, dtype=tf.int32)\n```", "metadata": {"problem_id": 707, "library_problem_id": 41, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 41}}
{"id": 708, "code": "```python\nimport tensorflow as tf\n\nseed_x = 10\n### return the tensor as variable 'result'\ntf.random.set_seed(seed_x)\nresult = tf.random.uniform(shape=[114], minval=2, maxval=6, dtype=tf.int32)\n```", "metadata": {"problem_id": 708, "library_problem_id": 42, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 41}}
{"id": 709, "code": "```python\n    tf.random.set_seed(seed_x)\n    result = tf.random.uniform(shape=[10], minval=1, maxval=5, dtype=tf.int32)\n    return result\n### END SOLUTION\n```", "metadata": {"problem_id": 709, "library_problem_id": 43, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 41}}
{"id": 710, "code": "```python\nresult = tf.__version__\n```", "metadata": {"problem_id": 710, "library_problem_id": 44, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 44}}
{"id": 711, "code": "```python\nimport numpy as np\nimport scipy\nx = np.array([1, 7, 20, 50, 79])\ny = np.array([10, 19, 30, 35, 51])\n\nlog_x = np.log(x)\ncoefficients = np.polyfit(log_x, y, 1)\nresult = coefficients\n</code>\n", "metadata": {"problem_id": 711, "library_problem_id": 0, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 0}}
{"id": 712, "code": "```python\nlog_x = np.log(x)\ncoeffs = np.polyfit(log_x, y, 1)\nresult = np.array([coeffs[1], coeffs[0]])\n</code>\n", "metadata": {"problem_id": 712, "library_problem_id": 1, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 0}}
{"id": 713, "code": "```python\ndef func(x, A, B, C):\n    return A * np.exp(B * x) + C\npopt, pcov = scipy.optimize.curve_fit(func, x, y, p0=p0)\nresult = np.array(popt)\n</code>\n", "metadata": {"problem_id": 713, "library_problem_id": 2, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 0}}
{"id": 714, "code": "```python\nstatistic, p_value = stats.ks_2samp(x, y)\n</code>", "metadata": {"problem_id": 714, "library_problem_id": 3, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 3}}
{"id": 715, "code": "```python\nstatistic, p_value = stats.ks_2samp(x, y)\nresult = p_value < alpha\n</code>", "metadata": {"problem_id": 715, "library_problem_id": 4, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 3}}
{"id": 716, "code": "```python\ndef f(x):\n  a, b, c = x\n  return ((a+b-c)-2)**2 + ((3*a-b-c))**2 + sin(b) + cos(b) + 4\n\nresult = optimize.minimize(f, initial_guess).x.tolist()\n</code></code>", "metadata": {"problem_id": 716, "library_problem_id": 5, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 5}}
{"id": 717, "code": "```python\np_values = scipy.stats.norm.cdf(z_scores)\n</code>\n", "metadata": {"problem_id": 717, "library_problem_id": 6, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 6}}
{"id": 718, "code": "```python\np_values = scipy.stats.norm.cdf(z_scores)\n```</code>", "metadata": {"problem_id": 718, "library_problem_id": 7, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 6}}
{"id": 719, "code": "```python\nz_scores = scipy.stats.norm.ppf(p_values)\n</code>\n", "metadata": {"problem_id": 719, "library_problem_id": 8, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 6}}
{"id": 720, "code": "```python\ns = stddev\nresult = stats.lognorm.cdf(x, s, scale=np.exp(mu))\n```</code>", "metadata": {"problem_id": 720, "library_problem_id": 9, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 9}}
{"id": 721, "code": "```python\ns = stddev\nscale = np.exp(mu)\nexpected_value = np.exp(mu + (stddev**2)/2)\nmedian = np.exp(mu)\n</code>\n```", "metadata": {"problem_id": 721, "library_problem_id": 10, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 9}}
{"id": 722, "code": "```python\nsb = sparse.csr_matrix(sb.toarray().reshape(1, -1))\nresult = sa.multiply(sb)\n```</code>", "metadata": {"problem_id": 722, "library_problem_id": 11, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 11}}
{"id": 723, "code": "```python\n    sB = np.array(sB.todense()).reshape(-1)\n    result = sA.multiply(sB)\n    return result\n```", "metadata": {"problem_id": 723, "library_problem_id": 12, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 11}}
{"id": 724, "code": "```python\ninterpolator = scipy.interpolate.LinearNDInterpolator(points, V)\nresult = interpolator(request)[0]\n</code>", "metadata": {"problem_id": 724, "library_problem_id": 13, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 13}}
{"id": 725, "code": "```python\ninterpolator = scipy.interpolate.LinearNDInterpolator(points, V)\nresult = list(interpolator(request))\n```</code>", "metadata": {"problem_id": 725, "library_problem_id": 14, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 13}}
{"id": 726, "code": "```python\n    center_x, center_y = data_orig.shape[1] // 2, data_orig.shape[0] // 2\n    angle_rad = np.radians(angle)\n    rotation_matrix = np.array([[np.cos(angle_rad), -np.sin(angle_rad)],\n                                [np.sin(angle_rad), np.cos(angle_rad)]])\n    x_translated, y_translated = x0 - center_x, y0 - center_y\n    rotated_point = rotation_matrix @ [x_translated, y_translated]\n    xrot, yrot = rotated_point[0] + center_x, rotated_point[1] + center_y\n    data_rot = rotate(data_orig, angle)\n</code>\n", "metadata": {"problem_id": 726, "library_problem_id": 15, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 15}}
{"id": 727, "code": "```python\nresult = M.diagonal()\n```</code>", "metadata": {"problem_id": 727, "library_problem_id": 16, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 16}}
{"id": 728, "code": "```python\n    times_scaled = np.array(times) / T\n    result = stats.kstest(times_scaled, 'uniform')\n```\n\n</code>", "metadata": {"problem_id": 728, "library_problem_id": 17, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 17}}
{"id": 729, "code": "```python\n    return stats.kstest(times, lambda x: x / T)\n### END SOLUTION\n</code>", "metadata": {"problem_id": 729, "library_problem_id": 18, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 17}}
{"id": 730, "code": "```python\ntimes_scaled = np.array(times) / T\nks_statistic, p_value = stats.kstest(times_scaled, 'uniform')\nresult = p_value > 0.05\n```\n\n</code>", "metadata": {"problem_id": 730, "library_problem_id": 19, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 17}}
{"id": 731, "code": "```python\nfrom scipy import sparse\nc1 = sparse.csr_matrix([[0, 0, 1, 0], [2, 0, 0, 0], [0, 0, 0, 0]])\nc2 = sparse.csr_matrix([[0, 3, 4, 0], [0, 0, 0, 5], [6, 7, 0, 8]])\nFeature = sparse.hstack([c1, c2])\n```\n\n</code>", "metadata": {"problem_id": 731, "library_problem_id": 20, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 20}}
{"id": 732, "code": "```python\nFeature = sparse.hstack([c1, c2])\n```\n\n</code>", "metadata": {"problem_id": 732, "library_problem_id": 21, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 20}}
{"id": 733, "code": "```python\nfrom scipy import sparse\nc1 = sparse.csr_matrix([[0, 0, 1, 0], [2, 0, 0, 0], [0, 0, 0, 0]])\nc2 = sparse.csr_matrix([[0, 3, 4, 0], [0, 0, 0, 5], [6, 7, 0, 8]])\nFeature = sparse.vstack([c1, c2])\n</code>\n", "metadata": {"problem_id": 733, "library_problem_id": 22, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 20}}
{"id": 734, "code": "```python\ndef euclidean_distance(point1, point2):\n    return np.sqrt(np.sum((np.array(point1) - np.array(point2)) ** 2))\n\ndef cost_matrix(points1, points2):\n    cost_matrix = np.zeros((len(points1), len(points2)))\n    for i in range(len(points1)):\n        for j in range(len(points2)):\n            cost_matrix[i, j] = euclidean_distance(points1[i], points2[j])\n    return cost_matrix\n\ndef optimal_assignment(cost_mat):\n    row_ind, col_ind = scipy.optimize.linear_sum_assignment(cost_mat)\n    return col_ind\n\ndef solve_mapping(points1, points2):\n    cost_mat = cost_matrix(points1, points2)\n    col_ind = optimal_assignment(cost_mat)\n    return list(col_ind)\n\nresult = solve_mapping(points1, points2)\n```\n\n</code>", "metadata": {"problem_id": 734, "library_problem_id": 23, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 23}}
{"id": 735, "code": "```python\nimport itertools\n\ndef manhattan_distance(point1, point2):\n    return sum(abs(x - y) for x, y in zip(point1, point2))\n\ndef total_manhattan_distance(points1, points2, permutation):\n    total_distance = 0\n    for i, j in enumerate(permutation):\n        total_distance += manhattan_distance(points1[i], points2[j])\n    return total_distance\n\ndef optimal_assignment(points1, points2):\n    n = len(points1)\n    min_distance = float('inf')\n    optimal_permutation = None\n    for permutation in itertools.permutations(range(n)):\n        distance = total_manhattan_distance(points1, points2, permutation)\n        if distance < min_distance:\n            min_distance = distance\n            optimal_permutation = list(permutation)\n    return optimal_permutation\n\nresult = optimal_assignment(points1, points2)\n```\n\n</code>", "metadata": {"problem_id": 735, "library_problem_id": 24, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 23}}
{"id": 736, "code": "```python\nrow, col = b.shape\nmask = np.ones(len(b.data), dtype=bool)\nfor i in range(row):\n    if (i in b.indices):\n        idx = np.where(b.indices == i)[0]\n        for j in idx:\n            if (b.indptr[i] + j) < len(b.data):\n                mask[b.indptr[i] + j] = False\n\nb.data = b.data[mask]\nb.indices = b.indices[mask]\nb.eliminate_zeros()\n</code>\n", "metadata": {"problem_id": 736, "library_problem_id": 25, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 25}}
{"id": 737, "code": "```python\nbinary_img = img > threshold\nlabeled_img, num_labels = ndimage.label(binary_img)\nresult = num_labels\n</code>\n", "metadata": {"problem_id": 737, "library_problem_id": 26, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 26}}
{"id": 738, "code": "```python\nmask = img < threshold\nlabeled_array, num_regions = ndimage.label(mask)\nresult = num_regions\n</code>\n", "metadata": {"problem_id": 738, "library_problem_id": 27, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 26}}
{"id": 739, "code": "```python\n    mask = img > threshold\n    labeled_img, num_regions = ndimage.label(mask, structure=np.ones((3, 3)))\n    return num_regions\n```", "metadata": {"problem_id": 739, "library_problem_id": 28, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 26}}
{"id": 740, "code": "```python\nmask = img > threshold\nlabeled_img, num_labels = ndimage.label(mask)\ncenters = ndimage.center_of_mass(img, labeled_img, range(1, num_labels + 1))\ndistances = [np.sqrt(center[0]**2 + center[1]**2) for center in centers]\nresult = distances\n```\n\n</code>", "metadata": {"problem_id": 740, "library_problem_id": 29, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 26}}
{"id": 741, "code": "```python\ndef make_symmetric(M):\n    M = M.tolil()\n    for i in range(M.shape[0]):\n        for j in range(i + 1, M.shape[1]):\n            if M[j, i] == 0:\n                M[j, i] = M[i, j]\n            elif M[i,j] == 0:\n                M[i,j] = M[j,i]\n    return M\n\nM = make_symmetric(M)\n</code>\n", "metadata": {"problem_id": 741, "library_problem_id": 30, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 30}}
{"id": 742, "code": "```python\n    for i in range(sA.shape[0]):\n        for j in range(i + 1, sA.shape[1]):\n            if sA[i, j] != 0:\n                if sA[j, i] == 0:\n                    sA[j, i] = sA[i, j]\n    return sA\n```</code>", "metadata": {"problem_id": 742, "library_problem_id": 31, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 30}}
{"id": 743, "code": "```python\nimport numpy as np\nimport scipy.ndimage\n\ndef remove_isolated_cells(array):\n    kernel = np.array([[0, 1, 0],\n                       [1, 1, 1],\n                       [0, 1, 0]])\n    \n    convolved = scipy.ndimage.convolve(array, kernel, mode='constant', cval=0)\n    isolated_mask = (convolved == 1)\n    array[isolated_mask] = 0\n    return array\n\nsquare = remove_isolated_cells(square)\n```\n\n</code>", "metadata": {"problem_id": 743, "library_problem_id": 32, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 32}}
{"id": 744, "code": "```python\nfrom scipy import ndimage\n\nstructure = np.array([[0, 1, 0],\n                       [1, 1, 1],\n                       [0, 1, 0]])\n\nisolated_points = ndimage.convolve(square > 0, structure, mode='constant', cval=0) == 1\nsquare[isolated_points] = 0\n```\n\n</code>", "metadata": {"problem_id": 744, "library_problem_id": 33, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 32}}
{"id": 745, "code": "```python\nnon_zero_elements = col.data\nmean = np.mean(non_zero_elements)\nstandard_deviation = np.std(non_zero_elements)\n</code>\n", "metadata": {"problem_id": 745, "library_problem_id": 34, "library": "Scipy", "test_case_cnt": 4, "perturbation_type": "Origin", "perturbation_origin_id": 34}}
{"id": 746, "code": "```python\nnon_zero_values = col.data\nif len(non_zero_values) > 0:\n    Max = np.max(non_zero_values)\n    if np.all(non_zero_values >= 0):\n        Min = 0\n    else:\n        Min = np.min(non_zero_values)\nelse:\n    Max = 0\n    Min = 0\n</code>\n", "metadata": {"problem_id": 746, "library_problem_id": 35, "library": "Scipy", "test_case_cnt": 4, "perturbation_type": "Semantic", "perturbation_origin_id": 34}}
{"id": 747, "code": "```python\nfrom scipy import stats\nMedian = np.median(col.data)\nMode = stats.mode(col.data)[0][0]\n</code>\n", "metadata": {"problem_id": 747, "library_problem_id": 36, "library": "Scipy", "test_case_cnt": 4, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 34}}
{"id": 748, "code": "```python\n    def fourier_series(x, *a):\n        ret = 0\n        for i, ai in enumerate(a):\n            ret += ai * np.cos((i+1) * np.pi / tau * x)\n        return ret\n    popt, pcov = curve_fit(fourier_series, z, Ua, p0=[1] * degree)\n```</code>", "metadata": {"problem_id": 748, "library_problem_id": 37, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 37}}
{"id": 749, "code": "```python\nunique_ids = np.unique(example_array)\nregion_coords = {}\nfor region_id in unique_ids:\n    region_coords[region_id] = np.where(example_array == region_id)\n\nresults = []\nfor i in range(len(unique_ids)):\n    for j in range(i + 1, len(unique_ids)):\n        id1 = unique_ids[i]\n        id2 = unique_ids[j]\n        \n        if id1 == 0 or id2 == 0:\n            min_dist = np.inf\n        else:\n            coords1 = np.array(list(zip(region_coords[id1][0], region_coords[id1][1])))\n            coords2 = np.array(list(zip(region_coords[id2][0], region_coords[id2][1])))\n            \n            if len(coords1) == 0 or len(coords2) == 0:\n                min_dist = np.inf\n            else:\n                distances = scipy.spatial.distance.cdist(coords1, coords2, 'euclidean')\n                min_dist = np.min(distances)\n        \n        results.append((id1, id2, min_dist))\nresult = results\n```\n\n</code>", "metadata": {"problem_id": 749, "library_problem_id": 38, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 38}}
{"id": 750, "code": "```python\nimport numpy as np\nimport scipy.spatial.distance\n\nunique_ids = np.unique(example_array)\nunique_ids = unique_ids[unique_ids != 0]\n\nregion_coords = {}\nfor id in unique_ids:\n    region_coords[id] = np.where(example_array == id)\n\nresults = []\nfor id1 in unique_ids:\n    for id2 in unique_ids:\n        coords1 = np.array(list(zip(region_coords[id1][0], region_coords[id1][1])))\n        coords2 = np.array(list(zip(region_coords[id2][0], region_coords[id2][1])))\n        \n        if coords1.size > 0 and coords2.size > 0:\n            distances = scipy.spatial.distance.cdist(coords1, coords2, metric='cityblock')\n            min_distance = np.min(distances)\n        else:\n            min_distance = np.inf \n\n        results.append((id1, id2, min_distance))\n\nresult = results\n```</code>", "metadata": {"problem_id": 750, "library_problem_id": 39, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 38}}
{"id": 751, "code": "```python\n    unique_ids = np.unique(example_array)\n    unique_ids = unique_ids[unique_ids != 0]\n    \n    distances = np.zeros((len(unique_ids), len(unique_ids)))\n    \n    region_coords = {}\n    for region_id in unique_ids:\n        region_coords[region_id] = np.where(example_array == region_id)\n    \n    for i, id1 in enumerate(unique_ids):\n        for j, id2 in enumerate(unique_ids):\n            if i == j:\n                distances[i, j] = 0  # Distance to itself is 0\n            else:\n                coords1 = np.array(list(zip(region_coords[id1][0], region_coords[id1][1])))\n                coords2 = np.array(list(zip(region_coords[id2][0], region_coords[id2][1])))\n                \n                min_dist = np.min(scipy.spatial.distance.cdist(coords1, coords2, 'euclidean'))\n                distances[i, j] = min_dist\n    \n    return distances\n```</code>", "metadata": {"problem_id": 751, "library_problem_id": 40, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 38}}
{"id": 752, "code": "```python\nresult = np.zeros((5, 100))\nfor i in range(5):\n    tck = interpolate.splrep(x[:, i], y[:, i], k=2, s=4)\n    y_extrap = interpolate.splev(x_val, tck)\n    result[i, :] = y_extrap\n```\n\n</code>", "metadata": {"problem_id": 752, "library_problem_id": 41, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 41}}
{"id": 753, "code": "```python\nimport numpy as np\nimport scipy.stats as ss\nx1=[38.7,  41.5,  43.8,  44.5,  45.5,  46.0,  47.7,  58.0]\nx2=[39.2,  39.3,  39.7,  41.4,  41.8,  42.9,  43.3,  45.8]\nx3=[34.0,  35.0,  39.0,  40.0,  43.0,  43.0,  44.0,  45.0]\nx4=[34.0,  34.8,  34.8,  35.4,  37.2,  37.8,  41.2,  42.8]\nstatistic, critical_values, significance_level = ss.anderson_ksamp([x1, x2, x3, x4])\n</code>\n```", "metadata": {"problem_id": 753, "library_problem_id": 42, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 42}}
{"id": 754, "code": "```python\nimport numpy as np\nimport scipy.stats as ss\nx1=np.array([38.7,  41.5,  43.8,  44.5,  45.5,  46.0,  47.7,  58.0])\nx2=np.array([39.2,  39.3,  39.7,  41.4,  41.8,  42.9,  43.3,  45.8])\nanderson_result = ss.anderson_ksamp([x1, x2])\np_value = anderson_result.significance_level\nresult = p_value > 0.05\n```\n\n</code>", "metadata": {"problem_id": 754, "library_problem_id": 43, "library": "Scipy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 42}}
{"id": 755, "code": "```python\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nfrom itertools import combinations\n\ndf = pd.DataFrame([[1, 5, 2], [2, 4, 4], [3, 3, 1], [4, 2, 2], [5, 1, 4]], \n                 columns=['A', 'B', 'C'], index = [1, 2, 3, 4, 5])\n\ndef kendall_tau_rolling(df, col1, col2, window):\n    def calculate_kendalltau(x):\n        if len(x[col1]) < window:\n            return np.nan\n        else:\n            return stats.kendalltau(x[col1], x[col2])[0]\n    return df[[col1, col2]].rolling(window=window).apply(calculate_kendalltau, raw=False)\n\nwindow = 3\ncolumn_pairs = list(combinations(df.columns, 2))\n\nfor col1, col2 in column_pairs:\n    df[col1 + col2] = kendall_tau_rolling(df, col1, col2, window)\n```\n\n</code>", "metadata": {"problem_id": 755, "library_problem_id": 44, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 44}}
{"id": 756, "code": "```python\nresult = sa.nnz == 0\n</code>\n", "metadata": {"problem_id": 756, "library_problem_id": 45, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 45}}
{"id": 757, "code": "```python\nresult = sa.nnz == 0\n</code>\n", "metadata": {"problem_id": 757, "library_problem_id": 46, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 45}}
{"id": 758, "code": "```python\nn, x, b = a.shape\nresult = np.zeros((n*x, n*b))\nfor i in range(n):\n    result[i*x:(i+1)*x, i*b:(i+1)*b] = a[i]\n</code>", "metadata": {"problem_id": 758, "library_problem_id": 47, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 47}}
{"id": 759, "code": "```python\nranksums_result = stats.ranksums(pre_course_scores, during_course_scores)\np_value = ranksums_result.pvalue\n</code>\n", "metadata": {"problem_id": 759, "library_problem_id": 48, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 48}}
{"id": 760, "code": "```python\n    result = stats.ranksums(pre_course_scores, during_course_scores)\n    return result.pvalue\n### END SOLUTION\n</code>\n", "metadata": {"problem_id": 760, "library_problem_id": 49, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 48}}
{"id": 761, "code": "```python\nmean = np.mean(a)\nstd = np.std(a)\nn = len(a)\nfourth_moment = np.sum((a - mean)**4) / n\nkurtosis_result = fourth_moment / (std**4)\n```\n", "metadata": {"problem_id": 761, "library_problem_id": 50, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 50}}
{"id": 762, "code": "```python\n    mean = np.mean(a)\n    std = np.std(a)\n    fourth_moment = np.sum((a - mean)**4) / len(a)\n    kurtosis = fourth_moment / (std**4) - 3\n    kurtosis_result = kurtosis\n```", "metadata": {"problem_id": 762, "library_problem_id": 51, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 50}}
{"id": 763, "code": "```python\nf = scipy.interpolate.RectBivariateSpline(x[:,0], y[0,:], z)\nresult = [f(s[i], t[i])[0][0] for i in range(len(s))]\n```\n\n</code>", "metadata": {"problem_id": 763, "library_problem_id": 52, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 52}}
{"id": 764, "code": "```python\n    f_interp = scipy.interpolate.interp2d(x, y, z, kind='cubic')\n    result = [f_interp(s[i], t[i])[0] for i in range(len(s))]\n    return result\n```", "metadata": {"problem_id": 764, "library_problem_id": 53, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 52}}
{"id": 765, "code": "```python\nimport numpy as np\nregion_indices = []\nfor point in extraPoints:\n    region_indices.append(vor.point_region[vor.find_simplex(point)])\nresult = np.array(region_indices)\n</code>\n", "metadata": {"problem_id": 765, "library_problem_id": 54, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 54}}
{"id": 766, "code": "```python\nimport numpy as np\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\nimport matplotlib.pyplot as plt\n\npoints = [[0,0], [1,4], [2,3], [4,1], [1,1], [2,2], [5,3]]\nvor = Voronoi(points)\nextraPoints = [[0.5,0.2], [3, 0], [4,0],[5,0], [4,3]]\n\nresult = []\nfor point in extraPoints:\n    region_index = -1\n    for i, region in enumerate(vor.regions):\n        if not region or -1 in region:\n            continue\n        polygon = vor.vertices[region]\n        \n        from matplotlib.path import Path\n        p = Path(polygon)\n        if p.contains_point(point):\n            region_index = i\n            break\n    result.append(region_index)\n\nresult = np.array(result)\n```</code>", "metadata": {"problem_id": 766, "library_problem_id": 55, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 54}}
{"id": 767, "code": "```python\nmax_len = max(len(v) for v in vectors)\npadded_vectors = [np.pad(v, (0, max_len - len(v)), 'constant') for v in vectors]\nsparse_matrix = sparse.csr_matrix(padded_vectors)\nresult = sparse_matrix\n```\n\n</code>", "metadata": {"problem_id": 767, "library_problem_id": 56, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 56}}
{"id": 768, "code": "```python\nb = scipy.ndimage.median_filter(a, size=3, origin=(0, -1))\n```</code>", "metadata": {"problem_id": 768, "library_problem_id": 57, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 57}}
{"id": 769, "code": "```python\nimport numpy as np\nfrom scipy.sparse import csr_matrix\n\narr = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]])\nM = csr_matrix(arr)\nrow = 2\ncolumn = 3\n\nresult = M.getrow(row).toarray()[0, column]\n</code>\n```", "metadata": {"problem_id": 769, "library_problem_id": 58, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 58}}
{"id": 770, "code": "```python\ndef get_values_from_csr(matrix, row_indices, col_indices):\n    result = []\n    for row_index, col_index in zip(row_indices, col_indices):\n        result.append(matrix[row_index, col_index])\n    return result\n\nresult = get_values_from_csr(M, row, column)\n</code>\n", "metadata": {"problem_id": 770, "library_problem_id": 59, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 58}}
{"id": 771, "code": "```python\nf = scipy.interpolate.interp1d(x, array, axis=0)\nnew_array = f(x_new)\n```\n\n</code>", "metadata": {"problem_id": 771, "library_problem_id": 60, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 60}}
{"id": 772, "code": "```python\ndef NormalDistro(u,o2,x):\n    dev = abs((x-u)/o2)\n    P_inner = scipy.integrate.quad(NDfx,-dev,dev)[0]\n    P_outer = 1 - P_inner\n    P = P_inner + P_outer/2\n    return(P)\nprob = NormalDistro(u,o2,x)\n</code>", "metadata": {"problem_id": 772, "library_problem_id": 61, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 61}}
{"id": 773, "code": "```python\n    dev = abs((x-u)/o2)\n    P = 0.5 + scipy.integrate.quad(NDfx,-dev,dev)[0]/2\n    return(P)\n### END SOLUTION\n```", "metadata": {"problem_id": 773, "library_problem_id": 62, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 61}}
{"id": 774, "code": "```python\ndef dctmtx(N):\n    V = np.zeros((N, N))\n    for k in range(N):\n        for n in range(N):\n            if k == 0:\n                V[k, n] = np.sqrt(1/N)\n            else:\n                V[k, n] = np.sqrt(2/N) * np.cos(np.pi/N * k * (n + 0.5))\n    return V\n\nresult = dctmtx(N)\n</code>\n", "metadata": {"problem_id": 774, "library_problem_id": 63, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 63}}
{"id": 775, "code": "```python\nfrom scipy import sparse\nimport numpy as np\nv1 = [3*i**2 +(i/2) for i in range(1, 6)]\nv2 = [-(6*i**2 - 1) for i in range(1, 6)]\nv3 = [3*i**2 -(i/2) for i in range(1, 6)]\nlower_diagonal = v3[:-1]\nmain_diagonal = v2\nupper_diagonal = v1[:-1]\ndiagonals = [lower_diagonal, main_diagonal, upper_diagonal]\noffsets = [-1, 0, 1]\nresult = sparse.diags(diagonals, offsets, shape=(5, 5)).toarray()\n```\n\n</code>", "metadata": {"problem_id": 775, "library_problem_id": 64, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 64}}
{"id": 776, "code": "```python\nimport numpy as np\nimport scipy.stats\nN = 3\np = 0.5\n\nM = np.zeros((N + 1, N + 1))\nfor i in range(N + 1):\n    for j in range(i + 1):\n        M[i, j] = scipy.stats.binom.pmf(j, i, p)\n\nresult = M\n```\n\n</code>", "metadata": {"problem_id": 776, "library_problem_id": 65, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 65}}
{"id": 777, "code": "```python\nresult = df.apply(stats.zscore, axis=1)\n```</code>", "metadata": {"problem_id": 777, "library_problem_id": 66, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 66}}
{"id": 778, "code": "```python\nresult = stats.zscore(df, axis=0)\nresult = pd.DataFrame(result, index=df.index, columns=df.columns)\n```</code>", "metadata": {"problem_id": 778, "library_problem_id": 67, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 66}}
{"id": 779, "code": "```python\nzscores = stats.zscore(df, axis=1)\nrows = []\nfor index in df.index:\n    rows.append({'probegenes': index, 'type': 'data', 'sample1': df.loc[index, 'sample1'], 'sample2': df.loc[index, 'sample2'], 'sample3': df.loc[index, 'sample3']})\n    rows.append({'probegenes': index, 'type': 'zscore', 'sample1': zscores[df.index.get_loc(index), 0], 'sample2': zscores[df.index.get_loc(index), 1], 'sample3': zscores[df.index.get_loc(index), 2]})\nresult = pd.DataFrame.from_records(rows)\nresult = result.set_index(['probegenes', 'type'])\n```\n\n</code>", "metadata": {"problem_id": 779, "library_problem_id": 68, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 66}}
{"id": 780, "code": "```python\nzscores = stats.zscore(df, axis=0, nan_policy='omit')\ndf_zscores = pd.DataFrame(zscores, index=df.index, columns=df.columns)\nindex = pd.MultiIndex.from_product([df.index, ['data', 'zscore']], names=['probegenes', None])\nresult = pd.DataFrame(index=index, columns=df.columns)\nresult.loc[(slice(None), 'data'), :] = df.values\nresult.loc[(slice(None), 'zscore'), :] = df_zscores.values\nresult = result.applymap(lambda x: f\"{x:.3f}\" if pd.notnull(x) else x)\n```\n\n</code>", "metadata": {"problem_id": 780, "library_problem_id": 69, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 66}}
{"id": 781, "code": "```python\nstarting_point = np.array([1.8, 1.7])\ndirection = np.array([-1, -1])\nresult = scipy.optimize.line_search(test_func, test_grad, starting_point, direction)[0]\n</code>\n", "metadata": {"problem_id": 781, "library_problem_id": 70, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 70}}
{"id": 782, "code": "```python\nrows, cols = shape\ny, x = np.indices(shape)\ncenter_y, center_x = rows / 2, cols / 2\ncoords = np.dstack((y, x)).reshape(-1, 2)\ncenter = np.array([[center_y, center_x]])\nresult = distance.cdist(coords, center).reshape(shape)\n```</code>", "metadata": {"problem_id": 782, "library_problem_id": 71, "library": "Scipy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 71}}
{"id": 783, "code": "```python\nrows, cols = shape\ncenter_y, center_x = (rows - 1) / 2, (cols - 1) / 2\ny, x = np.mgrid[:rows, :cols]\ncoords = np.stack((y, x), axis=-1)\ncenter = np.array([[center_y, center_x]])\nresult = distance.cdist(coords.reshape(-1, 2), center, metric='cityblock').reshape(rows, cols)\n```\n\n</code>", "metadata": {"problem_id": 783, "library_problem_id": 72, "library": "Scipy", "test_case_cnt": 3, "perturbation_type": "Semantic", "perturbation_origin_id": 71}}
{"id": 784, "code": "```python\n    rows, cols = shape\n    y = np.arange(rows)\n    x = np.arange(cols)\n    row_center = (rows - 1) / 2\n    col_center = (cols - 1) / 2\n    xv, yv = np.meshgrid(x, y)\n    coords = np.stack((yv, xv), axis=-1)\n    center = np.array([[row_center, col_center]])\n    distances = distance.cdist(coords.reshape(-1, 2), center).reshape(rows, cols)\n    return distances\n### END SOLUTION\n</code>", "metadata": {"problem_id": 784, "library_problem_id": 73, "library": "Scipy", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 71}}
{"id": 785, "code": "```python\ntargets = [(4, 6), (6, 8), (6, 10)]\nbest_result = None\nmin_diff = float('inf')\nfor target_shape in targets:\n    zoom_factors = (target_shape[0] / x.shape[0], target_shape[1] / x.shape[1])\n    resampled = scipy.ndimage.zoom(x, zoom_factors, order=1)\n    diff = np.sum(np.abs(np.array(resampled.shape) - np.array(target_shape)))\n    if diff < min_diff:\n        min_diff = diff\n        best_result = resampled\nresult = best_result\n```</code>", "metadata": {"problem_id": 785, "library_problem_id": 74, "library": "Scipy", "test_case_cnt": 4, "perturbation_type": "Origin", "perturbation_origin_id": 74}}
{"id": 786, "code": "```python\ndef objective_function(x, a, y):\n    return np.sum((a.dot(x**2) - y)**2)\n\nresult = scipy.optimize.minimize(objective_function, x0, args=(a, y), method='BFGS')\nout = result.x\n</code>", "metadata": {"problem_id": 786, "library_problem_id": 75, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 75}}
{"id": 787, "code": "```python\ndef objective_function(x, a, y):\n    return np.sum((a.dot(x**2) - y)**2)\n\nbounds = [(x_lower_bounds[i], None) for i in range(len(x_lower_bounds))]\n\nout = scipy.optimize.minimize(objective_function, x0, args=(a, y), method='L-BFGS-B', bounds=bounds)\n```\n\n</code>", "metadata": {"problem_id": 787, "library_problem_id": 76, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 75}}
{"id": 788, "code": "```python\nimport scipy.integrate\nimport numpy as np\nN0 = 10\ntime_span = [-0.1, 0.1]\n\ndef dN1_dt_simple(t, N1):\n    return -100 * N1 + np.sin(t)\n\nsol = scipy.integrate.solve_ivp(fun=dN1_dt_simple, t_span=time_span, y0=[N0,])\nresult = sol.y\n```</code>", "metadata": {"problem_id": 788, "library_problem_id": 77, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 77}}
{"id": 789, "code": "```python\nimport scipy.integrate\nimport numpy as np\nN0 = 1\ntime_span = [0, 10]\n\ndef input_function(t):\n    if 0 < t < 2 * np.pi:\n        return t - np.sin(t)\n    else:\n        return 2 * np.pi\n\ndef dN1_dt_simple(t, N1):\n    return -100 * (N1 + input_function(t))\n\nsol = scipy.integrate.solve_ivp(fun=dN1_dt_simple, t_span=time_span, y0=[N0,], dense_output=True)\nresult = sol.y\n```</code>", "metadata": {"problem_id": 789, "library_problem_id": 78, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 77}}
{"id": 790, "code": "```python\nimport scipy.integrate\nimport numpy as np\nN0 = 10\ntime_span = [-0.1, 0.1]\n\ndef dN1_dt(t, N1):\n    return -100 * N1 - np.cos(t)\n\nt_eval = np.linspace(time_span[0], time_span[1], 100)\n\nsol = scipy.integrate.solve_ivp(fun=dN1_dt, t_span=time_span, y0=[N0,], t_eval=t_eval)\nresult = sol.y\n```</code>", "metadata": {"problem_id": 790, "library_problem_id": 79, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 77}}
{"id": 791, "code": "```python\nfor t in range (4):\n    cons.append({'type':'ineq', 'fun': lambda x, t=t: x[t]})\n\nout=minimize(function, x0, method=\"SLSQP\", constraints=cons)\nx=out[\"x\"]\n```\n\n</code>", "metadata": {"problem_id": 791, "library_problem_id": 80, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 80}}
{"id": 792, "code": "```python\nimport numpy as np\nsa_data = sa.data\nsa_indices = sa.indices\nsa_indptr = sa.indptr\nsb_data = sb.data\nsb_indices = sb.indices\nsb_indptr = sb.indptr\ndata = np.concatenate((sa_data, sb_data))\nindices = np.concatenate((sa_indices, sb_indices))\nindptr = np.concatenate((sa_indptr[:-1], sb_indptr[1:] + sa_indptr[-1]))\nresult = sparse.csr_matrix((data, indices, indptr), shape=(sa.shape[0] + sb.shape[0], sa.shape[1]))\n```</code>", "metadata": {"problem_id": 792, "library_problem_id": 81, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 81}}
{"id": 793, "code": "```python\nimport scipy.sparse as sparse\nimport numpy as np\n\ndef hstack_csr(a, b):\n    if a.shape[0] != b.shape[0]:\n        raise ValueError(\"Matrices must have the same number of rows\")\n\n    a_data = a.data\n    a_indices = a.indices\n    a_indptr = a.indptr\n\n    b_data = b.data\n    b_indices = b.indices\n    b_indptr = b.indptr\n\n    new_data = np.concatenate((a_data, b_data))\n    new_indices = np.concatenate((a_indices, b_indices))\n    new_indptr = np.concatenate((a_indptr[:-1], b_indptr[1:] + a.shape[1]))\n\n    return sparse.csr_matrix((new_data, new_indices, new_indptr), shape=(a.shape[0], a.shape[1] + b.shape[1]))\n\nresult = hstack_csr(sa, sb)\n```\n\n</code>", "metadata": {"problem_id": 793, "library_problem_id": 82, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 81}}
{"id": 794, "code": "```python\nimport numpy as np\nfrom scipy import integrate\n\nfn = 'cooltemp.dat'\nc = np.loadtxt(fn,unpack=True,usecols=[1])\nI=[]\nfor n in range(len(c)):\n    result,error = integrate.quad(lambda x: 2*x*c[n],0,1)\n    I.append(result)\nresult = np.array(I)\n</code>\n", "metadata": {"problem_id": 794, "library_problem_id": 83, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 83}}
{"id": 795, "code": "```python\n    results = []\n    for c_val in [c] if not hasattr(c, '__iter__') else c:\n        integrand = lambda x: 2 * c_val * x\n        result, error = scipy.integrate.quad(integrand, low, high)\n        results.append(result)\n    return results\n```", "metadata": {"problem_id": 795, "library_problem_id": 84, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 83}}
{"id": 796, "code": "```python\nfor key in V.keys():\n    if V[key] != 0:\n        V[key] = V[key] + x\n```</code>", "metadata": {"problem_id": 796, "library_problem_id": 85, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 85}}
{"id": 797, "code": "```python\nV = sparse.coo_matrix((V.data + x, (V.row, V.col)), shape=V.shape)\n```</code>", "metadata": {"problem_id": 797, "library_problem_id": 86, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 85}}
{"id": 798, "code": "```python\nrow, col, data = V.row, V.col, V.data\ndata = data + x\nV = sparse.coo_matrix((data, (row, col)), shape=V.shape)\nrow, col, data = V.row, V.col, V.data\ndata = data + y\nV = sparse.coo_matrix((data, (row, col)), shape=V.shape)\n```\n\n</code>", "metadata": {"problem_id": 798, "library_problem_id": 87, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 85}}
{"id": 799, "code": "```python\n    sa = sa.tocsc()\n    for i in range(sa.shape[1]):\n        col = sa[:, i]\n        norm = np.linalg.norm(col.data)\n        if norm != 0:\n            col.data = col.data / norm\n            sa[:, i] = col\n```</code>", "metadata": {"problem_id": 799, "library_problem_id": 88, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 88}}
{"id": 800, "code": "```python\nfor col in range(sa.shape[1]):\n    col_data = sa[:, col].data\n    if len(col_data) > 0:\n        norm = np.linalg.norm(col_data)\n        if norm > 0:\n            col_data /= norm\n            sa[:, col] = col_data\n```\n\n</code>", "metadata": {"problem_id": 800, "library_problem_id": 89, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 88}}
{"id": 801, "code": "```python\na = np.where(a > 0, 1, 0)\n</code>", "metadata": {"problem_id": 801, "library_problem_id": 90, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 90}}
{"id": 802, "code": "```python\nn = a.shape[0]\nb = np.zeros((n, n))\nfor i in range(n):\n    for j in range(i, n):\n        if a[i, j] == 0:\n            b[i, j] = 1\n        else:\n            b[i, j] = 0\n        b[j, i] = b[i, j]\na = b\n</code>\n", "metadata": {"problem_id": 802, "library_problem_id": 91, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 90}}
{"id": 803, "code": "```python\nresult = []\nfor i in range(centroids.shape[0]):\n    distances = scipy.spatial.distance.cdist(centroids[i, :].reshape(1, -1), data, 'euclidean')\n    closest_index = np.argmin(distances)\n    result.append(closest_index)\nresult = np.array(result)\n</code>\n", "metadata": {"problem_id": 803, "library_problem_id": 92, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 92}}
{"id": 804, "code": "```python\nclosest_points = []\nfor i in range(centroids.shape[0]):\n    cluster_points = data[np.where(np.argmin(abs(data - centroids[i]),axis=1) == 0)]\n    if cluster_points.size > 0:\n        distances = scipy.spatial.distance.cdist(np.expand_dims(centroids[i], axis=0), cluster_points)\n        closest_index = np.argmin(distances)\n        closest_points.append(cluster_points[closest_index])\n    else:\n        closest_points.append(centroids[i])\nresult = np.array(closest_points)\n```</code>", "metadata": {"problem_id": 804, "library_problem_id": 93, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 92}}
{"id": 805, "code": "```python\nn_clusters = centroids.shape[0]\nresult = []\nfor i in range(n_clusters):\n    distances = scipy.spatial.distance.cdist(data, centroids[i, :].reshape(1, -1))\n    cluster_indices = np.where(np.argmin(scipy.spatial.distance.cdist(data, centroids), axis=1) == i)[0]\n    cluster_distances = distances[cluster_indices].flatten()\n    kth_distance = np.partition(cluster_distances, k-1)[k-1]\n    index_in_cluster = np.where(cluster_distances == np.partition(cluster_distances, k-1)[k-1])[0][0]\n    result.append(cluster_indices[index_in_cluster])\n</code>\n", "metadata": {"problem_id": 805, "library_problem_id": 94, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 92}}
{"id": 806, "code": "```python\ndef eqn_to_solve(a, x, b):\n    return x + 2*a - b**2\n\na_values = []\nfor x, b in zip(xdata, bdata):\n    a = fsolve(eqn_to_solve, x0=0.5, args=(x, b))\n    a_values.append(a[0])\nresult = np.array(a_values)\n```</code>", "metadata": {"problem_id": 806, "library_problem_id": 95, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 95}}
{"id": 807, "code": "```python\n    def solve_for_b(x, a):\n        def equation(b):\n            return x + 2*a - b**2\n        roots = fsolve(equation, 0)\n        return roots\n\n    result = []\n    for x, a in zip(xdata, adata):\n        roots = solve_for_b(x, a)\n        sorted_roots = sorted(roots)\n        result.append(sorted_roots.tolist())\n</code>", "metadata": {"problem_id": 807, "library_problem_id": 96, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 95}}
{"id": 808, "code": "```python\ndef cdf(x, a, m, d):\n    return integrate.quad(bekkers, range_start, x, args=(a, m, d))[0]\ncdf_func = lambda x: cdf(x, estimated_a, estimated_m, estimated_d)\nresult = stats.kstest(sample_data, cdf_func)\n```</code>", "metadata": {"problem_id": 808, "library_problem_id": 97, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 97}}
{"id": 809, "code": "```python\n    bekkers_integral = integrate.quad(bekkers, range_start, range_end, args=(estimated_a, estimated_m, estimated_d))[0]\n    def bekkers_pdf(x):\n        return bekkers(x, estimated_a, estimated_m, estimated_d) / bekkers_integral\n    def bekkers_cdf(x):\n        return integrate.quad(bekkers_pdf, range_start, x)[0]\n    kstest_result = stats.kstest(sample_data, bekkers_cdf)\n    p = kstest_result.pvalue\n    result = p < 0.05\n```\n\n</code>", "metadata": {"problem_id": 809, "library_problem_id": 98, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 97}}
{"id": 810, "code": "```python\nimport pandas as pd\nimport io\nfrom scipy import integrate\nimport numpy as np\n\nstring = '''\nTime                      A\n2017-12-18-19:54:40   -50187.0\n2017-12-18-19:54:45   -60890.5\n2017-12-18-19:54:50   -28258.5\n2017-12-18-19:54:55    -8151.0\n2017-12-18-19:55:00    -9108.5\n2017-12-18-19:55:05   -12047.0\n2017-12-18-19:55:10   -19418.0\n2017-12-18-19:55:15   -50686.0\n2017-12-18-19:55:20   -57159.0\n2017-12-18-19:55:25   -42847.0\n'''\ndf = pd.read_csv(io.StringIO(string), sep='\\s+')\ndf['Time'] = pd.to_datetime(df['Time'])\ndf = df.set_index('Time')\n\ndef rolling_integral(series):\n    y = series.values\n    x = pd.to_numeric(series.index)\n    return integrate.trapz(y, x)\n\nintegral_df = df['A'].rolling(window='4S').apply(rolling_integral)\n```", "metadata": {"problem_id": 810, "library_problem_id": 99, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 99}}
{"id": 811, "code": "```python\nimport scipy.interpolate\nx = [(2,2), (1,2), (2,3), (3,2), (2,1)]\ny = [5,7,8,10,3]\neval = [(2.7, 2.3)]\nresult = scipy.interpolate.griddata(x, y, eval, method='linear')[0]\n```</code>", "metadata": {"problem_id": 811, "library_problem_id": 100, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 100}}
{"id": 812, "code": "```python\ntotal_count = a['A1'].sum()\nweights = a['A1'] / total_count\n```\n\n</code>", "metadata": {"problem_id": 812, "library_problem_id": 101, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 101}}
{"id": 813, "code": "```python\np0 = np.array([1.0, 1.0])\nbounds = [(0.5, 1.5), (0.7, 1.8)]\nresult = sciopt.minimize(e, p0, args=(x, y), bounds=bounds).x\n```</code>", "metadata": {"problem_id": 813, "library_problem_id": 102, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 102}}
{"id": 814, "code": "```python\nextrema_indices = []\nfor i in range(len(arr)):\n    left_bound = max(0, i - n)\n    right_bound = min(len(arr), i + n + 1)\n    is_extrema = True\n    for j in range(left_bound, right_bound):\n        if arr[i] > arr[j]:\n            is_extrema = False\n            break\n    if is_extrema:\n        extrema_indices.append(i)\nresult = extrema_indices\n</code>\n", "metadata": {"problem_id": 814, "library_problem_id": 103, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 103}}
{"id": 815, "code": "```python\n    result = []\n    rows, cols = arr.shape\n    for i in range(rows):\n        for j in range(cols):\n            is_extrema = True\n            for k in range(max(0, j - n), min(cols, j + n + 1)):\n                if arr[i][j] > arr[i][k]:\n                    is_extrema = False\n                    break\n            if is_extrema:\n                result.append([i, j])\n</code>", "metadata": {"problem_id": 815, "library_problem_id": 104, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 103}}
{"id": 816, "code": "```python\nnumerical_cols = df.select_dtypes(include=np.number).columns\ndf = df[((np.abs(stats.zscore(df[numerical_cols])) < 3).all(axis=1))]\n```\n\n</code>", "metadata": {"problem_id": 816, "library_problem_id": 105, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 105}}
{"id": 817, "code": "```python\nimport numpy as np\nfrom sklearn.datasets import load_iris\nimport pandas as pd\ndata = load_iris()\ndata1 = pd.DataFrame(data=data.data, columns=data.feature_names)\ndata1['target'] = pd.Series(data.target)\n```\n", "metadata": {"problem_id": 817, "library_problem_id": 0, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 0}}
{"id": 818, "code": "```python\nimport numpy as np\nfrom sklearn.datasets import load_iris\nimport pandas as pd\ndata = load_iris()\ndata1 = pd.DataFrame(data=data.data, columns=data.feature_names)\n</code>\n", "metadata": {"problem_id": 818, "library_problem_id": 1, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 0}}
{"id": 819, "code": "```python\ndata = fetch_california_housing()\ndata1 = pd.DataFrame(data.data, columns=data.feature_names)\ndata1['target'] = data.target\n</code>\n", "metadata": {"problem_id": 819, "library_problem_id": 2, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 0}}
{"id": 820, "code": "```python\n    df = pd.DataFrame(data['data'], columns=data['feature_names'])\n    if 'target' in data:\n        df['target'] = data['target']\n    return df\n### END SOLUTION\n```", "metadata": {"problem_id": 820, "library_problem_id": 3, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 0}}
{"id": 821, "code": "```python\n    df1 = df['Col3'].explode()\n    df_out = pd.concat([df, pd.get_dummies(df1).groupby(level=0).max()], axis=1).drop('Col3', axis=1)\n```", "metadata": {"problem_id": 821, "library_problem_id": 4, "library": "Sklearn", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 4}}
{"id": 822, "code": "```python\n    col = 'Col3'\n    s = df[col].explode()\n    df_out = df.join(pd.crosstab(s.index, s))\n    df_out = df_out.drop(col, axis=1)\n</code>", "metadata": {"problem_id": 822, "library_problem_id": 5, "library": "Sklearn", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 4}}
{"id": 823, "code": "```python\n    last_col = df.iloc[:, -1]\n    unique_elements = []\n    for lst in last_col:\n        unique_elements.extend(lst)\n    unique_elements = list(set(unique_elements))\n    \n    for element in unique_elements:\n        df[element] = 0\n\n    for index, row in df.iterrows():\n        for element in row.iloc[-len(unique_elements)-1]:\n            df.loc[index, element] = 1\n            \n    df = df.drop(df.columns[-len(unique_elements)-1], axis=1)\n    df_out = df\n```\n\n", "metadata": {"problem_id": 823, "library_problem_id": 6, "library": "Sklearn", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 4}}
{"id": 824, "code": "```python\n    last_col = df.iloc[:, -1]\n    unique_elements = set()\n    for lst in last_col:\n        unique_elements.update(lst)\n    for element in unique_elements:\n        df[element] = 0\n    for index, row in df.iterrows():\n        for element in unique_elements:\n            if element in row.iloc[-len(unique_elements)-1]:\n                df.loc[index, element] = 1\n            else:\n                df.loc[index, element] = 0\n    df_out = df.drop(df.columns[-len(unique_elements)-1], axis=1)\n```</code>", "metadata": {"problem_id": 824, "library_problem_id": 7, "library": "Sklearn", "test_case_cnt": 4, "perturbation_type": "Semantic", "perturbation_origin_id": 4}}
{"id": 825, "code": "```python\n    last_col = df.iloc[:, -1]\n    unique_elements = set()\n    for lst in last_col:\n        unique_elements.update(lst)\n    for element in unique_elements:\n        df[element] = df.iloc[:, -1].apply(lambda x: 0 if element in x else 1)\n    df_out = df.drop(df.columns[-2], axis=1)\n</code>", "metadata": {"problem_id": 825, "library_problem_id": 8, "library": "Sklearn", "test_case_cnt": 4, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 4}}
{"id": 826, "code": "```python\nfrom sklearn.calibration import CalibratedClassifierCV\ncalibrated_svc = CalibratedClassifierCV(svmmodel, method='isotonic', cv=5)\ncalibrated_svc.fit(X, y)\nproba = calibrated_svc.predict_proba(x_test)\n```\n\n</code>", "metadata": {"problem_id": 826, "library_problem_id": 9, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 9}}
{"id": 827, "code": "```python\nfrom sklearn.calibration import CalibratedClassifierCV\ncalibrated_clf = CalibratedClassifierCV(base_estimator=model, cv=5)\ncalibrated_clf.fit(X, y)\nproba = calibrated_clf.predict_proba(x_predict)\n</code>\n", "metadata": {"problem_id": 827, "library_problem_id": 10, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 9}}
{"id": 828, "code": "```python\ndf_sparse = pd.DataFrame.sparse.from_spmatrix(transform_output)\ndf = pd.concat([df_origin, df_sparse], axis=1)\n</code>\n", "metadata": {"problem_id": 828, "library_problem_id": 11, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 11}}
{"id": 829, "code": "```python\n    transform_df = pd.DataFrame.sparse.from_spmatrix(transform_output, index=df_origin.index)\n    df = pd.concat([df_origin, transform_df], axis=1)\n</code>\n", "metadata": {"problem_id": 829, "library_problem_id": 12, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 11}}
{"id": 830, "code": "```python\n    if isinstance(transform_output, csr_matrix):\n        try:\n            feature_names = [f\"feature_{i}\" for i in range(transform_output.shape[1])]\n            df_transformed = pd.DataFrame.sparse.from_spmatrix(transform_output, columns=feature_names)\n        except:\n            df_transformed = pd.DataFrame(transform_output.toarray())\n            df_transformed.columns = [f\"feature_{i}\" for i in range(df_transformed.shape[1])]\n\n    else:\n        df_transformed = pd.DataFrame(transform_output)\n        df_transformed.columns = [f\"feature_{i}\" for i in range(df_transformed.shape[1])]\n\n    df = pd.concat([df.reset_index(drop=True), df_transformed.reset_index(drop=True)], axis=1)\n    return df\n### END SOLUTION\n```", "metadata": {"problem_id": 830, "library_problem_id": 13, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 11}}
{"id": 831, "code": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import PolynomialFeatures\nestimators = [('reduce_dim', PCA()), ('poly', PolynomialFeatures()), ('svm', SVC())]\nclf = Pipeline(estimators)\ndel clf.steps[1]\n```</code>", "metadata": {"problem_id": 831, "library_problem_id": 14, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 14}}
{"id": 832, "code": "```python\ndel clf.steps[0]\nclf\n```</code>", "metadata": {"problem_id": 832, "library_problem_id": 15, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 14}}
{"id": 833, "code": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import PolynomialFeatures\nestimators = [('reduce_dim', PCA()), ('poly', PolynomialFeatures()), ('svm', SVC())]\nclf = Pipeline(estimators)\n\nprint(\"Original Pipeline:\")\nprint(clf)\nprint(\"Original named_steps:\")\nprint(clf.named_steps)\n\ndel clf.named_steps['poly']\n\nclf.steps = [(name, step) for name, step in clf.named_steps.items()]\n\nprint(\"\\nModified Pipeline:\")\nprint(clf)\nprint(\"Modified named_steps:\")\nprint(clf.named_steps)\n```</code>", "metadata": {"problem_id": 833, "library_problem_id": 16, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 14}}
{"id": 834, "code": "```python\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Step 1: Create a basic Pipeline\nestimators = [('reduce_dim', PCA()), ('svm', SVC())]\nclf = Pipeline(estimators)\n\n# Step 2: Attempt to insert a step using named_steps()\noriginal_steps = clf.named_steps.copy()\n# Inserting into named_steps() does not modify the original pipeline\n# named_steps = clf.named_steps\n# named_steps['poly'] = PolynomialFeatures()\n# print(clf.named_steps)\n# print(original_steps)\n# print(clf.named_steps == original_steps)\n\n# Step 3: Create a new Pipeline object with insertion\nestimators_insert = [('reduce_dim', PCA()), ('poly', PolynomialFeatures()), ('svm', SVC())]\nclf_insert = Pipeline(estimators_insert)\n\n# Step 4: Create a new Pipeline object with deletion\nestimators_delete = [('svm', SVC())]\nclf_delete = Pipeline(estimators_delete)\n\n# Step 5: Example code for insertion and deletion (creating new Pipeline objects)\n# Insertion\nestimators_new = [('reduce_dim', PCA()), ('poly', PolynomialFeatures()), ('svm', SVC())]\nclf_new = Pipeline(estimators_new)\n\n# Deletion\nestimators_new_delete = [('reduce_dim', PCA())]\nclf_new_delete = Pipeline(estimators_new_delete)\n```</code>", "metadata": {"problem_id": 834, "library_problem_id": 17, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 17}}
{"id": 835, "code": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LogisticRegression\n\n# Create a Pipeline object 'clf' with initial steps\nestimators = [('reduce_poly', PolynomialFeatures()), ('dim_svm', PCA()), ('sVm_233', SVC())]\nclf = Pipeline(estimators)\n\n# Access the steps of the pipeline\nprint(\"Original Pipeline:\")\nprint(clf.steps)\n\n# Inserting a new step into the pipeline\nnew_step = ('logistic', LogisticRegression())\nnew_steps = list(clf.steps)  # Convert to list for modification\nnew_steps.insert(1, new_step)  # Insert at index 1\nclf.steps = new_steps  # Assign the new list to clf.steps\n\nprint(\"\\nPipeline after inserting a step:\")\nprint(clf.steps)\n\n# Deleting a step from the pipeline\ndel_index = 2  # Index of the step to delete\ndel new_steps[del_index]\nclf.steps = new_steps\n\nprint(\"\\nPipeline after deleting a step:\")\nprint(clf.steps)\n```</code>", "metadata": {"problem_id": 835, "library_problem_id": 18, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 17}}
{"id": 836, "code": "```python\nnew_step = ('t1919810', PCA())\nsteps = clf.steps\nindex_to_insert = next((i for i, step in enumerate(steps) if step[0] == 'svdm'), None)\nif index_to_insert is not None:\n    steps.insert(index_to_insert, new_step)\n    clf.steps = steps\nprint(clf)\n```</code>", "metadata": {"problem_id": 836, "library_problem_id": 19, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 17}}
{"id": 837, "code": "```python\nimport numpy as np\nimport pandas as pd\nimport xgboost.sklearn as xgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\n# Generate synthetic data for demonstration\nX, y = make_regression(n_samples=100, n_features=5, random_state=42)\ntrainX, testX, trainY, testY = train_test_split(X, y, test_size=0.2, random_state=42)\n\ntrainX = trainX.tolist()\ntrainY = trainY.tolist()\ntestX = testX.tolist()\ntestY = testY.tolist()\n\n# Define the XGBoost model\nmodel = xgb.XGBRegressor()\n\n# Define the parameter grid\nparam_grid = {\n    'n_estimators': [100, 200],\n    'learning_rate': [0.1, 0.01],\n    'max_depth': [3, 5]\n}\n\n# Define the fit_params\nfit_params = {\n    \"early_stopping_rounds\": 42,\n    \"eval_metric\": \"mae\",\n    \"eval_set\": [[np.array(testX), np.array(testY)]],\n    \"verbose\": False\n}\n\n# Initialize TimeSeriesSplit cross-validator\ncv = TimeSeriesSplit(n_splits=2)\n\n# Instantiate GridSearchCV\ngridsearch = GridSearchCV(\n    estimator=model,\n    param_grid=param_grid,\n    cv=cv,\n    scoring='neg_mean_absolute_error',\n    n_jobs=1\n)\n\n# Fit the GridSearchCV object to the training data\ngridsearch.fit(np.array(trainX), np.array(trainY), **fit_params)\n\n# Get the best score\nb = gridsearch.best_score_\n\n# Make predictions on the test set\nc = gridsearch.predict(np.array(testX))\n```\n\n</code>", "metadata": {"problem_id": 837, "library_problem_id": 20, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 20}}
{"id": 838, "code": "```python\nfit_params={\"early_stopping_rounds\":42,\n            \"eval_metric\" : \"mae\",\n            \"eval_set\" : [(testX, testY)]}\ngridsearch.fit(trainX, trainY, **fit_params)\nb = gridsearch.score(testX, testY)\nc = gridsearch.predict(testX)\n```\n\n</code>", "metadata": {"problem_id": 838, "library_problem_id": 21, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 20}}
{"id": 839, "code": "```python\nproba = []\nfor train_index, val_index in cv:\n    logreg.fit(X[train_index], y[train_index])\n    proba.append(logreg.predict_proba(X[val_index]))\n</code>\n", "metadata": {"problem_id": 839, "library_problem_id": 22, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 22}}
{"id": 840, "code": "```python\nproba = []\nfor train_index, val_index in cv:\n    logreg.fit(X[train_index], y[train_index])\n    proba.extend(logreg.predict_proba(X[val_index])[:, 1])\nproba = np.array(proba)\n```\n\n</code>", "metadata": {"problem_id": 840, "library_problem_id": 23, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 22}}
{"id": 841, "code": "```python\n    inversed = scaler.inverse_transform(scaled)\n```", "metadata": {"problem_id": 841, "library_problem_id": 24, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 24}}
{"id": 842, "code": "```python\n    from sklearn.linear_model import LinearRegression\n    from sklearn.model_selection import train_test_split\n    \n    X = data.drop('t', axis=1)\n    y = data['t']\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    scaler = StandardScaler()\n    y_train_scaled = scaler.fit_transform(y_train.values.reshape(-1, 1))\n    y_test_scaled = scaler.transform(y_test.values.reshape(-1, 1))\n    \n    model = LinearRegression()\n    model.fit(X_train, y_train_scaled)\n    \n    y_pred_scaled = model.predict(X_test)\n    \n    y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1))\n    \n    return y_pred\n### END SOLUTION\n</code>\n", "metadata": {"problem_id": 842, "library_problem_id": 25, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 24}}
{"id": 843, "code": "```python\nmodel_name = model.__class__.__name__\n</code>\n", "metadata": {"problem_id": 843, "library_problem_id": 26, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 26}}
{"id": 844, "code": "```python\nmodel_name = model.__class__.__name__\n```</code>", "metadata": {"problem_id": 844, "library_problem_id": 27, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 26}}
{"id": 845, "code": "```python\nmodel_name = model.__class__.__name__\n</code>", "metadata": {"problem_id": 845, "library_problem_id": 28, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 26}}
{"id": 846, "code": "```python\ndef load_data():\n    data = pd.DataFrame([[\"Salut comment tu vas\", \"Hey how are you today\", \"I am okay and you ?\"]]).T\n    data.columns = [\"test\"]\n    return data\n\ndata = load_data()\npipe = Pipeline([\n    (\"tf_idf\", TfidfVectorizer()),\n    (\"nmf\", NMF())\n])\n\npipe.fit(data.test)\ntf_idf_out = pipe.named_steps[\"tf_idf\"].transform(data.test)\n</code>", "metadata": {"problem_id": 846, "library_problem_id": 29, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 29}}
{"id": 847, "code": "```python\ndef load_data():\n    data = pd.DataFrame([[\"Salut comment tu vas\", \"Hey how are you today\", \"I am okay and you ?\"]]).T\n    data.columns = [\"test\"]\n    return data\n\ndata = load_data()\npipe = Pipeline([\n    (\"tf_idf\", TfidfVectorizer()),\n    (\"nmf\", NMF())\n])\n\npipe.fit(data.test)\ntf_idf_out = pipe.named_steps[\"tf_idf\"].transform(data.test)\n</code>", "metadata": {"problem_id": 847, "library_problem_id": 30, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 29}}
{"id": 848, "code": "```python\nselect_out = pipe.named_steps['select'].transform(data)\n</code>", "metadata": {"problem_id": 848, "library_problem_id": 31, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 29}}
{"id": 849, "code": "```python\nclf = GridSearchCV(bc, param_grid)\nclf = clf.fit(X_train, y_train)\nproba = clf.predict_proba(X_test)\n```\n\n</code>", "metadata": {"problem_id": 849, "library_problem_id": 32, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 32}}
{"id": 850, "code": "```python\nX = X.reshape(-1, 1)\nregressor = RandomForestRegressor(n_estimators=150, min_samples_split=1.0, random_state=42)\nrgr = regressor.fit(X, y)\npredict = rgr.predict(X_test)\n```</code>", "metadata": {"problem_id": 850, "library_problem_id": 33, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 33}}
{"id": 851, "code": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\nX, y, X_test = load_data()\nassert type(X) == np.ndarray\nassert type(y) == np.ndarray\nassert type(X_test) == np.ndarray\n\nif len(X.shape) == 1:\n    X = X.reshape(-1, 1)\nif len(y.shape) > 1:\n    y = y.ravel()\n\nregressor = RandomForestRegressor(n_estimators=150, min_samples_split=1.0, random_state=42)\nregressor.fit(X, y)\npredict = regressor.predict(X_test)\n```</code>", "metadata": {"problem_id": 851, "library_problem_id": 34, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 33}}
{"id": 852, "code": "```python\ndef preprocess(s):\n    return s.upper()\n\ncorpus = [\n    \"This is the first document.\",\n    \"This is the second second document.\",\n    \"And the third one.\",\n    \"Is this the first document?\"\n]\n\ntfidf = TfidfVectorizer(preprocessor=preprocess)\ntfidf = tfidf.fit_transform(corpus)\n```</code>", "metadata": {"problem_id": 852, "library_problem_id": 35, "library": "Sklearn", "test_case_cnt": 0, "perturbation_type": "Origin", "perturbation_origin_id": 35}}
{"id": 853, "code": "```python\ndef prePro(text):\n    return text.lower()\n\ntfidf = TfidfVectorizer(preprocessor=prePro)\n\ntext = [\"This is a SAMPLE.\", \"Another Example.\"]\ntfidf.fit_transform(text)\n```</code>", "metadata": {"problem_id": 853, "library_problem_id": 36, "library": "Sklearn", "test_case_cnt": 0, "perturbation_type": "Semantic", "perturbation_origin_id": 35}}
{"id": 854, "code": "```python\ndef load_data():\n    # Create a sample DataFrame for demonstration purposes\n    data = {'col1': [1, 2, 3, 4, 5],\n            'col2': [6.0, 7.0, 8.0, 9.0, 10.0],\n            'col3': ['a', 'b', 'c', 'd', 'e']}\n    df = pd.DataFrame(data)\n    return df\n\nnumerical_cols = data.select_dtypes(include=np.number).columns\nscaled_values = preprocessing.scale(data[numerical_cols])\ndf_out = pd.DataFrame(scaled_values, index=data.index, columns=numerical_cols)\n```</code>", "metadata": {"problem_id": 854, "library_problem_id": 37, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 37}}
{"id": 855, "code": "```python\n    scaled_cols = []\n    for col in data.columns:\n        scaled_col = preprocessing.scale(data[col])\n        scaled_cols.append(pd.Series(scaled_col, index=data.index, name=col))\n    df_out = pd.concat(scaled_cols, axis=1)\n</code>\n", "metadata": {"problem_id": 855, "library_problem_id": 38, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 37}}
{"id": 856, "code": "```python\nX = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\ny = np.array([0, 0, 1, 1])\npipe = Pipeline([\n    (\"scale\", StandardScaler()),\n    (\"model\", SGDClassifier(random_state=42))\n])\ngrid = GridSearchCV(pipe, param_grid={\"model__alpha\": [1e-3, 1e-2, 1e-1, 1]}, cv=5)\ngrid.fit(X, y)\ntry:\n    coef = grid.best_estimator_.named_steps['model'].coef_\nexcept AttributeError:\n    coef = None\n</code>", "metadata": {"problem_id": 856, "library_problem_id": 39, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 39}}
{"id": 857, "code": "```python\ngrid.fit(X, y)\ncoef = grid.best_estimator_.named_steps['model'].coef_\n</code>\n\n</code>", "metadata": {"problem_id": 857, "library_problem_id": 40, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 39}}
{"id": 858, "code": "```python\nselector = model.get_support()\ncolumn_names = X.columns[selector]\n</code>\n\n</code>", "metadata": {"problem_id": 858, "library_problem_id": 41, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 41}}
{"id": 859, "code": "```python\nselector = SelectFromModel(clf)\nselector.fit(X, y)\nselected_columns = X.columns[selector.get_support()]\ncolumn_names = list(selected_columns)\n</code>", "metadata": {"problem_id": 859, "library_problem_id": 42, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 41}}
{"id": 860, "code": "```python\nselector = model.get_support()\ncolumn_names = X.columns[selector]\n</code>\n", "metadata": {"problem_id": 860, "library_problem_id": 43, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 41}}
{"id": 861, "code": "```python\nselected_features = model.get_support()\ncolumn_names = list(X.columns[selected_features])\n</code>", "metadata": {"problem_id": 861, "library_problem_id": 44, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 41}}
{"id": 862, "code": "```python\nkm.fit(X)\ncenter = km.cluster_centers_[p]\ndistances = np.linalg.norm(X - center, axis=1)\nclosest_indices = np.argsort(distances)[:50]\nclosest_50_samples = X[closest_indices]\n</code>\n", "metadata": {"problem_id": 862, "library_problem_id": 45, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 45}}
{"id": 863, "code": "```python\nkm.fit(X)\ncenter = km.cluster_centers_[p]\ndistances = np.linalg.norm(X - center, axis=1)\nclosest_indices = np.argsort(distances)[:50]\nclosest_50_samples = X[closest_indices]\n</code>\n", "metadata": {"problem_id": 863, "library_problem_id": 46, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 45}}
{"id": 864, "code": "```python\nkm.fit(X)\ncenter = km.cluster_centers_[p]\ndistances = np.linalg.norm(X - center, axis=1)\nclosest_indices = np.argsort(distances)[:100]\nclosest_100_samples = X[closest_indices]\n</code>\n", "metadata": {"problem_id": 864, "library_problem_id": 47, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 45}}
{"id": 865, "code": "```python\n    center = km.cluster_centers_[p]\n    distances = np.linalg.norm(X - center, axis=1)\n    closest_indices = np.argsort(distances)[:50]\n    closest_samples = X[closest_indices]\n    return closest_samples\n### END SOLUTION\n```", "metadata": {"problem_id": 865, "library_problem_id": 48, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 45}}
{"id": 866, "code": "```python\nX_train = pd.get_dummies(X_train, columns=[0])\n```</code>", "metadata": {"problem_id": 866, "library_problem_id": 49, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 49}}
{"id": 867, "code": "```python\ndef load_data():\n    iris = datasets.load_iris()\n    X = iris.data[(iris.target==0) | (iris.target==1)]\n    Y = iris.target[(iris.target==0) | (iris.target==1)]\n    train_indices = list(range(40)) + list(range(50,90))\n    test_indices = list(range(40,50)) + list(range(90,100))\n    X_train = X[train_indices]\n    X_test = X[test_indices]\n    y_train = Y[train_indices]\n    y_test = Y[test_indices]\n    X_train = pd.DataFrame(X_train)\n    return X_train, y_train\nX_train = load_data()[0]\nX_train[0] = ['a'] * 40 + ['b'] * 40\nX_train = pd.get_dummies(X_train, columns=[0], drop_first=True)\n```</code>", "metadata": {"problem_id": 867, "library_problem_id": 50, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 49}}
{"id": 868, "code": "```python\nfrom sklearn.svm import SVR\n\ndef load_data():\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([2, 4, 6])\n    return X, y\n\nsvr = SVR(kernel='rbf')\nsvr.fit(X, y)\npredict = svr.predict(X)\n</code>\n", "metadata": {"problem_id": 868, "library_problem_id": 51, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 51}}
{"id": 869, "code": "```python\nfrom sklearn.svm import SVR\nfrom sklearn.datasets import make_regression\n\ndef load_data():\n    X, y = make_regression(n_samples=100, n_features=2, random_state=42)\n    return X, y\n\nmodel = SVR(kernel='rbf')\nmodel.fit(X, y)\npredict = model.predict(X)\n</code>\n", "metadata": {"problem_id": 869, "library_problem_id": 52, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 51}}
{"id": 870, "code": "```python\nfrom sklearn.svm import SVR\n\ndef load_data():\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([7, 8, 9])\n    return X, y\n\nsvr = SVR(kernel='poly', degree=2)\nsvr.fit(X, y)\npredict = svr.predict(X)\n</code>\n", "metadata": {"problem_id": 870, "library_problem_id": 53, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 51}}
{"id": 871, "code": "```python\nfrom sklearn.svm import SVR\nsvr = SVR(kernel='poly', degree=2)\nsvr.fit(X, y)\npredict = svr.predict(X)\n```</code>", "metadata": {"problem_id": 871, "library_problem_id": 54, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 53}}
{"id": 872, "code": "```python\nfrom sklearn.metrics.pairwise import cosine_similarity\nquery_tfidf = tfidf.transform(queries)\ncosine_similarities_of_queries = cosine_similarity(query_tfidf, tfidf.transform(documents))\n</code>\n", "metadata": {"problem_id": 872, "library_problem_id": 55, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 55}}
{"id": 873, "code": "```python\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Sample data (if load_data() is not available or returns incorrect data)\nqueries = [\n    \"This is the first query.\",\n    \"Another query about something else.\",\n    \"A third query on a different topic.\"\n]\ndocuments = [\n    \"This is the first document.\",\n    \"The second document is about something different.\",\n    \"A third document on another topic.\",\n    \"Document number four.\",\n    \"The fifth and final document.\"\n]\n\ntfidf = TfidfVectorizer()\ntfidf_matrix_documents = tfidf.fit_transform(documents)\ntfidf_matrix_queries = tfidf.transform(queries)\n\ncosine_similarities = cosine_similarity(tfidf_matrix_queries, tfidf_matrix_documents)\ncosine_similarities_of_queries = cosine_similarities\n```</code>", "metadata": {"problem_id": 873, "library_problem_id": 56, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 55}}
{"id": 874, "code": "```python\n    document_vectors = tfidf.fit_transform(documents)\n    query_vectors = tfidf.transform(queries)\n    from sklearn.metrics.pairwise import cosine_similarity\n    cosine_similarities = cosine_similarity(query_vectors, document_vectors)\n    return cosine_similarities\n### END SOLUTION\n```", "metadata": {"problem_id": 874, "library_problem_id": 57, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 55}}
{"id": 875, "code": "```python\ndef load_data():\n    return [\n        ['f1', 'f2', 'f3'],\n        ['f2', 'f4', 'f5', 'f6'],\n        ['f1', 'f2']\n    ]\n\nunique_features = sorted(list(set(feature for sample in features for feature in sample)))\nfeature_to_index = {feature: i for i, feature in enumerate(unique_features)}\nnew_features = np.zeros((len(features), len(unique_features)), dtype=int)\n\nfor i, sample in enumerate(features):\n    for feature in sample:\n        new_features[i, feature_to_index[feature]] = 1\nnew_features = pd.DataFrame(new_features, columns=unique_features)\n</code>", "metadata": {"problem_id": 875, "library_problem_id": 58, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 58}}
{"id": 876, "code": "```python\ndef load_data():\n    return [\n        ['t1'],\n        ['t2', 't5', 't7'],\n        ['t1', 't2', 't3', 't4', 't5'],\n        ['t4', 't5', 't6']\n    ]\n\nf = load_data()\nunique_features = set()\nfor sample in f:\n    unique_features.update(sample)\nunique_features = sorted(list(unique_features))\n\ndf = pd.DataFrame(0, index=[f'r{i+1}' for i in range(len(f))], columns=unique_features)\n\nfor i, sample in enumerate(f):\n    for feature in sample:\n        df.loc[f'r{i+1}', feature] = 1\n\nnew_f = df.to_numpy()\n```</code>", "metadata": {"problem_id": 876, "library_problem_id": 59, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 58}}
{"id": 877, "code": "```python\n    unique_features = set()\n    for sample in features:\n        unique_features.update(sample)\n    \n    feature_to_index = {feature: i for i, feature in enumerate(unique_features)}\n    \n    new_features = np.zeros((len(features), len(unique_features)), dtype=int)\n    \n    for i, sample in enumerate(features):\n        for feature in sample:\n            new_features[i, feature_to_index[feature]] = 1\n</code>", "metadata": {"problem_id": 877, "library_problem_id": 60, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 58}}
{"id": 878, "code": "```python\n    unique_features = set()\n    for sample in features:\n        unique_features.update(sample)\n    unique_features = sorted(list(unique_features))\n    \n    feature_to_index = {feature: i for i, feature in enumerate(unique_features)}\n    \n    num_samples = len(features)\n    num_unique_features = len(unique_features)\n    \n    result = np.zeros((num_samples, num_unique_features), dtype=int)\n    \n    for i, sample in enumerate(features):\n        for feature in sample:\n            j = feature_to_index[feature]\n            result[i, j] = 1\n            \n    return result\n```", "metadata": {"problem_id": 878, "library_problem_id": 61, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 58}}
{"id": 879, "code": "```python\n    unique_features = set()\n    for sample in features:\n        unique_features.update(sample)\n    unique_features = sorted(list(unique_features))\n    \n    feature_to_index = {feature: i for i, feature in enumerate(unique_features)}\n    \n    num_samples = len(features)\n    num_unique_features = len(unique_features)\n    \n    feature_array = np.zeros((num_samples, num_unique_features), dtype=int)\n    \n    for i, sample in enumerate(features):\n        for feature in sample:\n            feature_array[i, feature_to_index[feature]] = 1\n            \n    new_features = pd.DataFrame(feature_array, columns=unique_features)\n</code>", "metadata": {"problem_id": 879, "library_problem_id": 62, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 58}}
{"id": 880, "code": "```python\ndef load_data():\n    return np.array([[0,0.8,0.9],[0.8,0,0.2],[0.9,0.2,0]])\nclustering = sklearn.cluster.AgglomerativeClustering(n_clusters=2, affinity='precomputed', linkage='complete')\nclustering.fit(data_matrix)\ncluster_labels = list(clustering.labels_)\n</code>\n", "metadata": {"problem_id": 880, "library_problem_id": 63, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 63}}
{"id": 881, "code": "```python\ndef load_data():\n    data_matrix = np.array([[0,0.8,0.9],[0.8,0,0.2],[0.9,0.2,0]])\n    return data_matrix\nclustering = sklearn.cluster.AgglomerativeClustering(n_clusters=2, affinity='precomputed', linkage='complete')\nclustering.fit(data_matrix)\ncluster_labels = list(clustering.labels_)\n</code>\n", "metadata": {"problem_id": 881, "library_problem_id": 64, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 63}}
{"id": 882, "code": "```python\ndef load_data():\n    return np.array([[0,0.6,0.8],[0.6,0,0.111],[0.8,0.111,0]])\n\nclustering = sklearn.cluster.AgglomerativeClustering(n_clusters=2, affinity='precomputed', linkage='complete')\nclustering.fit(simM)\ncluster_labels = list(clustering.labels_)\n```</code>", "metadata": {"problem_id": 882, "library_problem_id": 65, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 63}}
{"id": 883, "code": "```python\nimport numpy as np\nfrom scipy.cluster.hierarchy import linkage, fcluster\n\ndata_matrix = np.array([[0,0.8,0.9],[0.8,0,0.2],[0.9,0.2,0]])\nlinked = linkage(data_matrix, method='complete')\ncluster_labels = fcluster(linked, t=2, criterion='maxclust')\ncluster_labels = list(cluster_labels)\n</code>\n", "metadata": {"problem_id": 883, "library_problem_id": 66, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 66}}
{"id": 884, "code": "```python\ndef load_data():\n    data_matrix = np.array([[0,0.8,0.9],[0.8,0,0.2],[0.9,0.2,0]])\n    return data_matrix\nlinkage_matrix = scipy.cluster.hierarchy.linkage(data_matrix, method='complete')\ncluster_labels = scipy.cluster.hierarchy.fcluster(linkage_matrix, 2, criterion='maxclust')\ncluster_labels = list(cluster_labels)\n</code>\n", "metadata": {"problem_id": 884, "library_problem_id": 67, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 66}}
{"id": 885, "code": "```python\nfrom scipy.cluster.hierarchy import linkage, fcluster\nfrom scipy.spatial.distance import squareform\n\nZ = linkage(squareform(simM), method='complete')\ncluster_labels = fcluster(Z, t=2, criterion='maxclust')\n```</code>", "metadata": {"problem_id": 885, "library_problem_id": 68, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 66}}
{"id": 886, "code": "```python\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\n\ndef load_data():\n    np.random.seed(1)\n    x1 = np.random.normal(loc=5, scale=2, size=1000)\n    x2 = np.random.exponential(scale=1/10, size=1000)\n    return np.column_stack((x1, x2))\n\ndata = load_data()\n\nx1_transformed, _ = stats.boxcox(data[:, 0] - np.min(data[:, 0]) + 1)\nx2_transformed, _ = stats.boxcox(data[:, 1] - np.min(data[:, 1]) + 1)\n\ntransformed_data = np.column_stack((x1_transformed, x2_transformed))\n\nscaler = StandardScaler()\ncentered_scaled_data = scaler.fit_transform(transformed_data)\n</code>\n", "metadata": {"problem_id": 886, "library_problem_id": 69, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 69}}
{"id": 887, "code": "```python\nfrom sklearn.preprocessing import PowerTransformer\n\npt = PowerTransformer()\ncentered_scaled_data = pt.fit_transform(data)\n</code>\n", "metadata": {"problem_id": 887, "library_problem_id": 70, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 69}}
{"id": 888, "code": "```python\nimport numpy as np\nimport pandas as pd\nimport sklearn\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\n\ndef load_data():\n    # Generate sample data (replace with your actual data loading)\n    np.random.seed(1)\n    x1 = np.random.normal(loc=5, scale=2, size=1000)\n    x2 = np.random.exponential(scale=1/10, size=1000)\n    data = np.column_stack((x1, x2))\n    return data\n\ndata = load_data()\nassert type(data) == np.ndarray\n\ntry:\n    # Box-Cox Transformation\n    data_plus_min = data + np.abs(np.min(data)) + 1e-6\n    box_cox_transformed, lambda_values = stats.boxcox(data_plus_min, axis=0)\n\n    # Centering and Scaling\n    scaler = StandardScaler()\n    box_cox_data = scaler.fit_transform(box_cox_transformed)\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n    box_cox_data = np.zeros_like(data)\n```</code>", "metadata": {"problem_id": 888, "library_problem_id": 71, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 71}}
{"id": 889, "code": "```python\nimport numpy as np\nimport pandas as pd\nimport sklearn\nfrom scipy import stats\n\ndef load_data():\n    # Replace this with your actual data loading logic\n    # This is just an example to create a sample numpy array\n    data = np.random.rand(100) * 10  # Example data, replace with your actual data\n    return data\n\ndata = load_data()\nassert type(data) == np.ndarray\n\n# Apply Box-Cox transformation\ndata_plus_one = data + 1  # Ensure data is positive\nbox_cox_data, lambda_value = stats.boxcox(data_plus_one)\n</code>\n", "metadata": {"problem_id": 889, "library_problem_id": 72, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 71}}
{"id": 890, "code": "```python\nfrom sklearn.preprocessing import PowerTransformer, StandardScaler\ndef load_data():\n    np.random.seed(1)\n    x1 = np.random.normal(loc=5, scale=2, size=1000)\n    x2 = np.random.exponential(scale=1/10, size=1000)\n    predictors = np.column_stack((x1, x2))\n    return predictors\ndata = load_data()\nassert type(data) == np.ndarray\npt = PowerTransformer(method='yeo-johnson', standardize=False)\nyeo_johnson_data = pt.fit_transform(data)\nscaler = StandardScaler()\nyeo_johnson_data = scaler.fit_transform(yeo_johnson_data)\n</code>\n", "metadata": {"problem_id": 890, "library_problem_id": 73, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 73}}
{"id": 891, "code": "```python\nfrom sklearn.preprocessing import PowerTransformer\n\npt = PowerTransformer(method='yeo-johnson', standardize=False)\nyeo_johnson_data = pt.fit_transform(data)\n</code>\n", "metadata": {"problem_id": 891, "library_problem_id": 74, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 73}}
{"id": 892, "code": "```python\nimport re\ndef custom_analyzer(text):\n    return re.findall(r'\\b\\w[\\w\\']*[\\w]\\b|[!?\"\\']', text)\n\nvectorizer = CountVectorizer(analyzer=custom_analyzer)\ntransformed_text = vectorizer.fit_transform([text])\n</code>\n", "metadata": {"problem_id": 892, "library_problem_id": 75, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 75}}
{"id": 893, "code": "```python\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(dataset.iloc[:, :-1], dataset.iloc[:, -1], test_size=0.2, random_state=42)\n```</code>", "metadata": {"problem_id": 893, "library_problem_id": 76, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 76}}
{"id": 894, "code": "```python\nfrom sklearn.model_selection import train_test_split\n\ndata_train, data_test = train_test_split(data, test_size=0.2, random_state=42)\nx_train = data_train.iloc[:, :-1]\ny_train = data_train.iloc[:, -1]\nx_test = data_test.iloc[:, :-1]\ny_test = data_test.iloc[:, -1]\n</code>\n", "metadata": {"problem_id": 894, "library_problem_id": 77, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 76}}
{"id": 895, "code": "```python\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(dataset.iloc[:, :-1], dataset.iloc[:, -1], test_size=0.4, random_state=42)\n</code>\n", "metadata": {"problem_id": 895, "library_problem_id": 78, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 76}}
{"id": 896, "code": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndef solve(data):\n    # Split the data into training and testing sets\n    train, test = train_test_split(data, test_size=0.2, random_state=42)\n    \n    # Split the training set into features (X_train) and target (Y_train)\n    x_train = train.iloc[:, :-1]\n    y_train = train.iloc[:, -1]\n    \n    # Split the testing set into features (X_test) and target (Y_test)\n    x_test = test.iloc[:, :-1]\n    y_test = test.iloc[:, -1]\n    \n    return x_train, y_train, x_test, y_test\n### END SOLUTION\n</code>\n", "metadata": {"problem_id": 896, "library_problem_id": 79, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 76}}
{"id": 897, "code": "```python\n    mse_values = df['mse'].values.reshape(-1, 1)\n    kmeans = KMeans(n_clusters=2, n_init=10)\n    kmeans.fit(mse_values)\n    labels = kmeans.predict(mse_values)\n</code>", "metadata": {"problem_id": 897, "library_problem_id": 80, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 80}}
{"id": 898, "code": "```python\n    f1 = df['mse'].values\n    f2 = list(range(0, len(f1)))\n    X = np.array(list(zip(f1, f2)))\n    kmeans = KMeans(n_clusters=2, n_init=10).fit(X)\n    labels = kmeans.predict(X)\n</code>", "metadata": {"problem_id": 898, "library_problem_id": 81, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 80}}
{"id": 899, "code": "```python\nmodel = LinearSVC(penalty=\"l1\", dual=False)\nmodel.fit(X, y)\nfeature_names = np.array(vectorizer.get_feature_names_out())\nselected_feature_names = feature_names[model.coef_[0] != 0]\n</code>\n", "metadata": {"problem_id": 899, "library_problem_id": 82, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 82}}
{"id": 900, "code": "```python\nfrom sklearn.svm import LinearSVC\nmodel = LinearSVC(penalty='l1', dual=False)\nmodel.fit(X, y)\nselected_feature_indices = model.coef_ != 0\nselected_feature_names = vectorizer.get_feature_names_out()[selected_feature_indices[0]].tolist()\n</code>\n", "metadata": {"problem_id": 900, "library_problem_id": 83, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 82}}
{"id": 901, "code": "```python\n    lsvc = LinearSVC(penalty=\"l1\", dual=False, C=0.1).fit(X, y)\n    selected_features_indices = np.where(lsvc.coef_[0] != 0)[0]\n    selected_feature_names = vectorizer.get_feature_names_out()[selected_features_indices]\n    return list(selected_feature_names)\n### END SOLUTION\n```", "metadata": {"problem_id": 901, "library_problem_id": 84, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 82}}
{"id": 902, "code": "```python\nvocabulary_list = ['Jscript','.Net','TypeScript','SQL', 'NodeJS','Angular','Mongo','CSS','Python','PHP','Photoshop','Oracle','Linux','C++',\"Java\",'TeamCity','Frontend','Backend','Full stack', 'UI Design', 'Web','Integration','Database design','UX']\nvectorizer = CountVectorizer(stop_words=\"english\",binary=True,lowercase=False, vocabulary=vocabulary_list)\nX = vectorizer.fit_transform(corpus)\nfeature_names = vectorizer.get_feature_names_out()\nX = X.toarray()\n</code>\n\n", "metadata": {"problem_id": 902, "library_problem_id": 85, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 85}}
{"id": 903, "code": "```python\nfrom collections import OrderedDict\nmy_vocabulary = OrderedDict([('Jscript',0),('.Net',1),('TypeScript',2),('NodeJS',3),('Angular',4),('Mongo',5),('CSS',6),('Python',7),('PHP',8),('Photoshop',9),('Oracle',10),('Linux',11),('C++',12),(\"Java\",13),('TeamCity',14),('Frontend',15),('Backend',16),('Full stack',17), ('UI Design', 18), ('Web', 19), ('Integration', 20), ('Database design', 21), ('UX', 22)])\nvectorizer = CountVectorizer(stop_words=\"english\",binary=True,lowercase=False,vocabulary=my_vocabulary)\nX = vectorizer.fit_transform(corpus)\nfeature_names = vectorizer.get_feature_names_out()\n</code>\n\n```", "metadata": {"problem_id": 903, "library_problem_id": 86, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 85}}
{"id": 904, "code": "```python\nvectorizer = CountVectorizer(stop_words=\"english\", binary=True, lowercase=False)\nvectorizer.fit(corpus)\nvocabulary = ['Jscript','.Net','TypeScript','SQL', 'NodeJS','Angular','Mongo','CSS','Python','PHP','Photoshop','Oracle','Linux','C++',\"Java\",'TeamCity','Frontend','Backend','Full stack', 'UI Design', 'Web','Integration','Database design','UX']\nvectorizer.vocabulary_ = {v: i for i, v in enumerate(vocabulary)}\nfeature_names = vocabulary\nX = vectorizer.transform(corpus)\nX = (X > 0).astype(int)\nX = X.toarray()\n```\n\n</code>", "metadata": {"problem_id": 904, "library_problem_id": 87, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 85}}
{"id": 905, "code": "```python\nvectorizer = CountVectorizer(stop_words=\"english\",binary=True,lowercase=False,vocabulary={'Jscript','.Net','TypeScript','NodeJS','Angular','Mongo','CSS','Python','PHP','Photoshop','Oracle','Linux','C++',\"Java\",'TeamCity','Frontend','Backend','Full stack', 'UI Design', 'Web','Integration','Database design','UX'})\nX = vectorizer.fit_transform(corpus)\nfeature_names = list(vectorizer.vocabulary_.keys())\nX = X.toarray()\nX = np.where(X > 0, 1, X)\nfeature_names, X = feature_names, X\n```\n\n</code>", "metadata": {"problem_id": 905, "library_problem_id": 88, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 85}}
{"id": 906, "code": "```python\n    def load_data():\n        data = {'Time': [1.00, 2.00, 3.00, 4.00, 5.00, 5.50, 6.00],\n                'A1': [6.64, 6.70, np.nan, 7.15, np.nan, 7.44, 7.62],\n                'A2': [6.82, 6.86, np.nan, 7.26, np.nan, 7.63, 7.86],\n                'A3': [6.79, 6.92, np.nan, 7.26, np.nan, 7.58, 7.71],\n                'B1': [6.70, np.nan, 7.07, 7.19, np.nan, 7.54, np.nan],\n                'B2': [6.95, np.nan, 7.27, np.nan, 7.40, np.nan, np.nan],\n                'B3': [7.02, np.nan, 7.40, np.nan, 7.51, np.nan, np.nan]}\n        df = pd.DataFrame(data)\n        return df\n\n    slopes = np.array([])\n    df1 = load_data()\n    for col in df1.columns:\n        if col != 'Time':\n            df2 = df1[~np.isnan(df1['Time']) & ~np.isnan(df1[col])]\n            df3 = df2[['Time', col]]\n            npMatrix = np.matrix(df3)\n            X, Y = npMatrix[:, 0], npMatrix[:, 1]\n            model = LinearRegression().fit(X, Y)\n            slope = model.coef_[0]\n            slopes = np.append(slopes, slope)\n</code>", "metadata": {"problem_id": 906, "library_problem_id": 89, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 89}}
{"id": 907, "code": "```python\n    cols = [f'{chr(i)}{j}' for i in range(65, 91) for j in range(1, 4) if f'{chr(i)}{j}' <= 'Z3']\n    slopes = []\n    for col in cols:\n        if col in df1.columns:\n            df2 = df1[~np.isnan(df1[col])]\n            df3 = df2[['Time', col]]\n            if not df3.empty:\n                npMatrix = np.matrix(df3)\n                X, Y = npMatrix[:, 0], npMatrix[:, 1]\n                try:\n                    slope = LinearRegression().fit(X, Y)\n                    m = slope.coef_[0]\n                    slopes.append(m)\n                except:\n                    slopes.append(np.nan)\n            else:\n                slopes.append(np.nan)\n        else:\n            slopes.append(np.nan)\n```", "metadata": {"problem_id": 907, "library_problem_id": 90, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 89}}
{"id": 908, "code": "```python\ndef load_data():\n    try:\n        df = pd.read_csv('titanic.csv')\n        return df\n    except FileNotFoundError:\n        print(\"Error: titanic.csv not found. Please make sure the file is in the same directory.\")\n        return pd.DataFrame()\n\nle = LabelEncoder()\ndf['Sex'] = le.fit_transform(df['Sex'])\ntransformed_df = df\n</code>\n", "metadata": {"problem_id": 908, "library_problem_id": 91, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 91}}
{"id": 909, "code": "```python\nle = LabelEncoder()\nle.fit(df['Sex'])\ndf['Sex'] = le.transform(df['Sex'])\ntransformed_df = df\n```\n\n</code>", "metadata": {"problem_id": 909, "library_problem_id": 92, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 91}}
{"id": 910, "code": "```python\n    le = LabelEncoder()\n    df['Sex'] = le.fit_transform(df['Sex'])\n    return df\n### END SOLUTION\n</code>\n", "metadata": {"problem_id": 910, "library_problem_id": 93, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 91}}
{"id": 911, "code": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn import linear_model\nimport statsmodels.api as sm\n\ndef load_data():\n    # Replace this with your actual data loading code\n    X_train = np.array([[1, 2], [3, 4], [5, 6]])\n    y_train = np.array([7, 8, 9])\n    X_test = np.array([[11, 12], [13, 14], [15, 16]])\n    y_test = np.array([17, 18, 19])\n    return X_train, y_train, X_test, y_test\n\nX_train, y_train, X_test, y_test = load_data()\n\nassert type(X_train) == np.ndarray\nassert type(y_train) == np.ndarray\nassert type(X_test) == np.ndarray\nassert type(y_test) == np.ndarray\n\nelastic_net = linear_model.ElasticNet()\nelastic_net.fit(X_train, y_train)\n\ntraining_set_score = elastic_net.score(X_train, y_train)\ntest_set_score = elastic_net.score(X_test, y_test)\n```\n", "metadata": {"problem_id": 911, "library_problem_id": 94, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 94}}
{"id": 912, "code": "```python\n    original_shape = np_array.shape\n    flattened_array = np_array.reshape(-1, 1)\n    scaler = MinMaxScaler()\n    normalized_array = scaler.fit_transform(flattened_array)\n    transformed = normalized_array.reshape(original_shape)\n</code>\n", "metadata": {"problem_id": 912, "library_problem_id": 95, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 95}}
{"id": 913, "code": "```python\nscaler = MinMaxScaler()\ntransformed_array = scaler.fit_transform(np_array.reshape(-1, 1))\ntransformed = transformed_array.reshape(3, 3)\n</code>\n", "metadata": {"problem_id": 913, "library_problem_id": 96, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 95}}
{"id": 914, "code": "```python\n    scaler = MinMaxScaler()\n    a_reshaped = a.reshape(-1, 1)\n    a_normalized_reshaped = scaler.fit_transform(a_reshaped)\n    a_normalized = a_normalized_reshaped.reshape(2, 2)\n    return a_normalized\n### END SOLUTION\n</code>", "metadata": {"problem_id": 914, "library_problem_id": 97, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 95}}
{"id": 915, "code": "```python\ndf['MA_50'] = df['Close'].rolling(window=50).mean()\ndf['MA_100'] = df['Close'].rolling(window=100).mean()\ndf['MA_200'] = df['Close'].rolling(window=200).mean()\ndf = df.dropna()\nX = np.concatenate([df[['Close']], df[['MA_50']], df[['MA_100']], df[['MA_200']]], axis=1)\ny = df['B/S']\nclf = tree.DecisionTreeRegressor()\nclf.fit(X[:-1], y[:-1])\nlast_row = np.array([df['Close'].iloc[-1], df['MA_50'].iloc[-1], df['MA_100'].iloc[-1], df['MA_200'].iloc[-1]]).reshape(1, -1)\npredict = clf.predict(last_row)\n```</code>", "metadata": {"problem_id": 915, "library_problem_id": 98, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 98}}
{"id": 916, "code": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\nnew_X = [['asdf', '1'], ['asdf', '0'], ['qwer', '1']]\ny = ['2', '3', '4']\n\n# Convert to pandas DataFrame for easier encoding\ndf = pd.DataFrame(new_X)\n\n# Apply Label Encoding to each column\nfor col in df.columns:\n    le = LabelEncoder()\n    df[col] = le.fit_transform(df[col])\n\n# Convert back to numpy array\nnew_X_encoded = df.values\n\nclf = DecisionTreeClassifier()\nclf.fit(new_X_encoded, y)\n</code>\n", "metadata": {"problem_id": 916, "library_problem_id": 99, "library": "Sklearn", "test_case_cnt": 0, "perturbation_type": "Origin", "perturbation_origin_id": 99}}
{"id": 917, "code": "```python\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\n\nnew_X = [['asdf', '1'], ['asdf', '0'], ['qwer', '1']]\nenc = OneHotEncoder(handle_unknown='ignore')\nenc.fit(new_X)\nencoded_X = enc.transform(new_X).toarray()\nclf = DecisionTreeClassifier()\ny = ['2', '3', '4']\nclf.fit(encoded_X, y)\n</code>\n", "metadata": {"problem_id": 917, "library_problem_id": 100, "library": "Sklearn", "test_case_cnt": 0, "perturbation_type": "Surface", "perturbation_origin_id": 99}}
{"id": 918, "code": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\n\nnew_X = [['dsa', '2'], ['sato', '3'], ['dsa', '3']]\nnew_X = pd.DataFrame(new_X)\nnew_X = pd.get_dummies(new_X)\n\nclf = DecisionTreeClassifier()\nclf.fit(new_X, ['4', '5', '4'])\n```</code>", "metadata": {"problem_id": 918, "library_problem_id": 101, "library": "Sklearn", "test_case_cnt": 0, "perturbation_type": "Surface", "perturbation_origin_id": 99}}
{"id": 919, "code": "```python\nX = dataframe.iloc[:, :-1].astype(float)\ny = dataframe.iloc[:, -1]\nlogReg = LogisticRegression()\nlogReg.fit(X, y)\npredict = logReg.predict(X)\n```\n\n</code>", "metadata": {"problem_id": 919, "library_problem_id": 102, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 102}}
{"id": 920, "code": "```python\nX = dataframe.iloc[:, :-1].astype(float)\ny = dataframe.iloc[:, -1]\nlogReg = LogisticRegression()\nlogReg.fit(X, y)\npredict = logReg.predict(X)\n```</code>", "metadata": {"problem_id": 920, "library_problem_id": 103, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 102}}
{"id": 921, "code": "```python\ntrain_size = 0.2\nsplit_index = int(len(features_dataframe) * train_size)\ntrain_dataframe = features_dataframe[:split_index]\ntest_dataframe = features_dataframe[split_index:]\ntrain_dataframe = train_dataframe.sort_values(by=['date'])\ntest_dataframe = test_dataframe.sort_values(by=['date'])\n```\n\n</code>", "metadata": {"problem_id": 921, "library_problem_id": 104, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 104}}
{"id": 922, "code": "```python\n    train_size = 0.8\n    split_index = int(len(features_dataframe) * (1 - train_size))\n    test_dataframe = features_dataframe[:split_index]\n    train_dataframe = features_dataframe[split_index:]\n    train_dataframe = train_dataframe.sort_values(by=[\"date\"])\n    test_dataframe = test_dataframe.sort_values(by=[\"date\"])\n</code>\n", "metadata": {"problem_id": 922, "library_problem_id": 105, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 104}}
{"id": 923, "code": "```python\n    train_size = 0.2\n    split_index = int(len(features_dataframe) * train_size)\n    train_dataframe = features_dataframe.iloc[:split_index]\n    test_dataframe = features_dataframe.iloc[split_index:]\n    \n    if not features_dataframe['date'].is_monotonic:\n        train_dataframe = train_dataframe.sort_values(by='date')\n        test_dataframe = test_dataframe.sort_values(by='date')\n    return train_dataframe, test_dataframe\n### END SOLUTION\n</code>", "metadata": {"problem_id": 923, "library_problem_id": 106, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 104}}
{"id": 924, "code": "```python\ndef scale_month(group):\n    scaler = MinMaxScaler()\n    cols = ['X2', 'X3']\n    scaled_values = scaler.fit_transform(group[cols])\n    scaled_df = pd.DataFrame(scaled_values, columns = ['X2_scale', 'X3_scale'], index=group.index)\n    return scaled_df\n\ndf = df.join(df.groupby('Month').apply(scale_month))\n</code>\n\n</code>", "metadata": {"problem_id": 924, "library_problem_id": 107, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 107}}
{"id": 925, "code": "```python\ndef scale_columns(group):\n    scaler = MinMaxScaler()\n    group[['new_A2', 'new_A3']] = scaler.fit_transform(group[['A2', 'A3']])\n    return group\nmyData = myData.groupby('Month').apply(scale_columns)\n</code>", "metadata": {"problem_id": 925, "library_problem_id": 108, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 107}}
{"id": 926, "code": "```python\nimport re\ndef load_data():\n    return \"Hello @friend, this is a good day. #good.\"\n\nwords = load_data()\nfeature_names = re.findall(r'\\b\\w+\\b|@\\w+|#\\w+', words)\n</code>\n", "metadata": {"problem_id": 926, "library_problem_id": 109, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 109}}
{"id": 927, "code": "```python\nwords = \"ha @ji me te no ru bu ru wa, @na n te ko to wa na ka tsu ta wa. wa ta shi da ke no mo na ri za, mo u to kku ni \" \\\n        \"#de a 't te ta ka ra\"\ncount = CountVectorizer(lowercase = False).fit([words])\nfeature_names = sorted(count.get_feature_names_out())\n```</code>", "metadata": {"problem_id": 927, "library_problem_id": 110, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 109}}
{"id": 928, "code": "```python\nfull_results = pd.DataFrame(GridSearch_fitted.cv_results_)\n</code>", "metadata": {"problem_id": 928, "library_problem_id": 111, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 111}}
{"id": 929, "code": "```python\n    cv_results = GridSearch_fitted.cv_results_\n    full_results = pd.DataFrame(cv_results).sort_values('mean_fit_time')\n</code>", "metadata": {"problem_id": 929, "library_problem_id": 112, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 111}}
{"id": 930, "code": "```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import IsolationForest\nimport joblib\n\ndef load_data():\n    \"\"\"Loads or creates sample data.\"\"\"\n    # Replace this with your actual data loading logic\n    rng = np.random.RandomState(42)\n    X = 0.3 * rng.randn(100, 2)\n    X_train = np.r_[X + 2, X - 2]\n    # Convert to DataFrame for demonstration purposes\n    X_train = pd.DataFrame(X_train, columns=['feature1', 'feature2'])\n    return X_train\n\ndef train_model(data):\n    \"\"\"Trains an Isolation Forest model.\"\"\"\n    model = IsolationForest(random_state=42)\n    model.fit(data)\n    return model\n\ndef save_model(model, filename=\"isolation_forest.joblib\"):\n    \"\"\"Saves the trained model to a file.\"\"\"\n    joblib.dump(model, filename)\n    print(f\"Model saved to {filename}\")\n\ndef load_model(filename=\"isolation_forest.joblib\"):\n    \"\"\"Loads the trained model from a file.\"\"\"\n    try:\n        model = joblib.load(filename)\n        print(f\"Model loaded from {filename}\")\n        return model\n    except FileNotFoundError:\n        print(f\"Error: Model file '{filename}' not found.  Train and save the model first.\")\n        return None\n\ndef predict_outliers(model, data):\n    \"\"\"Predicts outliers using the loaded model.\"\"\"\n    if model is None:\n        print(\"No model loaded. Cannot predict.\")\n        return None\n    predictions = model.predict(data)\n    return predictions\n\nif __name__ == \"__main__\":\n    # 1. Load data\n    data = load_data()\n\n    # 2. Train and save the model (only do this once or when retraining is needed)\n    model = train_model(data)\n    save_model(model)\n\n    # 3. Load the model\n    loaded_model = load_model()\n\n    # 4. Predict outliers on new data (or the same data for demonstration)\n    if loaded_model is not None:\n        new_data = load_data() # Or load completely new data\n        predictions = predict_outliers(loaded_model, new_data)\n\n        # Print some predictions\n        if predictions is not None:\n            print(\"Predictions:\", predictions)\n            # Example: Count the number of outliers (-1) and inliers (1)\n            num_outliers = np.sum(predictions == -1)\n            num_inliers = np.sum(predictions == 1)\n            print(f\"Number of outliers: {num_outliers}\")\n            print(f\"Number of inliers: {num_inliers}\")\n```</code>", "metadata": {"problem_id": 930, "library_problem_id": 113, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 113}}
{"id": 931, "code": "```python\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef load_data():\n    data = {'items': ['1fgg', '2hhj', '3jkl'],\n            'description': ['abcd ty', 'abc r', 'r df']}\n    df = pd.DataFrame(data)\n    return df\n\ntfidf_matrix = tfidf.fit_transform(df['description'])\ncosine_similarity_matrix = cosine_similarity(tfidf_matrix)\ncosine_similarity_df = pd.DataFrame(cosine_similarity_matrix, index=df['items'], columns=df['items'])\n</code>\n", "metadata": {"problem_id": 931, "library_problem_id": 114, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 114}}
{"id": 932, "code": "```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Create a dummy model\nmodel = nn.Linear(10, 1)\n\n# Initialize an optimizer\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\n# Print the initial learning rate\nprint(\"Initial learning rate:\", optimizer.param_groups[0]['lr'])\n\n# Dynamically change the learning rate\noptimizer.param_groups[0]['lr'] = 0.001\n\n# Print the updated learning rate\nprint(\"Updated learning rate:\", optimizer.param_groups[0]['lr'])\n```\n\n</code>", "metadata": {"problem_id": 932, "library_problem_id": 0, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 0}}
{"id": 933, "code": "```python\nimport torch\n\n# Initialize optimizer\noptimizer = torch.optim.SGD([torch.randn(10, requires_grad=True)], lr=0.01)\n\n# Initial learning rate\ninitial_lr = optimizer.param_groups[0]['lr']\nprint(f\"Initial learning rate: {initial_lr}\")\n\n# Simulate training loop\nprevious_loss = float('inf')\nfor epoch in range(5):\n    # Simulate loss calculation\n    loss = torch.rand(1)\n\n    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n\n    # Check if loss increased\n    if loss > previous_loss:\n        print(\"Loss increased, updating learning rate\")\n        # Update learning rate\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = 0.001\n        \n        # Print updated learning rate\n        print(f\"New learning rate: {optimizer.param_groups[0]['lr']}\")\n\n    # Store current loss for next iteration\n    previous_loss = loss\n```</code>", "metadata": {"problem_id": 933, "library_problem_id": 1, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 0}}
{"id": 934, "code": "```python\nimport torch\n\n# Create a dummy model\nmodel = torch.nn.Linear(10, 1)\n\n# Initialize the optimizer with an initial learning rate\noptimizer = torch.optim.SGD(model.parameters(), lr=0.005)\n\n# Print the initial learning rate\nprint(\"Initial learning rate:\", optimizer.param_groups[0]['lr'])\n\n# Change the learning rate\nnew_lr = 0.0005\nfor param_group in optimizer.param_groups:\n    param_group['lr'] = new_lr\n\n# Print the new learning rate\nprint(\"New learning rate:\", optimizer.param_groups[0]['lr'])\n```\n</code>", "metadata": {"problem_id": 934, "library_problem_id": 2, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 0}}
{"id": 935, "code": "```python\nimport torch\nimport torch.optim as optim\n\ndef load_data():\n    # Dummy parameters for demonstration\n    params = [torch.nn.Parameter(torch.randn(2, 3))]\n    optimizer = optim.SGD(params, lr=0.005)\n    return optimizer\n\ndef update_lr(optimizer, new_lr):\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = new_lr\n\noptim = load_data()\n\n# Simulate training loop\nloss = 0.1\nprint(f\"Initial learning rate: {optim.param_groups[0]['lr']}\")\nprint(f\"Initial loss: {loss}\")\n\n# Simulate loss increase\nloss = 0.2\nprint(f\"Loss increased to: {loss}\")\n\n# Update learning rate\nupdate_lr(optim, 0.0005)\nprint(f\"Updated learning rate: {optim.param_groups[0]['lr']}\")\n\n# Guidance on choosing learning rate:\nprint(\"\\nGuidance on choosing between lr=0.05 and lr=0.0005:\")\nprint(\"If the loss increase is significant and you are in the early stages of training, a larger decrease (e.g., from 0.05 to 0.0005) might be appropriate.\")\nprint(\"If the loss increase is small or you are nearing convergence, a smaller decrease would be better to avoid drastic changes to the training process.\")\n```</code>", "metadata": {"problem_id": 935, "library_problem_id": 3, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 0}}
{"id": 936, "code": "```python\nembedding_matrix = word2vec.wv.vectors\nnum_embeddings = len(word2vec.wv.index_to_key)\nembedding_dim = word2vec.vector_size\nembedding_layer = torch.nn.Embedding(num_embeddings, embedding_dim)\nembedding_layer.weight.data.copy_(torch.from_numpy(embedding_matrix))\nembedded_input = embedding_layer(input_Tensor)\n</code>\n", "metadata": {"problem_id": 936, "library_problem_id": 4, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 4}}
{"id": 937, "code": "```python\n    weights = torch.FloatTensor(word2vec.wv.vectors)\n    embedding_layer = torch.nn.Embedding.from_pretrained(weights)\n    embedded_input = embedding_layer(input_Tensor)\n    return embedded_input\n### END SOLUTION\n</code>\n", "metadata": {"problem_id": 937, "library_problem_id": 5, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 4}}
{"id": 938, "code": "```python\nx = torch.rand(4,4)\npx = pd.DataFrame(x.numpy())\n```</code>", "metadata": {"problem_id": 938, "library_problem_id": 6, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 6}}
{"id": 939, "code": "```python\ndef load_data():\n    return torch.rand(4,4)\nx = load_data()\npx = pd.DataFrame(x.numpy())\n```</code>", "metadata": {"problem_id": 939, "library_problem_id": 7, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 6}}
{"id": 940, "code": "```python\nx = torch.rand(6,6)\npx = pd.DataFrame(x.numpy())\n</code>\n", "metadata": {"problem_id": 940, "library_problem_id": 8, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 6}}
{"id": 941, "code": "```python\n    A_log = A_log.long()\n    C = B[:, A_log]\n```</code>", "metadata": {"problem_id": 941, "library_problem_id": 9, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 9}}
{"id": 942, "code": "```python\n    indices = torch.nonzero(A_logical).flatten()\n    C = B[:, indices]\n```</code>", "metadata": {"problem_id": 942, "library_problem_id": 10, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 9}}
{"id": 943, "code": "```python\n    A_log = A_log.bool()\n    C = B[:, A_log]\n</code>", "metadata": {"problem_id": 943, "library_problem_id": 11, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 9}}
{"id": 944, "code": "```python\n    A_log = A_log.long()\n    C = B[:, A_log]\n</code>", "metadata": {"problem_id": 944, "library_problem_id": 12, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Semantic", "perturbation_origin_id": 9}}
{"id": 945, "code": "```python\n    A_log = A_log.long()\n    C = B[:, A_log]\n    return C\n### END SOLUTION\n```", "metadata": {"problem_id": 945, "library_problem_id": 13, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 9}}
{"id": 946, "code": "```python\n    A_log_bool = A_log == 0\n    indices = torch.nonzero(A_log_bool).flatten()\n    C = B[:, indices]\n</code>\n\n", "metadata": {"problem_id": 946, "library_problem_id": 14, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 9}}
{"id": 947, "code": "```python\n    C = torch.index_select(B, dim=1, index=idx)\n</code>\n", "metadata": {"problem_id": 947, "library_problem_id": 15, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 9}}
{"id": 948, "code": "```python\nimport pandas as pd\nimport torch\nimport numpy as np\ndef load_data():\n    return np.array([\n       np.array([0.5, 1.0, 2.0], dtype=np.float16),\n       np.array([4.0, 6.0, 8.0], dtype=np.float16)\n    ], dtype=object)\n\nx_array = load_data()\nx_tensor = torch.from_numpy(np.stack(x_array)).float()\n```</code>", "metadata": {"problem_id": 948, "library_problem_id": 16, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 16}}
{"id": 949, "code": "```python\nx_array = np.array(x_array.tolist())\nx_tensor = torch.Tensor(x_array)\n```</code>", "metadata": {"problem_id": 949, "library_problem_id": 17, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 16}}
{"id": 950, "code": "```python\n    if not isinstance(a, np.ndarray):\n        raise TypeError(\"Input must be a NumPy array.\")\n\n    if a.size == 0:\n        return torch.Tensor()\n\n    dtype = None\n    shape = None\n    arrays = []\n\n    for i in range(a.size):\n        element = a[i]\n        if not isinstance(element, np.ndarray):\n            raise TypeError(f\"Element at index {i} is not a NumPy array.\")\n\n        if dtype is None:\n            dtype = element.dtype\n        elif element.dtype != dtype:\n            element = element.astype(dtype)\n\n        if shape is None:\n            shape = element.shape\n        elif element.shape != shape:\n            raise ValueError(f\"Array at index {i} has shape {element.shape}, expected {shape}.\")\n        \n        arrays.append(element)\n\n    try:\n        stacked_array = np.stack(arrays)\n    except ValueError as e:\n        raise ValueError(f\"Could not stack arrays: {e}\")\n\n    return torch.from_numpy(stacked_array)\n### END SOLUTION\n```", "metadata": {"problem_id": 950, "library_problem_id": 18, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 16}}
{"id": 951, "code": "```python\n    max_len = max(lens)\n    mask = torch.zeros((len(lens), max_len), dtype=torch.long)\n    for i, length in enumerate(lens):\n        mask[i, :length] = 1\n</code>\n", "metadata": {"problem_id": 951, "library_problem_id": 19, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 19}}
{"id": 952, "code": "```python\n    max_len = max(lens)\n    mask = torch.zeros(len(lens), max_len).long()\n    for i, l in enumerate(lens):\n        mask[i, :l] = 1\n</code>\n", "metadata": {"problem_id": 952, "library_problem_id": 20, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 19}}
{"id": 953, "code": "```python\n    max_len = max(lens)\n    mask = torch.zeros((len(lens), max_len), dtype=torch.long)\n    for i, length in enumerate(lens):\n        mask[i, :length] = 1\n</code>\n", "metadata": {"problem_id": 953, "library_problem_id": 21, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 19}}
{"id": 954, "code": "```python\n    max_len = max(lens)\n    mask = torch.zeros(len(lens), max_len).long()\n    for i, length in enumerate(lens):\n        mask[i, :length] = 1\n    return mask\n```", "metadata": {"problem_id": 954, "library_problem_id": 22, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 19}}
{"id": 955, "code": "```python\n    batch_size = Tensor_2D.shape[0]\n    diag_len = Tensor_2D.shape[1]\n    Tensor_3D = torch.zeros(batch_size, diag_len, diag_len)\n    for i in range(batch_size):\n        Tensor_3D[i] = torch.diag(Tensor_2D[i])\n</code>\n", "metadata": {"problem_id": 955, "library_problem_id": 23, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 23}}
{"id": 956, "code": "```python\n    result = []\n    for index, row in enumerate(t):\n        row = torch.Tensor(row)\n        diag_matrix = torch.diag(row)\n        scaled_matrix = index * diag_matrix\n        result.append(scaled_matrix)\n    return torch.stack(result)\n```", "metadata": {"problem_id": 956, "library_problem_id": 24, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 23}}
{"id": 957, "code": "```python\n    if a.shape[0] == 1:\n        ab = torch.stack((a, b), dim=0)\n    else:\n        ab = torch.cat((a, b.unsqueeze(0)), dim=0)\n```", "metadata": {"problem_id": 957, "library_problem_id": 25, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 25}}
{"id": 958, "code": "```python\n    pad_size = a.shape[0] - b.shape[0]\n    padding = torch.zeros(pad_size, b.shape[1])\n    b_padded = torch.cat((b, padding), dim=0)\n    ab = torch.cat((a, b_padded), dim=0)\n</code>", "metadata": {"problem_id": 958, "library_problem_id": 26, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 25}}
{"id": 959, "code": "```python\n    if len(b.shape) == 1:\n        b = b.unsqueeze(0)\n    elif b.shape != (1, a.shape[1]):\n        b = b.reshape(1, a.shape[1])\n    ab = torch.cat((a, b), dim=0)\n    return ab\n### END SOLUTION\n</code>", "metadata": {"problem_id": 959, "library_problem_id": 27, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 25}}
{"id": 960, "code": "```python\nfor i in range(a.shape[0]):\n    length = lengths[i]\n    a[i, length:, :] = 0\n</code>", "metadata": {"problem_id": 960, "library_problem_id": 28, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 28}}
{"id": 961, "code": "```python\nfor i in range(a.shape[0]):\n    length = lengths[i]\n    a[i, length:, :] = 2333\n```\n\n</code>", "metadata": {"problem_id": 961, "library_problem_id": 29, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 28}}
{"id": 962, "code": "```python\nfor i in range(a.shape[0]):\n    length = lengths[i]\n    a[i, :length, :] = 0\n</code>", "metadata": {"problem_id": 962, "library_problem_id": 30, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 28}}
{"id": 963, "code": "```python\nfor i in range(a.shape[0]):\n    a[i, :lengths[i], :] = 2333\n</code>", "metadata": {"problem_id": 963, "library_problem_id": 31, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 28}}
{"id": 964, "code": "```python\ntensor_of_tensors = torch.stack(list_of_tensors)\n</code>\n", "metadata": {"problem_id": 964, "library_problem_id": 32, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 32}}
{"id": 965, "code": "```python\nimport torch\nnew_tensors = torch.stack(list)\n</code>\n", "metadata": {"problem_id": 965, "library_problem_id": 33, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 32}}
{"id": 966, "code": "```python\n        tt = torch.stack(lt)\n        return tt\n    ### END SOLUTION\n```", "metadata": {"problem_id": 966, "library_problem_id": 34, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 32}}
{"id": 967, "code": "```python\ntensor_of_tensors = torch.stack(list_of_tensors)\n</code>\n", "metadata": {"problem_id": 967, "library_problem_id": 35, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 32}}
{"id": 968, "code": "```python\nresult = t[torch.arange(t.shape[0]), torch.tensor(idx)]\n```", "metadata": {"problem_id": 968, "library_problem_id": 36, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 36}}
{"id": 969, "code": "```python\nresult = t[torch.arange(t.shape[0]), torch.tensor(idx)]\n```", "metadata": {"problem_id": 969, "library_problem_id": 37, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 36}}
{"id": 970, "code": "```python\n    idx = torch.from_numpy(idx)\n    idx = 1 - idx\n    result = t[torch.arange(t.shape[0]), idx]\n</code>", "metadata": {"problem_id": 970, "library_problem_id": 38, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 36}}
{"id": 971, "code": "```python\n    result = torch.gather(x, 1, ids.unsqueeze(2).repeat(1,1,2)).squeeze(1)\n```", "metadata": {"problem_id": 971, "library_problem_id": 39, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 39}}
{"id": 972, "code": "```python\nresult = torch.gather(x, 1, ids.unsqueeze(2).repeat(1, 1, x.shape[2])).squeeze(1)\n```\n\n</code>", "metadata": {"problem_id": 972, "library_problem_id": 40, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 39}}
{"id": 973, "code": "```python\nresult = []\nfor i in range(ids.shape[0]):\n    j = np.where(ids[i] == 1)[0][0]\n    result.append(x[i, j])\nresult = np.array(result)\n```\n\n</code>", "metadata": {"problem_id": 973, "library_problem_id": 41, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 39}}
{"id": 974, "code": "```python\n    y = torch.argmax(softmax_output, dim=1)\n    y = y.reshape(-1, 1)\n</code>", "metadata": {"problem_id": 974, "library_problem_id": 42, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 42}}
{"id": 975, "code": "```python\n    softmax_output = torch.tensor([[0.7, 0.2, 0.1],\n                                     [0.2, 0.6, 0.2],\n                                     [0.1, 0.1, 0.8]])\n    y = torch.argmax(softmax_output, dim=1)\n    y = torch.reshape(y, (-1, 1))\n</code>", "metadata": {"problem_id": 975, "library_problem_id": 43, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 42}}
{"id": 976, "code": "```python\n    softmax_output = torch.tensor([[0.2, 0.1, 0.7],\n                                 [0.6, 0.3, 0.1],\n                                 [0.15, 0.8, 0.05]])\n    y = torch.argmin(softmax_output, dim=1)\n    y = y.reshape(-1, 1)\n</code>", "metadata": {"problem_id": 976, "library_problem_id": 44, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 42}}
{"id": 977, "code": "```python\n    max_indices = torch.argmax(softmax_output, dim=1)\n    result = max_indices.reshape(-1, 1)\n    return result\n```", "metadata": {"problem_id": 977, "library_problem_id": 45, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 42}}
{"id": 978, "code": "```python\n    min_values, min_indices = torch.min(softmax_output, dim=1)\n    y = min_indices.long()\n    return y\n```</code>", "metadata": {"problem_id": 978, "library_problem_id": 46, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 42}}
{"id": 979, "code": "```python\ndef cross_entropy2d(input, target, weight=None, size_average=True):\n    n, c, h, w = input.size()\n\n    log_p = F.log_softmax(input, dim=1)\n    target_onehot = F.one_hot(target, num_classes=c).permute(0, 3, 1, 2).float()\n    loss = -torch.sum(target_onehot * log_p) / (n * h * w)\n\n    return loss\n\nimages = Variable(torch.randn(5, 3, 4, 4))\nlabels = Variable(torch.LongTensor(5, 4, 4).random_(3))\nloss = cross_entropy2d(images, labels)\n```\n\n</code>", "metadata": {"problem_id": 979, "library_problem_id": 47, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 47}}
{"id": 980, "code": "```python\ncnt_equal = torch.sum(A == B)\n```</code>", "metadata": {"problem_id": 980, "library_problem_id": 48, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 48}}
{"id": 981, "code": "```python\ncnt_equal = torch.sum(A == B).item()\n</code>\n", "metadata": {"problem_id": 981, "library_problem_id": 49, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 48}}
{"id": 982, "code": "```python\ncnt_not_equal = torch.sum(A != B)\n</code>\n", "metadata": {"problem_id": 982, "library_problem_id": 50, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 48}}
{"id": 983, "code": "```python\n    cnt_equal = torch.sum(A == B)\n    return int(cnt_equal)\n### END SOLUTION\n</code>\n", "metadata": {"problem_id": 983, "library_problem_id": 51, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 48}}
{"id": 984, "code": "```python\n    x = A.shape[0] // 2\n    cnt_equal = torch.sum((A[-x:] == B[-x:]).int())\n</code>", "metadata": {"problem_id": 984, "library_problem_id": 52, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 48}}
{"id": 985, "code": "```python\nx = A.shape[0] // 2\ncnt_not_equal = torch.sum(A[-x:] != B[-x:])\n```\n", "metadata": {"problem_id": 985, "library_problem_id": 53, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 48}}
{"id": 986, "code": "```python\ntensors_31 = []\ndim = 3\nnum_tensors = a.shape[dim] - chunk_dim + 1\nfor i in range(num_tensors):\n    tensors_31.append(a[:, :, :, i:i+chunk_dim, :])\n```\n\n</code>", "metadata": {"problem_id": 986, "library_problem_id": 54, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 54}}
{"id": 987, "code": "```python\ndef split_tensor(tensor, chunk_size, dim):\n    tensors = []\n    for i in range(tensor.shape[dim] - chunk_size + 1):\n        tensors.append(tensor[:, :, i:i+chunk_size, :, :])\n    return tensors\n\na = torch.randn(1, 3, 40, 10, 1)\nchunk_size = 10\ndim = 2\ntensors_31 = split_tensor(a, chunk_size, dim)\nassert len(tensors_31) == 31\nassert tensors_31[0].shape == (1, 3, 10, 10, 1)\nassert tensors_31[-1].shape == (1, 3, 10, 10, 1)\n```\n\n</code>", "metadata": {"problem_id": 987, "library_problem_id": 55, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 54}}
{"id": 988, "code": "```python\n    mask = mask.unsqueeze(-1)\n    output = torch.where(mask == 1, clean_input_spectrogram, output)\n</code>\n", "metadata": {"problem_id": 988, "library_problem_id": 56, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 56}}
{"id": 989, "code": "```python\n    mask = mask.bool()\n    output[~mask.unsqueeze(-1).expand_as(output)] = clean_input_spectrogram[~mask.unsqueeze(-1).expand_as(output)]\n</code>", "metadata": {"problem_id": 989, "library_problem_id": 57, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 56}}
{"id": 990, "code": "```python\n    abs_x = torch.abs(x)\n    abs_y = torch.abs(y)\n    minimum = torch.minimum(abs_x, abs_y)\n    mask = abs_x <= abs_y\n    signed_min = torch.where(mask, x, y)\n</code>\n", "metadata": {"problem_id": 990, "library_problem_id": 58, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 58}}
{"id": 991, "code": "```python\n    abs_x = torch.abs(x)\n    abs_y = torch.abs(y)\n    max_abs = torch.maximum(abs_x, abs_y)\n    sign_x = torch.sign(x)\n    sign_y = torch.sign(y)\n    mask = (abs_x >= abs_y)\n    signed_max_sign = torch.where(mask, sign_x, sign_y)\n    signed_max = max_abs * signed_max_sign\n</code>\n", "metadata": {"problem_id": 991, "library_problem_id": 59, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 58}}
{"id": 992, "code": "```python\n    abs_x = torch.abs(x)\n    abs_y = torch.abs(y)\n    minimum = torch.min(abs_x, abs_y)\n    sign_x = torch.sign(x)\n    sign_y = torch.sign(y)\n    mask = abs_x <= abs_y\n    signed_min = torch.where(mask, sign_x * minimum, sign_y * minimum)\n    return signed_min\n```", "metadata": {"problem_id": 992, "library_problem_id": 60, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 58}}
{"id": 993, "code": "```python\nimport torch\nimport torch.nn.functional as F\nMyNet = torch.nn.Sequential(torch.nn.Linear(4, 15),\n                            torch.nn.Sigmoid(),\n                            torch.nn.Linear(15, 3),\n                            )\nMyNet.load_state_dict(torch.load(\"my_model.pt\"))\nMyNet.eval()\nwith torch.no_grad():\n    output = MyNet(input)\n    probabilities = F.softmax(output, dim=1)\n    confidence_score = torch.max(probabilities).item()\n```</code>", "metadata": {"problem_id": 993, "library_problem_id": 61, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 61}}
{"id": 994, "code": "```python\n    a = torch.Tensor([[1, 2, 3], [1, 2, 3]])\n    b = torch.Tensor([[5, 6, 7], [5, 6, 7]])\n    result = torch.cat((a[:, :2], (a[:, 2:3] + b[:, :1]) / 2, b[:, 1:]), dim=1)\n```</code>", "metadata": {"problem_id": 994, "library_problem_id": 62, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 62}}
{"id": 995, "code": "```python\n    a_first_cols = a[:, :-1]\n    b_last_cols = b[:, 1:]\n    a_last_col = a[:, -1]\n    b_first_col = b[:, 0]\n    avg_col = (a_last_col + b_first_col) / 2\n    avg_col = avg_col.reshape(-1, 1)\n    result = torch.cat((a_first_cols, avg_col, b_last_cols), dim=1)\n    return result\n### END SOLUTION\n```", "metadata": {"problem_id": 995, "library_problem_id": 63, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 62}}
{"id": 996, "code": "```python\n    shape = t.shape\n    new_shape = (shape[0], shape[1] + 2, shape[2] + 2)\n    result = torch.zeros(new_shape, dtype=t.dtype)\n    result[:, 1:-1, 1:-1] = t\n</code>\n", "metadata": {"problem_id": 996, "library_problem_id": 64, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 64}}
{"id": 997, "code": "```python\n    result = torch.zeros((4, 4))\n    result[1:3, 1:3] = t[0]\n</code>", "metadata": {"problem_id": 997, "library_problem_id": 65, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 64}}
{"id": 998, "code": "```python\n    top_bottom_padding = torch.full((1, t.shape[1]), -1)\n    left_right_padding = torch.full((t.shape[0] + 2, 1), -1)\n    t = t.squeeze(0)\n    t = torch.cat((top_bottom_padding, t), dim=0)\n    t = torch.cat((t, top_bottom_padding), dim=0)\n    t = torch.cat((left_right_padding, t), dim=1)\n    t = torch.cat((t, left_right_padding), dim=1)\n    result = t\n```\n\n</code>", "metadata": {"problem_id": 998, "library_problem_id": 66, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 64}}
{"id": 999, "code": "```python\nW = W.unsqueeze(1)\nresult = torch.bmm(data, W).squeeze(2)\n```\n", "metadata": {"problem_id": 999, "library_problem_id": 67, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 67}}
